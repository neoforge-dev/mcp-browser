This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-04-09T17:30:30.208Z

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
apparmor/
  mcp-browser.profile
docker/
  apparmor/
    mcp-browser.profile
  Dockerfile
  network-config.yml
  setup-network.sh
  xvfb-init.sh
docs/
  examples/
    responsive_testing.py
  api.md
examples/
  event_subscription_example.py
  README.md
mcp-browser/
  docker/
    Dockerfile
  output/
  src/
  tests/
memory-bank/
  .neorules
  active-context.md
  mcp-browser-features.md
  product-context.md
  progress.md
  project-brief.md
  system-patterns.md
  tech-context.md
src/
  __init__.py
  browser_pool.py
  error_handler.py
  integrate_components.py
  integration.py
  main.py
  rate_limiter.py
  simple_test.py
  test_api.py
  test_event_subscription.py
  test_events.html
  test_integration.py
  test_lifespan.py
  test_rate_limiting.py
  test_websocket_client.py
  test_websocket.py
test_output/
tests/
  conftest.py
  test_network_isolation.py
  test_resource_management.py
.dockerignore
.gitignore
.python-version
CHANGELOG.md
docker-compose.yml
Dockerfile
example_mac_mini_setup.md
install_one_line.sh
install.sh
Makefile
ONE_LINE_INSTALL.md
pyproject.toml
README.md
requirements-test.txt
run_analysis.sh
run.sh
simple_test.sh
test_api.sh
test_local.sh
test_mcp_events.sh
test_mcp_tools.sh
test_simple.sh
WEBSOCKET_EVENTS.md
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="apparmor/mcp-browser.profile">
# AppArmor profile for MCP Browser
#include <tunables/global>

profile mcp-browser flags=(attach_disconnected) {
    #include <abstractions/base>
    #include <abstractions/python>
    #include <abstractions/nameservice>
    #include <abstractions/openssl>

    # Basic capabilities
    capability net_bind_service,
    capability setuid,
    capability setgid,
    capability sys_chroot,
    capability sys_admin,

    # Network access controls
    network inet stream,
    network inet6 stream,
    network unix stream,
    
    # Deny raw socket access
    deny network raw,
    
    # Allow specific ports
    network inet tcp port 8000,
    network inet tcp port 7665,
    
    # Deny ICMP
    deny network inet icmp,
    deny network inet6 icmp,
    
    # Process operations
    ptrace (read) peer=@{profile_name},
    signal (receive) peer=@{profile_name},

    # File operations
    /usr/bin/python3* ix,
    /usr/local/bin/python3* ix,
    /usr/lib/python3/** r,
    /usr/local/lib/python3/** r,
    
    # Rate limiting storage
    owner /tmp/mcp-browser-rate-limit/ rw,
    owner /tmp/mcp-browser-rate-limit/** rwk,
    
    # Browser operations
    owner @{PROC}/@{pid}/fd/ r,
    owner @{PROC}/@{pid}/task/@{pid}/stat r,
    owner @{PROC}/@{pid}/stat r,
    owner @{PROC}/@{pid}/cmdline r,
    owner @{PROC}/@{pid}/status r,
    owner @{PROC}/@{pid}/mem r,
    owner @{PROC}/@{pid}/auxv r,
    
    # System metrics
    @{PROC}/loadavg r,
    @{PROC}/stat r,
    @{PROC}/meminfo r,
    @{PROC}/cpuinfo r,
    
    # Browser process monitoring
    @{PROC}/*/{stat,status,cmdline} r,
    
    # X11 display
    /tmp/.X11-unix/* rw,
    
    # SSL certificates
    /etc/ssl/certs/** r,
    /usr/share/ca-certificates/** r,
    
    # Application paths
    /app/** r,
    /app/src/** r,
    /app/static/** r,
    owner /app/output/** rw,
    
    # Temporary files
    owner /tmp/** rwk,
    
    # Log files
    owner /var/log/mcp-browser/ rw,
    owner /var/log/mcp-browser/** rw,
    
    # Shared memory
    owner /{,var/}run/shm/** rwk,
    
    # Browser sandbox
    owner /dev/shm/** rwk,
    
    # Security denials
    deny @{PROC}/sys/kernel/yama/ptrace_scope w,
    deny @{PROC}/sys/kernel/suid_dumpable w,
    deny @{PROC}/sysrq-trigger w,
    deny @{PROC}/kcore r,
    
    # Network security
    deny network inet raw,
    deny network inet6 raw,
    deny network packet,
    deny network netlink,
    
    # Additional security
    deny @{PROC}/sys/net/ipv4/conf/*/accept_redirects w,
    deny @{PROC}/sys/net/ipv4/conf/*/send_redirects w,
    deny @{PROC}/sys/net/ipv4/ip_forward w,
    deny @{PROC}/sys/net/ipv6/conf/*/accept_redirects w,
    deny @{PROC}/sys/net/ipv6/conf/*/send_redirects w,
    deny @{PROC}/sys/net/ipv6/ip_forward w,
}
</file>

<file path="docker/apparmor/mcp-browser.profile">
#include <tunables/global>

profile mcp-browser flags=(attach_disconnected,mediate_deleted) {
  #include <abstractions/base>
  #include <abstractions/nameservice>
  #include <abstractions/python>
  #include <abstractions/X>

  # Allow network access
  network inet tcp,
  network inet udp,

  # Access to file system
  /app/** r,
  /app/ r,
  /app/main.py r,
  /home/pwuser/ r,
  /home/pwuser/** rw,
  /tmp/** rw,
  /dev/shm/** rw,
  /usr/lib/** rm,
  /usr/bin/** rm,
  /usr/local/bin/python* ix,
  /usr/local/lib/python*/** rm,
  
  # X11 permissions
  /tmp/.X11-unix/** rw,
  owner /dev/tty* rw,
  owner /proc/*/fd/* r,
  owner /var/tmp/** rw,

  # Browser specific
  deny @{PROC}/* r,
  deny @{PROC}/*/net/if_inet6 r,
  deny @{PROC}/*/stat r,
  owner @{PROC}/*/fd/ r,
  owner @{PROC}/*/task/ r,
  owner @{PROC}/*/status r,
  owner @{PROC}/*/cmdline r,
  owner @{PROC}/*/oom_score_adj rw,
  owner @{PROC}/*/task/** r,
}
</file>

<file path="docker/Dockerfile">
FROM mcr.microsoft.com/playwright:v1.51.1-noble

# Setup directories
RUN mkdir -p /home/pwuser/Downloads && \
    chown -R pwuser:pwuser /home/pwuser

# Install uv
RUN curl -fsSL https://astral.sh/uv/install.sh | bash && \
    echo 'export PATH="$HOME/.cargo/bin:$PATH"' >> /home/pwuser/.bashrc

# Set up the application directory
WORKDIR /app

# Copy pyproject.toml first for dependency installation
COPY pyproject.toml .

# Install dependencies using uv
RUN /root/.cargo/bin/uv pip install -e .

# Install Playwright browsers
RUN python -m playwright install chromium

# Create output directory
RUN mkdir -p /app/output && chown -R pwuser:pwuser /app/output

# Copy application files
COPY src/ /app/src/
COPY mcp-browser/ /app/mcp-browser/

# Change ownership of the application to the non-root user
RUN chown -R pwuser:pwuser /app

# Set necessary environment variables
ENV PYTHONUNBUFFERED=1
ENV SERVER_PORT=7665
ENV OUTPUT_DIR=/app/output

# Switch to non-root user
USER pwuser
EXPOSE 7665

# Command to run the application
CMD ["python", "-m", "uv", "run", "src/main.py"]
</file>

<file path="docker/network-config.yml">
version: "3.8"
networks:
  mcp-browser-internal:
    driver: bridge
    internal: true
    ipam:
      driver: default
      config:
        - subnet: 172.20.0.0/16
          gateway: 172.20.0.1
    labels:
      - "com.mcp-browser.network=internal"
      - "com.mcp-browser.security=high"
  mcp-browser-external:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.21.0.0/16
          gateway: 172.21.0.1
    labels:
      - "com.mcp-browser.network=external"
      - "com.mcp-browser.security=medium"
  mcp-browser-monitoring:
    driver: bridge
    internal: true
    ipam:
      driver: default
      config:
        - subnet: 172.22.0.0/16
          gateway: 172.22.0.1
    labels:
      - "com.mcp-browser.network=monitoring"
      - "com.mcp-browser.security=high"
</file>

<file path="docker/setup-network.sh">
#!/bin/bash
set -e
# Create Docker networks if they don't exist
docker network create mcp-browser-internal || true
docker network create mcp-browser-external || true
docker network create mcp-browser-monitoring || true
# Configure iptables rules
iptables -N MCP_BROWSER_FORWARD
iptables -A FORWARD -j MCP_BROWSER_FORWARD
# Allow established connections
iptables -A MCP_BROWSER_FORWARD -m state --state ESTABLISHED,RELATED -j ACCEPT
# Allow internal network communication
iptables -A MCP_BROWSER_FORWARD -s 172.20.0.0/16 -d 172.20.0.0/16 -j ACCEPT
# Allow monitoring network to internal network
iptables -A MCP_BROWSER_FORWARD -s 172.22.0.0/16 -d 172.20.0.0/16 -j ACCEPT
# Allow external network to specific ports
iptables -A MCP_BROWSER_FORWARD -s 172.21.0.0/16 -d 172.20.0.0/16 -p tcp --dport 8000 -j ACCEPT
iptables -A MCP_BROWSER_FORWARD -s 172.21.0.0/16 -d 172.20.0.0/16 -p tcp --dport 7665 -j ACCEPT
# Drop all other traffic
iptables -A MCP_BROWSER_FORWARD -j DROP
# Enable IP forwarding
echo 1 > /proc/sys/net/ipv4/ip_forward
# Configure TCP hardening
echo 1 > /proc/sys/net/ipv4/tcp_syncookies
echo 1024 > /proc/sys/net/ipv4/tcp_max_syn_backlog
echo 2 > /proc/sys/net/ipv4/tcp_synack_retries
# Save iptables rules
iptables-save > /etc/iptables/rules.v4
echo "Network isolation and firewall rules configured successfully."
</file>

<file path="docker/xvfb-init.sh">
#!/bin/bash
set -e
# Log startup message
echo "Starting Xvfb and MCP Browser..."
# Kill any existing Xvfb processes
if [ -f /tmp/.X99-lock ]; then
    echo "Removing existing X11 lock file"
    rm -f /tmp/.X99-lock
fi
# Start Xvfb
Xvfb :99 -screen 0 1280x720x24 > /dev/null 2>&1 &
XVFB_PID=$!
# Give Xvfb time to start
echo "Waiting for Xvfb to initialize..."
sleep 2
# Check if Xvfb is running
if ! ps -p $XVFB_PID > /dev/null; then
    echo "Error: Xvfb failed to start"
    exit 1
fi
echo "Xvfb started with PID $XVFB_PID"
# Set up a trap to ensure clean shutdown
trap "echo 'Shutting down Xvfb and MCP Browser'; kill $XVFB_PID; exit" SIGINT SIGTERM
# Determine if we're in test mode
if [ "$RUN_TESTS" = "true" ]; then
    echo "Running tests..."
    cd /app
    pytest /app/tests -v -vv --capture=no
else
    echo "Starting MCP Browser application..."
    cd /app
    python3 src/main.py
fi
# Clean up Xvfb
kill $XVFB_PID
</file>

<file path="docs/examples/responsive_testing.py">
#!/usr/bin/env python3
"""
Example script demonstrating usage of the MCP Browser Responsive Testing API
"""
import requests
import json
import os
import time
from pprint import pprint
# API settings
API_BASE_URL = "http://localhost:7665"
TEST_URL = "https://example.com"
# Create output directory
output_dir = "responsive_results"
os.makedirs(output_dir, exist_ok=True)
def responsive_test():
    """Test a website for responsive behavior across multiple viewport sizes"""
    print(f"Testing responsive behavior for: {TEST_URL}")
    # Configure test parameters
    viewports = [
        {"width": 375, "height": 667},    # Mobile portrait
        {"width": 768, "height": 1024},   # Tablet portrait
        {"width": 1366, "height": 768},   # Laptop
        {"width": 1920, "height": 1080}   # Desktop
    ]
    selectors = [
        "h1",                # Main heading
        "p",                 # Paragraphs
        "a",                 # Links
        ".container",        # Container elements
        "#main",            # Main content area
    ]
    # Make API request
    try:
        response = requests.post(
            f"{API_BASE_URL}/api/responsive/test",
            json={
                "url": TEST_URL,
                "viewports": viewports,
                "selectors": selectors,
                "include_screenshots": True,
                "compare_elements": True
            }
        )
        # Process response
        if response.status_code == 200:
            result = response.json()
            # Save full results
            timestamp = int(time.time())
            output_file = os.path.join(output_dir, f"responsive_test_{timestamp}.json")
            with open(output_file, "w") as f:
                json.dump(result, f, indent=2)
            print(f"Full results saved to: {output_file}")
            # Display summary
            print("\nResponsive Testing Summary:")
            print("--------------------------")
            print(f"URL: {result['url']}")
            print(f"Tested Viewports: {len(result['viewports'])}")
            # Show viewport-specific metrics
            print("\nViewport Metrics:")
            for vp_result in result['viewport_results']:
                vp_name = vp_result['viewport_name']
                print(f"\n- {vp_name}:")
                if 'page_metrics' in vp_result:
                    metrics = vp_result['page_metrics']
                    print(f"  Document Size: {metrics.get('documentWidth', 'N/A')}x{metrics.get('documentHeight', 'N/A')}")
                    print(f"  Horizontal Scrolling: {'Present' if metrics.get('horizontalScrollPresent', False) else 'None'}")
                    print(f"  Small Touch Targets: {metrics.get('touchTargetSizes', 'N/A')}")
                    print(f"  Media Queries: {len(metrics.get('mediaQueries', []))}")
                if 'screenshot_path' in vp_result:
                    print(f"  Screenshot: {vp_result['screenshot_path']}")
            # Show responsive issues if any
            if result.get('element_comparison'):
                print("\nResponsive Issues Detected:")
                issues_found = False
                for selector, comparison in result['element_comparison'].items():
                    if comparison.get('differences') or comparison.get('responsive_issues'):
                        issues_found = True
                        print(f"\n- {selector}:")
                        for diff in comparison.get('differences', []):
                            print(f"  • {diff.get('description', 'Unknown issue')}")
                            if 'counts' in diff:
                                print(f"    Element counts: {diff['counts']}")
                        for issue in comparison.get('responsive_issues', []):
                            print(f"  • {issue.get('description', 'Unknown issue')}")
                            if 'visibility' in issue:
                                print(f"    Visibility changes: {issue['visibility']}")
                if not issues_found:
                    print("No significant responsive issues detected.")
            return True
        else:
            print(f"Error: API returned status code {response.status_code}")
            print(response.text)
            return False
    except Exception as e:
        print(f"Error: {e}")
        return False
if __name__ == "__main__":
    responsive_test()
</file>

<file path="docs/api.md">
# MCP Browser API Documentation

## Frontend Analysis Endpoints

### Screenshot Capture

**Endpoint:** `POST /api/screenshots/capture`

Captures a screenshot of a web page with configurable options.

**Parameters:**
- `url` (string, required): The URL of the page to capture
- `viewport` (object, optional): The viewport size, default: `{"width": 1280, "height": 800}`
- `full_page` (boolean, optional): Whether to capture the full page or just the viewport, default: `true`
- `format` (string, optional): Image format, options: "png" or "jpeg", default: "png"
- `quality` (integer, optional): Image quality for JPEG format (1-100), default: None
- `wait_until` (string, optional): When to consider navigation finished, default: "networkidle"

**Example Request:**
```json
{
  "url": "https://example.com",
  "viewport": {
    "width": 1920,
    "height": 1080
  },
  "full_page": true,
  "format": "png",
  "wait_until": "networkidle"
}
```

**Example Response:**
```json
{
  "success": true,
  "screenshot": "base64_encoded_image_data...",
  "format": "png",
  "viewport": {
    "width": 1920,
    "height": 1080
  },
  "url": "https://example.com"
}
```

### DOM Extraction

**Endpoint:** `POST /api/dom/extract`

Extracts DOM elements from a web page with optional style computation.

**Parameters:**
- `url` (string, required): The URL of the page to analyze
- `selector` (string, optional): CSS selector for elements to extract, if not provided extracts entire DOM
- `include_styles` (boolean, optional): Whether to include computed styles, default: `false`
- `include_attributes` (boolean, optional): Whether to include element attributes, default: `true`

**Example Request:**
```json
{
  "url": "https://example.com",
  "selector": "h1",
  "include_styles": true,
  "include_attributes": true
}
```

**Example Response:**
```json
{
  "success": true,
  "url": "https://example.com",
  "dom": [
    {
      "tagName": "h1",
      "textContent": "Example Domain",
      "isVisible": true,
      "boundingBox": {
        "x": 192,
        "y": 192,
        "width": 896,
        "height": 38
      },
      "attributes": {
        "class": "heading"
      },
      "styles": {
        "color": "rgb(0, 0, 0)",
        "font-size": "32px",
        "margin": "0px"
      }
    }
  ]
}
```

### CSS Analysis

**Endpoint:** `POST /api/css/analyze`

Analyzes CSS properties of selected elements on a web page.

**Parameters:**
- `url` (string, required): The URL of the page to analyze
- `selector` (string, required): CSS selector for elements to analyze
- `properties` (array, optional): Specific CSS properties to analyze, if not provided returns most common properties
- `check_accessibility` (boolean, optional): Whether to include accessibility checks, default: `false`

**Example Request:**
```json
{
  "url": "https://example.com",
  "selector": "p",
  "properties": ["color", "font-size", "margin", "padding"],
  "check_accessibility": true
}
```

**Example Response:**
```json
{
  "success": true,
  "url": "https://example.com",
  "selector": "p",
  "elements": [
    {
      "tagName": "p",
      "textContent": "This domain is for use in illustrative examples in documents.",
      "isVisible": true,
      "boundingBox": {
        "x": 192,
        "y": 240,
        "width": 896,
        "height": 72
      },
      "styles": {
        "color": "rgb(0, 0, 0)",
        "font-size": "16px",
        "margin": "16px 0px",
        "padding": "0px"
      },
      "accessibility": {
        "colorContrast": null,
        "hasAltText": null,
        "hasAriaLabel": false,
        "isFocusable": false,
        "backgroundColor": "rgb(255, 255, 255)",
        "textColor": "rgb(0, 0, 0)"
      }
    }
  ],
  "count": 1
}
```

### Accessibility Testing

**Endpoint:** `POST /api/accessibility/test`

Tests a web page for accessibility issues using axe-core.

**Parameters:**
- `url` (string, required): The URL of the page to test
- `standard` (string, optional): Accessibility standard to test against, options: "wcag2a", "wcag2aa", "wcag2aaa", "wcag21aa", "section508", default: "wcag2aa"
- `include_html` (boolean, optional): Whether to include HTML context in results, default: `true`
- `include_warnings` (boolean, optional): Whether to include warnings in results, default: `true`
- `selectors` (array, optional): List of CSS selectors to test, if not provided tests the entire page

**Example Request:**
```json
{
  "url": "https://example.com",
  "standard": "wcag2aa",
  "include_html": true,
  "include_warnings": true,
  "selectors": ["main", "nav"]
}
```

**Example Response:**
```json
{
  "url": "https://example.com",
  "timestamp": 1742762305,
  "standard": "wcag2aa",
  "results": {
    "testEngine": {
      "name": "axe-core",
      "version": "4.7.0"
    },
    "violations": [
      {
        "id": "color-contrast",
        "impact": "serious",
        "nodes": [
          {
            "html": "<p style=\"color: #999\">Low contrast text</p>",
            "target": ["p:nth-child(2)"],
            "failureSummary": "Element has insufficient color contrast"
          }
        ]
      }
    ],
    "passes": [...],
    "incomplete": [...],
    "inapplicable": [...]
  },
  "output_file": "output/accessibility_test_1742762305.json"
}
```

### Responsive Design Testing

**Endpoint:** `POST /api/responsive/test`

Tests a web page across different viewport sizes to analyze responsive behavior.

**Parameters:**
- `url` (string, required): The URL of the page to test
- `viewports` (array, optional): List of viewport sizes to test, default:
  ```
  [
    {"width": 375, "height": 667},   # Mobile
    {"width": 768, "height": 1024},  # Tablet
    {"width": 1366, "height": 768},  # Laptop
    {"width": 1920, "height": 1080}  # Desktop
  ]
  ```
- `compare_elements` (boolean, optional): Whether to compare elements across viewports, default: `true`
- `include_screenshots` (boolean, optional): Whether to capture screenshots at each viewport, default: `true`
- `selectors` (array, optional): List of CSS selectors to test, required for element comparison
- `waiting_time` (integer, optional): Additional time to wait after page load in milliseconds, default: `null`

**Example Request:**
```json
{
  "url": "https://example.com",
  "viewports": [
    {"width": 375, "height": 667},
    {"width": 1366, "height": 768}
  ],
  "selectors": ["h1", "p", ".navigation"],
  "include_screenshots": true,
  "compare_elements": true
}
```

**Example Response:**
```json
{
  "url": "https://example.com",
  "timestamp": 1742762418,
  "viewports": [
    {"width": 375, "height": 667},
    {"width": 1366, "height": 768}
  ],
  "viewport_results": [
    {
      "viewport": {"width": 375, "height": 667},
      "viewport_name": "375x667",
      "page_metrics": {
        "documentWidth": 375,
        "documentHeight": 667,
        "viewportWidth": 375,
        "viewportHeight": 667,
        "mediaQueries": ["(max-width: 768px)"],
        "horizontalScrollPresent": false,
        "textOverflows": 0,
        "touchTargetSizes": 2
      },
      "elements_data": [...],
      "screenshot_path": "output/responsive/1742762418/screenshot_375x667.png"
    },
    {
      "viewport": {"width": 1366, "height": 768},
      "viewport_name": "1366x768",
      "page_metrics": {...},
      "elements_data": [...],
      "screenshot_path": "output/responsive/1742762418/screenshot_1366x768.png"
    }
  ],
  "element_comparison": {
    "h1": {
      "selector": "h1",
      "differences": [],
      "responsive_issues": []
    },
    "p": {
      "selector": "p",
      "differences": [],
      "responsive_issues": [
        {
          "element_key": "p-0",
          "issue": "visibility_change",
          "description": "Element visibility changes across viewports",
          "visibility": {
            "375x667": false,
            "1366x768": true
          }
        }
      ]
    }
  },
  "output_directory": "output/responsive/1742762418"
}
```

## WebSocket Interface

The MCP Browser provides a WebSocket interface for real-time communication with the browser.

**Endpoint:** `WebSocket /ws`

**Supported Actions:**
- `navigate`: Navigate to a URL
  ```json
  {
    "action": "navigate",
    "url": "https://example.com"
  }
  ```
</file>

<file path="examples/event_subscription_example.py">
#!/usr/bin/env python3
"""
MCP Browser WebSocket Event Subscription Example
This example demonstrates how to:
1. Connect to the MCP Browser WebSocket event endpoint
2. Subscribe to specific browser events
3. Process and handle the events in real-time
4. Unsubscribe when no longer needed
Requirements:
- websockets
- asyncio
- json
Usage:
python event_subscription_example.py
"""
import asyncio
import json
import signal
import sys
import time
import argparse
from uuid import uuid4
import websockets
# Default configuration
DEFAULT_WS_URL = "ws://localhost:7665/ws/browser/events"
DEFAULT_API_URL = "http://localhost:7665"
DEFAULT_TEST_URL = "https://example.com"
DEFAULT_TIMEOUT = 60  # seconds
# Event colors for terminal output
COLORS = {
    "PAGE": "\033[94m",    # Blue
    "DOM": "\033[92m",     # Green
    "CONSOLE": "\033[93m", # Yellow
    "NETWORK": "\033[91m", # Red
    "DEFAULT": "\033[0m",  # Reset
}
class EventSubscriptionClient:
    def __init__(self, ws_url, timeout=60):
        self.ws_url = ws_url
        self.timeout = timeout
        self.subscriptions = {}
        self.running = False
        self.websocket = None
        self.client_id = None
    async def connect(self):
        """Connect to the WebSocket server"""
        try:
            self.websocket = await websockets.connect(self.ws_url)
            print(f"Connected to {self.ws_url}")
            # Wait for the welcome message
            welcome = await self.websocket.recv()
            welcome_data = json.loads(welcome)
            if welcome_data.get("type") == "connection":
                self.client_id = welcome_data.get("client_id")
                print(f"Received welcome message: {welcome_data.get('message')}")
                print(f"Client ID: {self.client_id}")
            # Set a timeout handler
            if self.timeout > 0:
                asyncio.create_task(self._timeout_handler())
            return True
        except Exception as e:
            print(f"Connection error: {e}")
            return False
    async def subscribe(self, event_types, filters=None):
        """Subscribe to specific event types with optional filters"""
        if not self.websocket:
            print("Not connected. Call connect() first.")
            return None
        subscription_request = {
            "action": "subscribe",
            "event_types": event_types
        }
        if filters:
            subscription_request["filters"] = filters
        await self.websocket.send(json.dumps(subscription_request))
        response = await self.websocket.recv()
        response_data = json.loads(response)
        if "subscription_id" in response_data:
            subscription_id = response_data["subscription_id"]
            self.subscriptions[subscription_id] = {
                "event_types": event_types,
                "filters": filters
            }
            print(f"Subscribed to {', '.join(event_types)} with ID: {subscription_id}")
            return subscription_id
        else:
            print(f"Subscription failed: {response_data}")
            return None
    async def unsubscribe(self, subscription_id):
        """Unsubscribe from a specific subscription"""
        if not self.websocket:
            print("Not connected. Call connect() first.")
            return False
        if subscription_id not in self.subscriptions:
            print(f"Subscription ID {subscription_id} not found.")
            return False
        unsubscribe_request = {
            "action": "unsubscribe",
            "subscription_id": subscription_id
        }
        await self.websocket.send(json.dumps(unsubscribe_request))
        response = await self.websocket.recv()
        response_data = json.loads(response)
        if response_data.get("success", False):
            del self.subscriptions[subscription_id]
            print(f"Unsubscribed from {subscription_id}")
            return True
        else:
            print(f"Unsubscribe failed: {response_data}")
            return False
    async def list_subscriptions(self):
        """List all active subscriptions"""
        if not self.websocket:
            print("Not connected. Call connect() first.")
            return []
        list_request = {
            "action": "list"
        }
        await self.websocket.send(json.dumps(list_request))
        response = await self.websocket.recv()
        response_data = json.loads(response)
        if "subscriptions" in response_data:
            return response_data["subscriptions"]
        else:
            print(f"List subscriptions failed: {response_data}")
            return []
    async def listen(self):
        """Listen for events and process them"""
        if not self.websocket:
            print("Not connected. Call connect() first.")
            return
        self.running = True
        try:
            while self.running:
                message = await self.websocket.recv()
                event = json.loads(message)
                # Only process events with a proper type
                if "type" in event and event["type"] not in ["connection", "subscription"]:
                    self._process_event(event)
        except websockets.exceptions.ConnectionClosed:
            print("Connection closed")
        except Exception as e:
            print(f"Error in listen loop: {e}")
        finally:
            self.running = False
    def _process_event(self, event):
        """Process a received event"""
        event_type = event.get("type", "UNKNOWN")
        event_name = event.get("event", "unknown")
        timestamp = event.get("timestamp", time.time())
        # Format timestamp
        time_str = time.strftime("%H:%M:%S", time.localtime(timestamp))
        # Get color for event type
        color = COLORS.get(event_type, COLORS["DEFAULT"])
        reset = COLORS["DEFAULT"]
        # Print event information
        print(f"{color}[{time_str}] {event_type}.{event_name}{reset}")
        # Print event data
        if "data" in event:
            data_str = json.dumps(event["data"], indent=2)
            print(f"  Data: {data_str}")
        # Print page ID if available
        if "page_id" in event:
            print(f"  Page: {event['page_id']}")
        print("-" * 40)
    async def close(self):
        """Close the WebSocket connection"""
        self.running = False
        if self.websocket:
            await self.websocket.close()
            self.websocket = None
            print("Connection closed")
    async def _timeout_handler(self):
        """Handle timeout to automatically close the connection"""
        await asyncio.sleep(self.timeout)
        if self.running:
            print(f"Timeout after {self.timeout} seconds")
            await self.close()
async def navigate_to_page(api_url, url):
    """Navigate the browser to a specific URL using the API"""
    import aiohttp
    navigate_url = f"{api_url}/api/browser/navigate?url={url}"
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(navigate_url) as response:
                result = await response.json()
                if result.get("success", False):
                    print(f"Successfully navigated to: {url}")
                else:
                    print(f"Navigation failed: {result}")
    except Exception as e:
        print(f"Navigation error: {e}")
        print("Continuing without navigation...")
async def main():
    parser = argparse.ArgumentParser(description="MCP Browser WebSocket Event Subscription Example")
    parser.add_argument("--ws-url", default=DEFAULT_WS_URL, help="WebSocket URL")
    parser.add_argument("--api-url", default=DEFAULT_API_URL, help="API URL")
    parser.add_argument("--test-url", default=DEFAULT_TEST_URL, help="URL to navigate to")
    parser.add_argument("--timeout", type=int, default=DEFAULT_TIMEOUT, help="Timeout in seconds")
    args = parser.parse_args()
    # Extract the base URL from the WebSocket URL to use for API calls if not specified
    if args.ws_url and args.ws_url.startswith("ws://") and "--api-url" not in sys.argv:
        ws_parts = args.ws_url.split("/")
        if len(ws_parts) >= 3:
            args.api_url = f"http://{ws_parts[2]}"
            print(f"Using API URL derived from WebSocket URL: {args.api_url}")
    # Setup signal handlers
    loop = asyncio.get_running_loop()
    for sig in (signal.SIGINT, signal.SIGTERM):
        loop.add_signal_handler(sig, lambda: asyncio.create_task(shutdown(client)))
    # Create client
    client = EventSubscriptionClient(args.ws_url, args.timeout)
    # Connect to WebSocket server
    if not await client.connect():
        return 1
    # Subscribe to events
    subscription_id = await client.subscribe([
        "PAGE", "NETWORK", "CONSOLE", "DOM"
    ])
    if not subscription_id:
        await client.close()
        return 1
    # Navigate to test URL to generate events
    print(f"Navigating to {args.test_url}...")
    await navigate_to_page(args.api_url, args.test_url)
    # Listen for events
    print("Listening for events. Press Ctrl+C to exit.")
    await client.listen()
    # Cleanup
    await client.close()
    return 0
async def shutdown(client):
    """Shutdown gracefully"""
    print("Shutting down...")
    await client.close()
    tasks = [t for t in asyncio.all_tasks() if t is not asyncio.current_task()]
    [task.cancel() for task in tasks]
    await asyncio.gather(*tasks, return_exceptions=True)
    asyncio.get_event_loop().stop()
if __name__ == "__main__":
    sys.exit(asyncio.run(main()))
</file>

<file path="examples/README.md">
# MCP Browser Examples

This directory contains example scripts and applications that demonstrate how to use various features of the MCP Browser.

## Available Examples

### 1. WebSocket Event Subscription

**File:** `event_subscription_example.py`

This example demonstrates how to use the WebSocket event subscription feature to receive real-time browser events. The script:

- Connects to the MCP Browser WebSocket events endpoint
- Subscribes to specific event types (PAGE, NETWORK, CONSOLE, DOM)
- Navigates to a test URL to generate events
- Receives and displays browser events in real-time
- Handles graceful shutdown and cleanup

**Usage:**

```bash
# Run with default settings
python event_subscription_example.py

# Or customize with options
python event_subscription_example.py --ws-url ws://localhost:7665/ws/browser/events --test-url https://example.com --timeout 120
```

**Command-line Options:**

- `--ws-url`: WebSocket URL (default: ws://localhost:7665/ws/browser/events)
- `--api-url`: API URL (default: http://localhost:7665)
- `--test-url`: URL to navigate to (default: https://example.com)
- `--timeout`: Timeout in seconds (default: 60)

**Requirements:**

- websockets
- asyncio
- aiohttp
- json

Install with:
```bash
pip install websockets aiohttp
```

## Running the Examples

Before running any examples, make sure the MCP Browser server is running:

```bash
# Go to the MCP Browser root directory
cd /path/to/mcp-browser

# Start the server
python src/main.py
```

Then, in a separate terminal, you can run any of the examples as described above.

## Creating Your Own Examples

Feel free to use these examples as a starting point for your own applications. The key patterns demonstrated include:

1. **API Interaction**: How to call the HTTP API endpoints
2. **WebSocket Communication**: How to establish WebSocket connections and handle messages
3. **Event Subscription**: How to subscribe to browser events and process them
4. **Error Handling**: How to handle errors and gracefully shutdown
</file>

<file path="mcp-browser/docker/Dockerfile">
FROM mcr.microsoft.com/playwright:v1.51.1-noble
</file>

<file path="memory-bank/.neorules">
# NEO Rules for MCP Browser Project

## Project-Specific Patterns

1. **Docker-First Development**
   - Always test changes in Docker environment before committing
   - Use volume mounts for local development to speed up iteration
   - Keep Docker images slim by using multi-stage builds where appropriate

2. **Security Considerations**
   - Never run browser processes as root
   - Always use environment variables for secrets
   - Apply AppArmor profiles for all containers
   - Validate and sanitize all user inputs
   - Use virtual display server (Xvfb) for isolation

3. **Python Best Practices**
   - Use async/await for all IO operations
   - Type hint all functions for better IDE support
   - Use dataclasses for structured data
   - Prefer composition over inheritance
   - Use dependency injection for testability

4. **Playwright Usage Patterns**
   - Create isolated browser contexts for each session
   - Handle browser errors with structured error types
   - Use page.evaluate sparingly for better performance
   - Manage browser resources carefully (close pages when done)
   - Use stealth mode for more realistic browser behavior
   - Access browser_context.pages as a property, not a method (no await needed)
   - Always check if pages exist before accessing them
   - Handle parameters differently for element methods vs page methods

5. **MCP Protocol Extensions**
   - Follow existing MCP patterns for tool definitions
   - Return structured JSON for all responses
   - Use WebSockets for real-time events
   - Include metadata with all responses (timing, etc.)
   - Namespace browser-specific tools appropriately
   - Use consistent error handling with try/except blocks
   - Implement proper page navigation and lifecycle management
   - Use descriptive error messages for easier debugging

## User Preferences

1. **Code Organization**
   - Module structure: src/[module]/[feature].py
   - Test structure: tests/[module]/test_[feature].py
   - Separation of UI, business logic, and data access
   - Configuration via environment variables, not files
   - Documentation in Markdown format

2. **Testing Approach**
   - Unit tests for all core functionality
   - Integration tests for API endpoints
   - Browser tests run in a similar container environment
   - Mocking external dependencies for unit tests
   - Test coverage target: 80%+
   - Use test scripts for API endpoint verification
   - Save test results to output directory for later inspection

3. **Documentation Style**
   - RESTful API documented with OpenAPI
   - Code comments focus on "why" not "what"
   - README-driven development (write docs first)
   - Example scripts for common operations
   - Architecture diagrams in ASCII format for version control

4. **Deployment Preferences**
   - One-command deployment with Docker Compose
   - Environment-specific configuration via .env files
   - Health checks for all services
   - Graceful shutdown handling
   - Automatic restart capabilities

## Known Project Challenges

1. **Resource Management**
   - Browser automation can be memory-intensive
   - Monitor and adjust container resource limits
   - Consider pooling browser instances for efficiency
   - Implement garbage collection for abandoned sessions

2. **Cross-Platform Compatibility**
   - Local development on macOS, deployment on Linux
   - Xvfb doesn't work the same on all platforms
   - Use Docker to normalize environments
   - Document platform-specific quirks

3. **Security Balancing**
   - Need security, but also need browser functionality
   - AppArmor profiles need careful configuration
   - Balance between isolation and capabilities
   - Regular security scanning for dependencies

4. **Browser Automation Flakiness**
   - Handle intermittent failures gracefully
   - Implement retry mechanisms where appropriate
   - Add detailed logging for debugging
   - Use stable selectors for DOM elements

5. **Performance Considerations**
   - Browser startup time impacts user experience
   - Consider browser pooling for improved responsiveness
   - Optimize Docker image size for faster deployment
   - Cache Playwright browser downloads

## Learned Solutions

1. **Problem**: Xvfb doesn't work properly on macOS for local testing
   **Solution**: Use PLAYWRIGHT_SKIP_BROWSER_DOWNLOAD=1 environment variable and run in headless-only mode for local development on macOS

2. **Problem**: Docker container restart fails to clean up Xvfb processes
   **Solution**: Add trap handlers in xvfb-init.sh script to kill processes on exit signals

3. **Problem**: Playwright browser download is slow
   **Solution**: Use a specific browser (chromium only) instead of all browsers, and consider caching the download in a Docker volume

4. **Problem**: WebSocket connections terminate unexpectedly
   **Solution**: Implement ping/pong mechanism to keep connections alive and detect disconnections

5. **Problem**: Resource limits too restrictive
   **Solution**: Start with conservative limits and monitor actual usage, then adjust accordingly based on real-world metrics

6. **Problem**: JavaScript booleans in Playwright page.evaluate()
   **Solution**: Convert Python boolean values (True/False) to JavaScript boolean values (true/false) using str().lower() when injecting into JavaScript code

7. **Problem**: Complex DOM extraction and analysis
   **Solution**: Use f-strings to inject parameters into JavaScript functions rather than passing them as arguments to Playwright's evaluate method, which can be error-prone for complex structures

8. **Problem**: API testing and verification
   **Solution**: Create dedicated test endpoints that verify all API functionality, save results to output files, and provide detailed error reporting for easier debugging

9. **Problem**: Output file organization
   **Solution**: Create separate directories for each API output type (screenshots, DOM data, CSS analysis, etc.) and use timestamps in filenames to avoid conflicts

10. **Problem**: Cross-viewport testing
    **Solution**: Test responsive behavior by rendering the same page at different viewport sizes and comparing element properties and visibility

11. **Problem**: browser_context.pages access error "object list can't be used in 'await' expression"
    **Solution**: Access browser_context.pages as a property, not awaitable method. Use "pages = browser_context.pages" instead of "pages = await browser_context.pages"

12. **Problem**: Element screenshot with full_page parameter error
    **Solution**: Element screenshots don't support the full_page parameter. Use different parameter sets for page.screenshot() and element.screenshot()

13. **Problem**: Browser page initialization
    **Solution**: Always check if any pages exist before accessing them. Create a new page if none exist during navigation, handle empty page list gracefully in other endpoints

14. **Problem**: API query parameter handling vs body parameter handling
    **Solution**: For GET requests, use query parameters. For POST requests that need both URL and body parameters, support both input methods with clear parameter names 

## WebSocket Event Handling Patterns

1. **Separate Connection Management**: Keep WebSocket connections in separate collections based on their purpose.
   - `active_connections` for general control connections
   - `event_connections` for event subscription connections

2. **Unique Identifiers for Subscriptions**: Use unique identifiers for subscriptions with a descriptive prefix (e.g., `sub_` prefix for subscription IDs) to make them easily identifiable.

3. **Event Filtering Architecture**: Implement filtering as a separate function (`_matches_filters`) to allow flexible extension of filtering criteria.
   - URL pattern matching with regex
   - Page ID exact matching
   - Can be extended with additional filter types

4. **Broadcasting Strategy**: Use an async broadcast function that filters events before sending them to clients, avoiding unnecessary processing and network usage.

5. **Event Type Enumeration**: Use Enums for event types and event names to enforce consistency, make code more readable, and enable static checking.

6. **Subscription Handler Pattern**: Use a dictionary of event types to handler functions for dynamic event handling registration and unregistration.

7. **Client Message Structure**: For WebSocket client messages, use an "action" field to distinguish between different operations (subscribe, unsubscribe, list).

8. **Connection and Subscription Lifecycle**: 
   - Add connections to the active pool on connect
   - Remove connections and their subscriptions on disconnect
   - Send confirmation messages for subscription events
   - Handle errors gracefully with appropriate error messages
   
9. **Event Data Structure**: Include consistent fields in all events:
   - `type`: The event type (PAGE, DOM, CONSOLE, NETWORK)
   - `event`: Specific event name (e.g., "page.load", "console.error")
   - `timestamp`: When the event occurred
   - `data`: Event-specific details
   - `page_id`: (when applicable) Identifier for the source page

## API Endpoint Conventions

// ... existing code ...

## Response Formats

// ... existing code ...

## Testing and Debugging

// ... existing code ...

## File Organization

// ... existing code ...
</file>

<file path="memory-bank/active-context.md">
# Active Context - MCP Browser (v0.4.0)

## Current Focus Areas

1.  **Resource Mgmt**: Implement context/pool management & cleanup.
2.  **Security**: Implement rate limiting, granular AppArmor, network isolation.
3.  **Verification Agent**: Integrate static analysis, test automation, security checks.
4.  **Monitoring**: Integrate NetData, Loki+Grafana, cAdvisor.
5.  **DevEx**: API Docs (w/ examples), CLI tool, example scripts.

## Recent Changes

*   Core frontend analysis APIs completed.
*   MCP protocol extensions implemented.
*   WebSocket event subscriptions functional (with filtering).
*   Basic security (AppArmor, non-root) in place.
*   Core documentation structure established.
*   Analyzed current test infrastructure and identified gaps
*   Documented test coverage issues and technical debt
*   Created a comprehensive plan for test improvements

## Technical Debt / Must-Have Tasks (Summary)

*   **Resource Mgmt**: Context mgmt, cleanup, event perf.
*   **Security**: Rate limiting, AppArmor, network isolation.
*   **Verification**: Static analysis, test automation, security checks.
*   **Monitoring**: NetData, Loki+Grafana, cAdvisor integration.
*   **DevEx**: API docs, CLI tool, examples.

## Active Decisions / Strategy

*   **Resource Mgmt**: Use context pooling; optimize event broadcasting.
*   **Security**: Use FastAPI middleware for rate limits; Docker network isolation.
*   **Verification**: Use pytest; integrate tools like SonarQube.
*   **Monitoring**: Use NetData (system), Loki+Grafana (logs), cAdvisor (containers).
*   **DevEx**: Use FastAPI docs; Click/Typer for CLI.

## Open Questions / Blockers

*   Optimal context management strategy (pooling/cleanup)?
*   Efficient rate limiting details (limits, burst handling)?
*   Best static analysis/security tools to integrate?
*   Monitoring setup details (key metrics, alerting)?
*   *Blocker*: Need to implement Resource Mgmt (context/pooling) for stability.
*   *Blocker*: Need to implement Security (rate limiting, network isolation).
*   *Blocker*: Need to select and integrate Verification/Monitoring tools.

## Current Sprint Goals

1.  Implement browser context management.
2.  Add rate limiting & security enhancements.
3.  Integrate verification tools.
4.  Set up monitoring infrastructure.
5.  Enhance DevEx (docs, tools).

## Active Decisions
1. **Test Infrastructure Improvements**
   - Prioritize creating mock browser implementations for faster tests
   - Implement proper test isolation to prevent interference
   - Add test data management utilities for consistent testing

2. **Test Coverage Strategy**
   - Focus on critical areas first: browser pool initialization and cleanup
   - Implement concurrent operation tests to ensure thread safety
   - Add comprehensive error scenario tests

3. **Performance Optimization**
   - Implement browser instance reuse to reduce test execution time
   - Add parallel test execution support
   - Optimize test fixtures for better resource management

## Next Steps
1. Create mock browser implementation for testing
2. Implement test isolation mechanisms
3. Add test data management utilities
4. Document test patterns and best practices

## Open Questions
- What is the optimal balance between mock implementations and real browser testing?
- How to best handle test data management for different scenarios?
- What metrics should we track for test performance?

## Current Considerations
- Need to maintain test reliability while improving performance
- Balance between test coverage and execution time
- Documentation requirements for new test patterns

## Current Focus
Improving the testing infrastructure to enable proper test-driven development and ensure reliable browser pool operations.
</file>

<file path="memory-bank/mcp-browser-features.md">
# MCP Browser - Feature Implementation Plan

## 1. Frontend Analysis Capabilities

### 1.1 Screenshot Capture and Comparison

**Implementation Tasks:**
- Implement screenshot capture API endpoint
- Add viewport size configuration
- Create screenshot comparison utility
- Develop visual diff highlighting
- Implement pixel-based comparison metrics
- Add structural similarity index metrics
- Create screenshot storage and retrieval

**API Design:**
```python
@app.post("/api/screenshots/capture")
async def capture_screenshot(
    url: str, 
    viewport: dict = {"width": 1280, "height": 800},
    full_page: bool = True,
    format: str = "png",
    quality: Optional[int] = None,
    wait_until: str = "networkidle"
):
    """Capture a screenshot of a web page"""
    # Implementation
```

```python
@app.post("/api/screenshots/compare")
async def compare_screenshots(
    screenshot1_id: str,
    screenshot2_id: str,
    threshold: float = 0.1,
    highlight_diff: bool = True
):
    """Compare two screenshots and return diff metrics"""
    # Implementation
```

### 1.2 DOM State Analysis

**Implementation Tasks:**
- Implement DOM tree extraction
- Create element selector utilities
- Develop DOM comparison tools
- Add accessibility checking
- Implement CSS property extraction
- Create DOM search functionality
- Add viewport-specific DOM analysis

**API Design:**
```python
@app.post("/api/dom/extract")
async def extract_dom(
    url: str,
    selector: Optional[str] = None,
    include_styles: bool = False,
    include_attributes: bool = True
):
    """Extract DOM elements from a web page"""
    # Implementation
```

```python
@app.post("/api/dom/compare")
async def compare_dom(
    dom1_id: str,
    dom2_id: str,
    ignore_attributes: List[str] = ["id", "data-testid"]
):
    """Compare two DOM states and identify differences"""
    # Implementation
```

### 1.3 CSS Analysis

**Implementation Tasks:**
- Extract computed CSS properties for elements
- Analyze responsive design breakpoints
- Verify CSS consistency
- Check color contrast for accessibility
- Validate font sizes and readability
- Detect layout shifts and overflow issues

**API Design:**
```python
@app.post("/api/css/analyze")
async def analyze_css(
    url: str,
    selector: str,
    properties: Optional[List[str]] = None,
    check_accessibility: bool = False
):
    """Analyze CSS properties for selected elements"""
    # Implementation
```

### 1.4 Accessibility Analysis

**Implementation Tasks:**
- ✅ Implement accessibility testing API endpoint
- ✅ Add multiple standards support (WCAG, Section 508)
- ✅ Create selectors-based testing capability
- ✅ Add detailed violation reporting
- ✅ Implement HTML context inclusion for better debugging
- Add summary report generation
- Develop custom rule support

**API Design:**
```python
@app.post("/api/accessibility/test")
async def test_accessibility(
    url: str,
    standard: str = "wcag2aa",
    include_html: bool = True,
    include_warnings: bool = True,
    selectors: Optional[List[str]] = None
):
    """Test a web page for accessibility issues"""
    # Implementation
```

```python
@app.post("/api/accessibility/summary")
async def accessibility_summary(
    url: str,
    standards: List[str] = ["wcag2aa"],
    viewport_sizes: List[Dict[str, int]] = None
):
    """Generate a comprehensive accessibility summary across standards and viewport sizes"""
    # Implementation
```

### 1.5 Responsive Design Testing

**Implementation Tasks:**
- ✅ Create viewport size simulation
- ✅ Implement cross-device testing
- ✅ Add element visibility checking across viewports
- ✅ Develop media query detection
- ✅ Implement touch target size validation
- ✅ Create comparison mode for detecting responsive differences
- Add advanced layout shift detection

**API Design:**
```python
@app.post("/api/responsive/test")
async def test_responsive(
    url: str,
    viewports: List[Dict[str, int]] = None,
    selectors: Optional[List[str]] = None,
    include_screenshots: bool = True,
    compare_elements: bool = True
):
    """Test a web page across different viewport sizes"""
    # Implementation
```

```python
@app.post("/api/responsive/compare")
async def compare_responsive(
    url: str,
    device_presets: List[str] = ["mobile", "tablet", "desktop"],
    scenarios: List[Dict] = None
):
    """Compare a web page across different device presets with custom scenarios"""
    # Implementation
```

## 2. MCP Protocol Extensions

### 2.1 Browser-Specific MCP Tools

**Implementation Tasks:**
- Create MCP tool for browser navigation
- Implement page interaction tools (click, type, etc.)
- Develop DOM interaction tools
- Add screenshot and visual tools
- Create form interaction tools
- Implement browser automation tools

**API Design:**
```python
@mcp.tool()
async def browser_navigate(url: str, wait_until: str = "networkidle") -> Dict[str, Any]:
    """
    Navigate the browser to a URL
    
    Args:
        url: The URL to navigate to
        wait_until: Navigation condition to wait for
    
    Returns:
        Dictionary with navigation results
    """
    # Implementation
```

```python
@mcp.tool()
async def browser_click(selector: str, timeout: int = 30000) -> Dict[str, Any]:
    """
    Click an element on the page
    
    Args:
        selector: CSS selector for the element
        timeout: Maximum time to wait for element in ms
    
    Returns:
        Dictionary with click results
    """
    # Implementation
```

### 2.2 DOM Manipulation Tools

**Implementation Tasks:**
- Create element selection tools
- Implement form filling utilities
- Develop DOM traversal capabilities
- Add element property extraction
- Implement DOM modification tools
- Create shadow DOM handling utilities

**API Design:**
```python
@mcp.tool()
async def dom_extract(selector: str, include_html: bool = True) -> Dict[str, Any]:
    """
    Extract information about DOM elements
    
    Args:
        selector: CSS selector for elements to extract
        include_html: Whether to include HTML content
    
    Returns:
        Dictionary with DOM element data
    """
    # Implementation
```

### 2.3 Visual Analysis Tools

**Implementation Tasks:**
- Implement screenshot capture tools
- Create visual comparison utilities
- Develop visual element location tools
- Add image analysis capabilities
- Implement visual verification tools

**API Design:**
```python
@mcp.tool()
async def visual_capture(
    selector: Optional[str] = None, 
    full_page: bool = False
) -> Dict[str, Any]:
    """
    Capture a screenshot of the current page or element
    
    Args:
        selector: Optional CSS selector to capture specific element
        full_page: Whether to capture the full page
    
    Returns:
        Dictionary with screenshot data
    """
    # Implementation
```

### 2.4 WebSocket Event Subscriptions

**Implementation Tasks:**
- Create event subscription system
- Implement DOM mutation observers
- Develop network activity monitoring
- Add console log capturing
- Implement browser event forwarding

**API Design:**
```python
@app.websocket("/ws/events")
async def browser_events(websocket: WebSocket):
    """WebSocket endpoint for browser events"""
    await websocket.accept()
    
    try:
        # Register event subscriptions
        data = await websocket.receive_json()
        subscription_types = data.get("subscribe", [])
        
        # Setup event listeners
        
        # Main event loop
        while True:
            # Forward events as they occur
            pass
            
    except WebSocketDisconnect:
        # Cleanup
        pass
```

## 3. Verification Agent Integration

### 3.1 Static Analysis Integration

**Implementation Tasks:**
- Integrate Bandit for Python security analysis
- Add Semgrep for code pattern matching
- Implement ESLint for JavaScript analysis
- Create automated code review capabilities
- Develop security vulnerability scanning

**API Design:**
```python
@mcp.tool()
async def verify_code(
    code: str,
    language: str,
    rules: Optional[List[str]] = None
) -> Dict[str, Any]:
    """
    Verify code with static analysis
    
    Args:
        code: Source code to analyze
        language: Programming language (python, js, etc.)
        rules: Optional list of specific rules to check
    
    Returns:
        Dictionary with verification results
    """
    # Implementation
```

### 3.2 Unit Test Automation

**Implementation Tasks:**
- Create test generation capabilities
- Implement test runner integration
- Develop test result reporting
- Add test coverage analysis
- Implement regression test detection

**API Design:**
```python
@mcp.tool()
async def run_tests(
    test_path: str,
    test_runner: str = "pytest",
    timeout: int = 60
) -> Dict[str, Any]:
    """
    Run automated tests
    
    Args:
        test_path: Path to test files
        test_runner: Test framework to use
        timeout: Maximum test execution time
    
    Returns:
        Dictionary with test results
    """
    # Implementation
```

### 3.3 Security Checks

**Implementation Tasks:**
- Implement dependency vulnerability scanning
- Create XSS injection testing
- Develop CSRF protection verification
- Add content security policy checking
- Implement input validation testing

**API Design:**
```python
@mcp.tool()
async def security_scan(
    url: str,
    scan_type: str = "passive",
    max_depth: int = 3
) -> Dict[str, Any]:
    """
    Perform security checks on a web application
    
    Args:
        url: Target URL to scan
        scan_type: Type of scan (passive, active)
        max_depth: Maximum crawl depth
    
    Returns:
        Dictionary with security scan results
    """
    # Implementation
```

## 4. Monitoring and Metrics

### 4.1 NetData Integration

**Implementation Tasks:**
- Configure NetData for real-time metrics
- Implement custom metrics collectors
- Create dashboard for browser metrics
- Add resource usage monitoring
- Develop performance metrics visualization

**Implementation Details:**
- Install NetData in Docker environment
- Configure appropriate metrics collection
- Set up appropriate retention policies
- Create custom dashboards for browser metrics
- Implement alerting for resource thresholds

### 4.2 Loki + Grafana Setup

**Implementation Tasks:**
- Configure Loki log aggregation
- Set up Grafana dashboards
- Implement log parsing for browser events
- Create alert rules for errors
- Develop log visualization dashboards

**Implementation Details:**
- Add Loki and Grafana to Docker Compose setup
- Configure log forwarding from FastAPI and browser
- Create dashboards for error rates and patterns
- Implement alerting for critical errors
- Set up appropriate retention policies

### 4.3 cAdvisor Integration

**Implementation Tasks:**
- Configure cAdvisor for container insights
- Create container performance dashboards
- Implement resource usage monitoring
- Add container health checks
- Develop export mechanisms for metrics

**Implementation Details:**
- Add cAdvisor to Docker Compose setup
- Configure appropriate metrics collection
- Create dashboards for container performance
- Set up alerting for resource exhaustion
- Implement metrics export for historical analysis

## 5. Developer Experience

### 5.1 API Documentation

**Implementation Tasks:**
- Generate OpenAPI documentation
- Create usage examples for all endpoints
- Implement interactive API explorer
- Add error code documentation
- Develop authentication guides

**Implementation Details:**
- Use FastAPI's built-in OpenAPI generation
- Enhance docstrings for better documentation
- Create Swagger UI customization
- Add detailed examples for complex operations
- Implement playground for API testing

### 5.2 CLI Tool

**Implementation Tasks:**
- Create command-line interface for common operations
- Implement browser session management
- Develop test automation commands
- Add screenshot and visual testing capabilities
- Create reporting and export features

**Implementation Details:**
- Use Click or Typer for CLI framework
- Implement subcommands for different operation types
- Create progress indicators for long-running operations
- Add proper error handling and user feedback
- Implement configuration file support

### 5.3 Example Scripts

**Implementation Tasks:**
- Create example scripts for common use cases
- Implement tutorial notebooks
- Develop integration examples
- Add automation recipe collection
- Create debugging examples

**Implementation Details:**
- Organize examples by use case
- Provide well-documented code with comments
- Create step-by-step tutorials
- Implement real-world scenarios
- Add troubleshooting guides

## 6. Enhanced Security

### 6.1 Rate Limiting

**Implementation Tasks:**
- Implement API rate limiting
- Create rate limit configuration
- Develop rate limit bypass for authenticated users
- Add rate limit headers
- Implement rate limit logging

**Implementation Details:**
- Use FastAPI's middleware capabilities
- Create configurable rate limits per endpoint
- Implement token bucket algorithm
- Add appropriate headers for limit information
- Create monitoring for rate limit events

### 6.2 More Granular AppArmor Profiles

**Implementation Tasks:**
- Create specific AppArmor profiles for different components
- Implement resource access controls
- Develop network access restrictions
- Add file system isolation
- Create process execution controls

**Implementation Details:**
- Create separate profiles for browser and API server
- Implement least privilege principle
- Add specific resource access controls
- Test profiles for security and functionality
- Document profile configuration and management

### 6.3 Network Isolation

**Implementation Tasks:**
- Implement Docker network isolation
- Create network access controls
- Develop host protection mechanisms
- Add traffic monitoring
- Implement network security policies

**Implementation Details:**
- Configure Docker network isolation
- Implement appropriate firewall rules
- Create network segregation for components
- Add logging for network access attempts
- Document network security configuration
</file>

<file path="memory-bank/product-context.md">
# Product Context - MCP Browser

## Problem

*   AI agents need accurate, secure, resource-efficient browser testing.
*   Current solutions lack rendering fidelity, are resource-heavy, insecure, and complex to integrate.

## Solution: MCP Browser

*   Secure, efficient browser automation designed for AI agents (MCP).
*   Enables AI to interact with apps, capture visuals, inspect DOM/CSS, detect issues, verify responsive design.

## Target Users

*   **Primary**: AI Coding Agents (L3 via MCP).
*   **Secondary**: DevOps (Deployment, Security Config).
*   **Tertiary**: Developers/QA (Using AI test results).

## User Experience Goals

*   **AI Agents**: Seamless MCP control, rich rendering feedback, stable API.
*   **DevOps**: One-command deploy, simple config, monitoring, low maintenance.
*   **Developers**: Accurate issue reporting, detailed evidence for debugging.

## Business Value

*   Enhances AI frontend testing capabilities.
*   Reduces resource costs (>90% RAM saving vs full browsers).
*   Improves engineering efficiency (early bug detection).
*   Ensures rendering consistency.
*   Provides secure testing environment.

## Success Metrics (Key Targets)

*   **Performance**: < 3s startup, < 300MB RAM/instance, 99.9% uptime.
*   **User Success**: AI finds >95% visual issues, < 10min setup, 0 security escapes.
*   **Business**: Reduced missed frontend bugs, faster debug cycles, lower infra costs.
</file>

<file path="memory-bank/progress.md">
# Progress - MCP Browser (v0.4.0)

## Completed Features

*   **Core APIs**: Screenshot, DOM Extract, CSS Analyze, Accessibility Test, Responsive Test.
*   **MCP Extensions**: Browser Navigation, DOM Manipulation, Visual Analysis tools integrated.
*   **WebSocket Events**: Real-time PAGE, DOM, CONSOLE, NETWORK events with filtering.
*   **Basic Security**: AppArmor, Non-root execution, Basic API auth.
*   **Infrastructure**: Docker, Xvfb, Playwright, FastAPI, Basic scripts.

## Pending Tasks (Prioritized)

### High Priority (Must Have)

1.  **Resource Mgmt**: Browser context/pool mgmt, Resource cleanup, Perf optimization (high-volume events).
2.  **Security**: Rate limiting, Granular AppArmor, Network isolation improvements.
3.  **Verification Agent**: Static analysis integration, Test automation, Security checks.
4.  **Monitoring**: NetData, Loki+Grafana, cAdvisor integration.
5.  **DevEx**: API docs (w/ examples), CLI tool, Example scripts.

### Medium Priority

1.  **Network Features**: Interception/modification, Cookie/storage mgmt, Perf metrics.
2.  **Testing**: Comprehensive coverage (Integration, Performance).
3.  **Error Handling**: Standardized responses, Better reporting, Graceful degradation.

## Current Status Summary

Core features implemented. Focus now on resource management, security, verification, monitoring, and DevEx.

## Known Issues / Blockers

| Issue                      | Severity | Status      | Notes                                        |
| :------------------------- | :------- | :---------- | :------------------------------------------- |
| Resource Management        | High     | In Progress | Context mgmt needed for stability/perf       |
| Rate Limiting              | High     | To Address  | Missing on API endpoints                     |
| Network Isolation          | High     | To Address  | Docker network rules need improvement      |
| Static Analysis Integration| High     | To Address  | Need to integrate tools (e.g., SonarQube)    |
| Monitoring Setup           | High     | To Address  | Tools (NetData, Loki, etc.) need integration |
| API Documentation          | Medium   | To Address  | Needs examples                               |
| Standardized Errors        | Medium   | To Address  | Current handling is basic                    |
| Event Broadcasting Perf    | Medium   | To Address  | Optimize for high load                       |

## Progress Checklist

*   [x] Project structure
*   [x] Basic FastAPI server
*   [x] Playwright integration
*   [x] WebSocket interface
*   [x] Core Frontend Analysis APIs
*   [x] MCP Protocol Extensions
*   [x] Basic Security (AppArmor, non-root)
*   [ ] Resource Management (Context/Pooling/Cleanup)
*   [ ] Security Enhancements (Rate Limit, Net Isolation)
*   [ ] Verification Agent (Static Analysis, Tests)
*   [ ] Monitoring Integration (NetData, Loki, etc.)
*   [ ] Developer Experience (Docs, CLI, Examples)

## Next Milestones (Target)

*   **April 2024**: Complete resource management.
*   **May 2024**: Implement security enhancements.
*   **May 2024**: Integrate verification tools.
*   **June 2024**: Set up monitoring infrastructure.
*   **June 2024**: Enhance developer experience.
*   **July 2024**: Production readiness.

## Progress Tracking

## Current State

### Testing Infrastructure
- Basic test setup with pytest and pytest-asyncio
- Core fixtures for browser pool and context management
- Tests for resource management and network isolation
- Logging configured for test execution

### Identified Issues

1. **Test Coverage Gaps**
   - Missing tests for browser pool initialization and cleanup
   - Incomplete coverage of error handling scenarios
   - No tests for concurrent browser operations
   - Limited testing of resource monitoring and limits

2. **Testing Infrastructure Limitations**
   - No mock implementations for browser operations
   - Heavy reliance on real browser instances
   - Long test execution times due to browser startup
   - Limited isolation between test cases

3. **Technical Debt**
   - Complex test fixtures with manual cleanup
   - Inconsistent error handling in test teardown
   - No standardized approach for test data management
   - Missing documentation for test patterns

## Next Steps

1. **Improve Test Infrastructure**
   - [ ] Create mock browser implementations for faster tests
   - [ ] Implement proper test isolation
   - [ ] Add test data management utilities
   - [ ] Document test patterns and best practices

2. **Enhance Test Coverage**
   - [ ] Add tests for browser pool initialization
   - [ ] Implement concurrent operation tests
   - [ ] Add error scenario tests
   - [ ] Improve resource monitoring tests

3. **Optimize Test Performance**
   - [ ] Implement browser instance reuse
   - [ ] Add parallel test execution
   - [ ] Optimize test fixtures
   - [ ] Add test timeouts and cleanup

4. **Documentation and Standards**
   - [ ] Create test documentation
   - [ ] Define test patterns
   - [ ] Document fixture usage
   - [ ] Add test contribution guidelines

## Current Focus
Improving test infrastructure and coverage to enable proper test-driven development.
</file>

<file path="memory-bank/project-brief.md">
# Project Brief - MCP Browser

## Overview

*   **Purpose**: Enterprise-grade secure browser automation for L3 AI coding agents.
*   **Function**: Enables AI agents to test frontends, evaluate rendering, and identify issues in real browsers.

## Core Requirements (Summarized)

1.  **Platform**: Headless browser (Playwright/Chromium) via Xvfb.
2.  **Security**: AppArmor, non-root, resource limits, env secrets, isolated display.
3.  **Deployment**: One-command deploy (Docker), resource pooling.
4.  **Verification**: Static analysis, automated tests (CI), security checks.
5.  **Agent Integration**: MCP via WebSockets/API, screenshot/DOM analysis.

## Architecture Sketch

```mermaid
graph TD
    A[AI Agent] -->|MCP/SSH| B(MCP Browser Service);
    subgraph Docker Host [Older Mac/Linux PC]
      direction LR
      B --> C{Playwright};
      C --> D[Headless Chromium];
      D --> E(Xvfb);
      B --> F(Security Sandbox/AppArmor);
      B --> G(Resource Monitor);
    end
```

## Success Criteria

*   One-command deployment.
*   Secure container isolation.
*   Accurate rendering analysis.
*   Resource efficient (target < 300MB RAM/instance).
*   AI agents can effectively identify frontend issues.

## Out of Scope

*   Interactive UI for humans.
*   Browser extension management.
*   Multi-user session management.
*   Advanced anti-detection features.
</file>

<file path="memory-bank/system-patterns.md">
# System Architecture & Patterns - MCP Browser

## Architecture Overview

*   FastAPI app bridging clients (L3 AI Agents via MCP) and Playwright (headless browser).
*   Modular: HTTP API, WebSocket, Browser Control, Error Handling, Data Processing layers.

```mermaid
graph TD
    A[L3 AI Agent] -->|MCP over SSH| C(MCP Browser Service);
    C -->|Playwright API| D(Playwright Engine);
    D -->|Browser Control| E(Headless Chromium);
    E -->|Render via| F(Xvfb Virtual Display);
    C --> G(Resource Monitor);
    C --> H(Security Sandbox);
    subgraph "Docker Container" 
        direction LR
        C; D; E; F; G; H;
    end
```

## Key Components & Responsibilities

*   **MCP Browser Service (FastAPI)**: Manage sessions, process MCP commands, return output, log, handle security.
*   **Playwright Engine**: Launch/manage browser, execute actions, capture state.
*   **Xvfb Display**: Provide X11 env for headless browser, enable visual ops.
*   **Docker Container**: Consistent/isolated environment, resource mgmt, security boundaries.
*   **SSH Tunnel**: Secure remote access & encryption.

## Design Patterns Employed

*   **Microservice**: Single responsibility components, defined interfaces.
*   **Command**: Browser ops as commands (serialized, validated, executed).
*   **Observer**: WebSockets for real-time state updates (pub/sub).
*   **Factory**: Browser instance creation & config management.
*   **REST API**: Resource-oriented endpoints, JSON payloads, consistent responses.
*   **WebSocket**: Connection pool, pub/sub management, event filtering (URL, page ID).
*   **Facade**: Simplified browser control interface over Playwright complexity.
*   **Error Handling**: Standardized structure (code, msg), detailed logging.

## Data Flow Summary

1.  Agent sends MCP command (via SSH).
2.  Service receives/validates.
3.  Translates to Playwright op.
4.  Playwright executes in Chromium (via Xvfb).
5.  Results captured (DOM, screenshot, etc.).
6.  Service formats/returns results.
7.  Operation logged.

## Security Architecture (Defense-in-Depth)

*   **Network**: SSH Tunnel encryption, Firewall rules, Rate limiting.
*   **Application**: JWT Auth, Input validation/sanitization.
*   **Container**: AppArmor, Non-root user, Resource quotas.
*   **Browser**: Isolated contexts, No persistent storage, Network restrictions (planned).

## Key Technical Decisions & Rationale

*   **Playwright**: Reliability, cross-browser, modern API, performance.
*   **Chromium**: Best compatibility, perf, dev tools, security updates.
*   **Docker**: Consistency, isolation, dependency mgmt, scaling.
*   **FastAPI**: Async perf, auto-docs, type safety, WebSocket support.
*   **Xvfb**: Lightweight, no GPU needed, stable for headless.

## Core API Endpoint Examples (Structure)

*   `/api/screenshots/capture` (POST)
*   `/api/dom/extract` (POST)
*   `/api/css/analyze` (POST)
*   `/api/accessibility/test` (POST)
*   `/api/responsive/test` (POST)
*   `/api/browser/navigate` (POST)
*   `/api/browser/click` (POST)
*   `/api/events/subscribe` (WebSocket)

*(Detailed request/response schemas available in OpenAPI docs/code)*
</file>

<file path="memory-bank/tech-context.md">
# Technical Context - MCP Browser

## Core Stack

*   **Language/Framework**: Python 3.13+, FastAPI
*   **Browser Automation**: Playwright (>=1.51.0) with Chromium
*   **Infrastructure**: Docker (+Compose), Xvfb, AppArmor
*   **Comms**: WebSockets (>=15.0.1), HTTPS (via Uvicorn)
*   **Package Manager**: uv

## Key Dependencies

*   **Core**: `fastapi` (>=0.108.0), `playwright` (>=1.51.0), `uvicorn[standard]` (>=0.24.0), `websockets` (>=15.0.1), `psutil`, `pydantic` (>=2.0.0), `docker`
*   **Security**: `python-jose` (>=3.4.0) (JWT), `passlib[bcrypt]` (>=1.7.4)
*   **Utils**: `aiohttp` (>=3.11.14), `pyyaml` (>=6.0), `httpx` (>=0.28.1), `aiofiles` (>=24.1.0)
*   **Testing**: `pytest` (>=8.2.0), `pytest-asyncio` (==0.25.3), `pytest-cov` (==4.1.0), `pytest-timeout`

## Dev Environment Setup

*   **Prereqs**: Python 3.13+, Docker, uv, Git
*   **Structure**: `src/`, `tests/`, `docker/`, `Dockerfile`, `docker-compose.yml`, `pyproject.toml` (`requirements-test.txt` for test deps)
*   **Init**:
    ```bash
    git clone <repo_url>
    cd mcp-browser
    uv venv .venv
    source .venv/bin/activate
    uv pip install -e . # Installs project dependencies from pyproject.toml
    uv pip install -r requirements-test.txt # Installs test dependencies
    python -m playwright install chromium # Install browser if needed
    # For Docker-based dev:
    # docker-compose up -d
    ```
*   **Testing**: `pytest tests/` or via `make` targets

## Technical Constraints

*   **Python Version**: >= 3.13 required due to dependencies/features.
*   **Target Hardware**: Resource efficiency is critical (target < 300MB RAM/instance).
*   **Security**: Non-root execution, AppArmor enforcement, resource limits mandatory.
*   **Network**: SSH tunnel required for remote access in some deployment models.
*   **Browser**: Primarily targets Chromium via Playwright.

## Monitoring Stack (Planned)

*   **System**: NetData
*   **Logs**: Loki + Grafana
*   **Containers**: cAdvisor

## Deployment

*   **Primary**: Docker Compose (`docker-compose.yml`) for local/production.
*   **Environment**: Configured via `.env` file (see `.env.example`).

## Security Layers

*   **Network**: SSH Tunnel (optional), Firewall rules, Rate Limiting (FastAPI middleware).
*   **Application**: JWT Auth (planned), Input validation (Pydantic).
*   **Container**: AppArmor profiles (`docker/apparmor/`), Non-root user, Docker resource quotas.
*   **Browser**: Isolated contexts, Xvfb sandbox, Network restrictions (via `BrowserPool` config).

## API Design Principles

*   **Request**: Pydantic models for validation, required `url`.
*   **Response**: Consistent JSON structure (status, metadata, result/file ref).
*   **Error**: Standard HTTP codes, detailed JSON body, server-side logging.
*   **Docs**: Auto-generated via FastAPI (OpenAPI).

## Testing Strategy

*   **Framework**: Pytest
*   **Types**: Unit, Integration (mocking), E2E (real sites).
*   **Tools**: `pytest-asyncio`, `pytest-cov`, `pytest-timeout`.

## Development Environment

### Prerequisites
- Python 3.13+
- Docker and Docker Compose
- uv package manager
- (Optional) Xvfb or XQuartz for local testing

### Project Structure
```
mcp-browser/
├── docker/                 # Docker-related files
│   ├── apparmor/           # AppArmor security profiles
│   └── xvfb-init.sh        # Xvfb initialization script
├── src/                    # Source code
│   ├── __init__.py         # Package initialization 
│   └── main.py             # Main application code
├── tests/                  # Test suite
├── .dockerignore           # Docker ignore patterns
├── .env.example            # Environment variable templates
├── .gitignore              # Git ignore patterns
├── Dockerfile              # Docker build definition
├── docker-compose.yml      # Docker Compose configuration
├── pyproject.toml          # Python project metadata
├── README.md               # Project documentation
├── run.sh                  # Deployment script
└── simple_test.sh          # Local testing script
```

## Technologies Used

### Core Technologies

| Technology | Version | Purpose |
|------------|---------|---------|
| Python | 3.9+ | Primary programming language |
| FastAPI | 0.95.0+ | Web framework for API development |
| Uvicorn | 0.22.0+ | ASGI server for FastAPI |
| Playwright | 1.32.0+ | Browser automation for web page analysis |
| Docker | 20.10.0+ | Containerization for consistent environments |
| Xvfb | 1.20.0+ | Virtual framebuffer for headless browser |

### Frontend Analysis Dependencies

| Technology | Version | Purpose |
|------------|---------|---------|
| axe-core | 4.7.0+ | Accessibility testing and standards compliance |
| PIL (Pillow) | 9.5.0+ | Image processing for screenshots |
| BeautifulSoup | 4.12.0+ | HTML parsing and DOM operations |
| pydantic | 1.10.7+ | Data validation and settings management |
| pytest | 7.3.1+ | Test framework for API validation |

### Support Tools

| Technology | Version | Purpose |
|------------|---------|---------|
| GitHub Actions | N/A | CI/CD platform for automated testing |
| pre-commit | 3.3.1+ | Git hooks for code quality |
| black | 23.3.0+ | Code formatting |
| flake8 | 6.0.0+ | Code linting |
| mypy | 1.3.0+ | Static type checking |

## Development Environment

### Local Development Setup

1. **Prerequisites**:
   - Docker and Docker Compose
   - Python 3.9+
   - Git

2. **Environment Initialization**:
   ```bash
   # Clone repository
   git clone https://github.com/your-org/mcp-browser.git
   cd mcp-browser
   
   # Build and start Docker containers
   docker-compose up -d
   
   # Run the API server
   python -m scripts.run
   ```

3. **Testing Environment**:
   ```bash
   # Run tests
   pytest tests/
   
   # Run tests with coverage
   pytest --cov=app tests/
   ```

### Docker Environment

The Docker setup includes:

1. **Base Image**: Python 3.9-slim
2. **Browser Layer**: Playwright browsers installation
3. **Virtual Display**: Xvfb configuration
4. **Application Layer**: Application code and dependencies
5. **Output Volumes**: Mounted volumes for persistent output

The Dockerfile implements multi-stage building to minimize image size.

## API Design

### Request/Response Patterns

All API endpoints follow a consistent pattern:

1. **Request Structure**:
   - Required parameters: `url` (the target website)
   - Optional parameters: endpoint-specific configuration
   - Validation: Pydantic models for type safety

2. **Response Structure**:
   - Status information
   - Execution metadata (timing, browser info)
   - Result data in JSON format
   - File references for generated artifacts

3. **Error Handling**:
   - HTTP status codes for error categories
   - Detailed error messages in response body
   - Logging for debugging purposes

### API Data Flow

```
Request → Validation → Browser Setup → Page Navigation → Analysis → Result Processing → Response
```

### Authentication and Security

Current implementation uses:

1. API keys for basic authentication
2. Rate limiting by client IP
3. Input validation for all parameters
4. Timeout controls for browser operations
5. Resource limits in Docker container

## Testing Framework

The testing framework includes:

1. **Unit Tests**: Testing individual components and utilities
2. **Integration Tests**: Testing API endpoints with mock server
3. **End-to-End Tests**: Testing complete workflows with real websites
4. **Performance Tests**: Testing response times and resource usage

Test data includes a set of reference websites with known properties. 

## Technologies Used

### Core Technologies

- **Python 3.13+**: Primary programming language
- **FastAPI**: Web framework for building APIs
- **Playwright**: Browser automation library
- **Pydantic**: Data validation and settings management
- **Uvicorn**: ASGI server implementation
- **WebSockets**: Protocol for real-time communication
- **asyncio**: Asynchronous I/O library for concurrent code

### Supporting Libraries

- **websockets**: Python library for WebSocket client/server implementation
- **uuid**: Library for generating unique identifiers
- **aiohttp**: Asynchronous HTTP client/server framework
- **json**: JSON encoding/decoding
- **httpx**: Fully asynchronous HTTP client
- **aiofiles**: Asynchronous file operations

### Development Tools

- **uv**: Fast Python package installer
- **Docker**: Containerization
- **Xvfb**: Virtual framebuffer for X11 (for headless environments)
- **pytest**: Testing framework
- **autopep8**: Code formatter

## Development Setup

The project requires:

1. Python 3.13 or higher
2. uv for dependency management
3. Playwright browsers installed

Setup commands:
```bash
uv venv .venv
source .venv/bin/activate
uv pip install -e .
python -m playwright install
```

## Technical Constraints

1. **Browser Compatibility**: The system targets Chromium-based browsers for consistent behavior.
2. **Memory Usage**: Browser automation is memory-intensive, requiring at least 2GB RAM.
3. **Event Broadcasting**: WebSocket connections for event subscriptions require consideration for scaling.
4. **Asynchronous Architecture**: All components must be designed to work in an asynchronous environment.

## Dependencies

### Core Dependencies

```
fastapi>=0.97.0
playwright>=1.40.0
uvicorn>=0.22.0
pydantic>=2.0.0
websockets>=11.0.3
```

### Test Dependencies

```
pytest>=7.0.0
httpx>=0.24.1
pytest-asyncio>=0.21.1
```

## Configuration

Key environment variables:
- `SERVER_PORT`: Web server port (default: 7665)
- `PLAYWRIGHT_SKIP_BROWSER_DOWNLOAD`: Skip browser download for headless mode
- `MCP_SECRET`: Secret key for MCP authentication

## Deployment

The application supports:
1. Local development environment
2. Docker containerized deployment
3. Production deployment with appropriate scaling

## Third-Party Integrations

The system is designed to integrate with:
1. **MCP**: For AI agent communication
2. **External services**: Via the HTTP API
3. **Client applications**: Via WebSockets and HTTP API
</file>

<file path="src/__init__.py">
"""
MCP Browser - A browser interface for MCP (Model Control Protocol)
"""
__version__ = "0.1.0"
</file>

<file path="src/browser_pool.py">
#!/usr/bin/env python3
"""
Browser Pool for MCP Browser
This module provides a pool of browser instances for efficient resource management.
"""
import os
import asyncio
import logging
from typing import Dict, List, Optional, Any, Set
import time
import uuid
import psutil
from playwright.async_api import async_playwright, Browser, BrowserContext
from src.error_handler import MCPBrowserException, ErrorCode
# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("browser-pool")
class BrowserInstance:
    """Represents a browser instance in the pool"""
    def __init__(self, instance_id: str, allowed_domains: Set[str] = None, blocked_domains: Set[str] = None, network_isolation: bool = True):
        """
        Initialize a browser instance
        Args:
            instance_id: Unique identifier for this browser instance
            allowed_domains: Set of domains allowed for network access
            blocked_domains: Set of domains explicitly blocked
            network_isolation: Whether network isolation is enabled
        """
        self.id = instance_id
        self.contexts: Dict[str, BrowserContext] = {}
        self.last_used = time.time()
        self.browser: Optional[Browser] = None
        self.is_closing = False
        self._playwright = None
        self.network_isolation = network_isolation
        self.allowed_domains = allowed_domains or set()
        self.blocked_domains = blocked_domains or set()
        logger.info(f"Created browser instance {self.id} with network isolation: {self.network_isolation}")
        if self.network_isolation:
            logger.info(f"Allowed domains: {self.allowed_domains}")
            logger.info(f"Blocked domains: {self.blocked_domains}")
    async def initialize(self):
        """Initialize the browser instance with Playwright"""
        try:
            logger.info(f"Initializing browser instance {self.id}")
            self._playwright = await async_playwright().start()
            # Launch browser with resource constraints and isolation args
            launch_args = [
                '--disable-dev-shm-usage',  # Avoid /dev/shm issues in Docker
                '--no-sandbox',  # Required for Docker
                '--disable-gpu',  # Reduce resource usage
                '--disable-software-rasterizer',  # Reduce memory usage
                '--disable-extensions',  # Disable extensions
                f'--js-flags=--max-old-space-size={256}',  # Limit JS heap
            ]
            if self.network_isolation:
                 # Experimental flags, might change based on Chromium version
                 launch_args.extend([
                     '--disable-features=NetworkService,NetworkServiceInProcess',
                     '--disable-background-networking',
                     '--disable-sync',
                     '--disable-default-apps',
                     '--disable-breakpad', # Disable crash reporting
                     '--disable-component-extensions-with-background-pages',
                     '--disable-component-update',
                     '--disable-domain-reliability',
                     '--disable-client-side-phishing-detection',
                     '--disable-sync-preferences',
                     '--enable-strict-mixed-content-checking',
                     '--use-mock-keychain', # Prevent keychain access
                 ])
            self.browser = await self._playwright.chromium.launch(
                args=launch_args,
                handle_sigint=True,
                handle_sigterm=True,
                handle_sighup=True
            )
            # Get browser process for monitoring - Removed as browser.process is not available/reliable
            # if self.browser and hasattr(self.browser, 'process') and self.browser.process:
            #      try:
            #           self.process = psutil.Process(self.browser.process.pid)
            #           logger.info(f"Browser instance {self.id} initialized with PID {self.process.pid}")
            #      except (psutil.NoSuchProcess, AttributeError) as e:
            #            logger.warning(f"Could not get process info for browser {self.id}: {e}")
            #            self.process = None
            # else:
            #      logger.warning(f"Browser instance {self.id} started but process info unavailable.")
            logger.info(f"Browser instance {self.id} initialized successfully.")
            return self.browser
        except Exception as e:
            logger.error(f"Failed to initialize browser instance {self.id}: {str(e)}")
            await self.close() # Attempt cleanup on failure
            raise MCPBrowserException(
                error_code=ErrorCode.BROWSER_INITIALIZATION_FAILED,
                message=f"Failed to initialize browser: {str(e)}",
                original_exception=e
            )
    async def create_context(self, context_id: str, **kwargs) -> BrowserContext:
        """
        Create a new browser context with resource limits and network isolation
        Args:
            context_id: Unique identifier for this context
            **kwargs: Additional context options
        Returns:
            Browser context object
        """
        if not self.browser:
             raise MCPBrowserException(ErrorCode.BROWSER_NOT_INITIALIZED, f"Browser {self.id} is not initialized.")
        try:
            logger.info(f"Creating context {context_id} in browser {self.id}")
            # Set default viewport and device scale factor
            context_params = {
                "viewport": {"width": 1280, "height": 720},
                "device_scale_factor": 1,
                "bypass_csp": True,  # Allow running scripts
                "java_script_enabled": True,
                **kwargs
            }
            # Apply network isolation settings
            if self.network_isolation:
                context_params.update({
                    "ignore_https_errors": False,  # Enforce HTTPS
                    "extra_http_headers": {
                        "X-Isolated-Context": "true"  # Mark as isolated
                    }
                })
            # Create the context with resource limits
            context = await self.browser.new_context(**context_params)
            # Set up network request interception if isolation is enabled
            if self.network_isolation:
                 logger.info(f"Enabling network request interception for context {context_id} in browser {self.id}")
                 await context.route("**/*", self._handle_route)
            # Set default timeout
            context.set_default_timeout(30000)
            # Store the context
            self.contexts[context_id] = context
            self.last_used = time.time()
            logger.info(f"Context {context_id} created successfully in browser {self.id}")
            return context
        except Exception as e:
            logger.error(f"Failed to create context {context_id} in browser {self.id}: {str(e)}")
            # Attempt to close context if creation failed mid-way
            if 'context' in locals() and context:
                try:
                    await context.close()
                except Exception as close_exc:
                     logger.error(f"Error closing partially created context {context_id}: {close_exc}")
            raise MCPBrowserException(
                error_code=ErrorCode.CONTEXT_CREATION_FAILED,
                message=f"Failed to create browser context {context_id}: {str(e)}",
                original_exception=e
            )
    async def close_context(self, context_id: str):
        """
        Close a browser context and clean up resources
        Args:
            context_id: ID of the context to close
        """
        if context_id not in self.contexts:
            logger.warning(f"Context {context_id} not found in browser {self.id}")
            return
        try:
            logger.info(f"Closing context {context_id} in browser {self.id}")
            context = self.contexts[context_id]
            # Close all pages in the context
            for page in context.pages:
                try:
                    await page.close()
                except Exception as e:
                    logger.warning(f"Error closing page in context {context_id}: {str(e)}")
            # Close the context
            await context.close()
            del self.contexts[context_id]
            self.last_used = time.time()
        except Exception as e:
            logger.error(f"Error closing context {context_id}: {str(e)}")
            # Still remove from tracking
            if context_id in self.contexts:
                del self.contexts[context_id]
    async def close(self):
        """Close the browser instance and clean up all resources"""
        if self.is_closing:
            logger.info(f"[Browser {self.id}] Already closing, skipping")
            return
        self.is_closing = True
        logger.info(f"[Browser {self.id}] Starting close process")
        try:
            # Close all contexts
            context_ids = list(self.contexts.keys())
            if context_ids:
                logger.info(f"[Browser {self.id}] Closing {len(context_ids)} contexts: {context_ids}")
                for context_id in context_ids:
                    try:
                        logger.info(f"[Browser {self.id}] Closing context {context_id}")
                        await self.close_context(context_id)
                        logger.info(f"[Browser {self.id}] Successfully closed context {context_id}")
                    except Exception as e:
                        logger.error(f"[Browser {self.id}] Error closing context {context_id}: {e}", exc_info=True)
            else:
                logger.info(f"[Browser {self.id}] No contexts to close")
            # Close browser
            if self.browser:
                logger.info(f"[Browser {self.id}] Closing browser process")
                try:
                    await self.browser.close()
                    logger.info(f"[Browser {self.id}] Successfully closed browser process")
                except Exception as e:
                    logger.error(f"[Browser {self.id}] Error closing browser process: {e}", exc_info=True)
                finally:
                    self.browser = None
            # Stop playwright
            if self._playwright:
                logger.info(f"[Browser {self.id}] Stopping playwright")
                try:
                    await self._playwright.stop()
                    logger.info(f"[Browser {self.id}] Successfully stopped playwright")
                except Exception as e:
                    logger.error(f"[Browser {self.id}] Error stopping playwright: {e}", exc_info=True)
                finally:
                    self._playwright = None
            logger.info(f"[Browser {self.id}] Close process completed successfully")
        except Exception as e:
            logger.error(f"[Browser {self.id}] Error during close process: {e}", exc_info=True)
            raise MCPBrowserException(
                error_code=ErrorCode.BROWSER_CLEANUP_FAILED,
                message=f"Failed to clean up browser resources: {str(e)}",
                original_exception=e
            )
    async def _handle_route(self, route):
        """Intercept and handle network requests based on isolation rules."""
        request = route.request
        url = request.url
        domain = url.split('/')[2].split(':')[0] # Extract domain name
        if domain in self.blocked_domains:
            logger.warning(f"Blocked request to {domain} (explicitly blocked) in browser {self.id}")
            await route.abort("blockedbyclient")
            return
        # If allowed_domains is defined, only allow those domains
        if self.allowed_domains and domain not in self.allowed_domains:
            logger.warning(f"Blocked request to {domain} (not in allowed list) in browser {self.id}")
            await route.abort("blockedbyclient")
            return
        # Allow the request if it's not blocked and either allowed_domains is empty or the domain is in the list
        logger.debug(f"Allowed request to {url} in browser {self.id}")
        await route.continue_()
class BrowserPool:
    """Manages a pool of browser instances"""
    def __init__(self, 
                 max_browsers: int = 5, 
                 idle_timeout: int = 300, 
                 max_memory_percent: float = 80.0, 
                 max_cpu_percent: float = 80.0, 
                 monitor_interval: int = 60,
                 network_isolation: bool = True,
                 allowed_domains: Optional[List[str]] = None,
                 blocked_domains: Optional[List[str]] = None):
        """
        Initialize the browser pool
        Args:
            max_browsers: Maximum number of concurrent browser instances
            idle_timeout: Time in seconds before an idle browser is closed
            max_memory_percent: Maximum system memory usage percentage allowed
            max_cpu_percent: Maximum system CPU usage percentage allowed
            monitor_interval: Interval in seconds for resource monitoring task
            network_isolation: Enable network isolation features
            allowed_domains: List of domains allowed for network access
            blocked_domains: List of domains explicitly blocked
        """
        logger.info("[Pool] Initializing browser pool")
        self.max_browsers = max_browsers
        self.idle_timeout = idle_timeout
        self.max_memory_percent = max_memory_percent
        self.max_cpu_percent = max_cpu_percent
        self.monitor_interval = monitor_interval
        self.browsers: Dict[str, BrowserInstance] = {}
        self.lock = asyncio.Lock()
        self._monitor_task_handle: Optional[asyncio.Task] = None
        self._shutting_down = False
        # Network Isolation Settings
        self.network_isolation = network_isolation
        self.allowed_domains: Set[str] = set(allowed_domains) if allowed_domains else set()
        self.blocked_domains: Set[str] = set(blocked_domains) if blocked_domains else set()
        logger.info(f"[Pool] Browser Pool initialized with:")
        logger.info(f"[Pool]   Max Browsers: {self.max_browsers}")
        logger.info(f"[Pool]   Idle Timeout: {self.idle_timeout}s")
        logger.info(f"[Pool]   Max Memory: {self.max_memory_percent}%")
        logger.info(f"[Pool]   Max CPU: {self.max_cpu_percent}%")
        logger.info(f"[Pool]   Monitor Interval: {self.monitor_interval}s")
        logger.info(f"[Pool]   Network Isolation: {self.network_isolation}")
        if self.network_isolation:
            logger.info(f"[Pool]   Allowed Domains: {self.allowed_domains if self.allowed_domains else 'Any (if not blocked)'}")
            logger.info(f"[Pool]   Blocked Domains: {self.blocked_domains if self.blocked_domains else 'None'}")
        logger.info("[Pool] Initialization complete")
    async def start(self):
        """Start the browser pool and monitoring tasks"""
        logger.info("Starting browser pool")
        self.start_monitoring()
    async def stop(self):
        """Stop the browser pool and clean up all resources"""
        logger.info("Stopping browser pool")
        # Cancel monitoring tasks
        if self._monitor_task_handle and not self._monitor_task_handle.done():
            self._monitor_task_handle.cancel()
            try:
                await self._monitor_task_handle
            except asyncio.CancelledError:
                logger.info("Monitoring task successfully cancelled.")
            except Exception as e:
                logger.error(f"Error during monitor task cancellation: {e}")
        # Close all browsers
        async with self.lock:
            for browser_id in list(self.browsers.keys()):
                await self.close_browser(browser_id)
        logger.info("Browser pool stopped")
    def _get_system_metrics(self) -> Dict[str, float]:
        """Get current system resource usage"""
        return {
            "memory_percent": psutil.virtual_memory().percent,
            "cpu_percent": psutil.cpu_percent(interval=1)
        }
    async def _check_resource_limits(self) -> bool:
        """Check if system resource usage is within limits."""
        metrics = self._get_system_metrics()
        memory_usage = metrics["memory_percent"]
        cpu_usage = metrics["cpu_percent"]
        if memory_usage > self.max_memory_percent:
            logger.warning(f"Memory usage high: {memory_usage:.2f}% (Limit: {self.max_memory_percent}%)")
            await self._close_idle_browsers(force_check=True)
            # Recheck after cleanup
            memory_usage = self._get_system_metrics()["memory_percent"]
            if memory_usage > self.max_memory_percent:
                logger.error(f"Memory usage still high after cleanup: {memory_usage:.2f}%")
                return False
        if cpu_usage > self.max_cpu_percent:
            logger.warning(f"CPU usage high: {cpu_usage:.2f}% (Limit: {self.max_cpu_percent}%)")
            await self._close_idle_browsers(force_check=True)
            # Recheck after cleanup
            cpu_usage = self._get_system_metrics()["cpu_percent"]
            if cpu_usage > self.max_cpu_percent:
                logger.error(f"CPU usage still high after cleanup: {cpu_usage:.2f}%")
                return False
        return True
    async def _close_idle_browsers(self, force_check=False):
        """Closes browser instances that have been idle for too long."""
        async with self.lock:
            current_time = time.time()
            browsers_to_close = []
            for instance_id, browser in self.browsers.items():
                if not browser.is_closing and not browser.contexts:
                    idle_time = current_time - browser.last_used
                    if idle_time > self.idle_timeout:
                        logger.info(f"Browser {instance_id} idle for {idle_time:.2f}s, closing")
                        browsers_to_close.append(instance_id)
            if browsers_to_close:
                logger.info(f"Closing {len(browsers_to_close)} idle browsers")
                await asyncio.gather(
                    *(self.close_browser(browser_id) for browser_id in browsers_to_close),
                    return_exceptions=True
                )
    async def _monitor_task(self):
        """Background task to monitor resources and close idle browsers."""
        logger.info("Starting browser pool monitor task")
        while not self._shutting_down:
            try:
                await asyncio.sleep(self.monitor_interval)
                if self._shutting_down:
                    break
                await self._check_resource_limits()
                await self._close_idle_browsers()
            except asyncio.CancelledError:
                logger.info("Monitor task cancelled")
                break
            except Exception as e:
                logger.error(f"Error in monitor task: {e}", exc_info=True)
                await asyncio.sleep(self.monitor_interval)
        logger.info("Browser pool monitor task stopped")
    async def get_browser(self) -> BrowserInstance:
        """
        Get an available browser instance from the pool, creating one if necessary.
        Returns:
            An available BrowserInstance
        Raises:
            MCPBrowserException: If resource limits are exceeded or browser creation fails.
        """
        async with self.lock:
            if self._shutting_down:
                raise MCPBrowserException(ErrorCode.POOL_SHUTTING_DOWN, "Browser pool is shutting down")
            # Check resource limits before creating a new browser
            if not await self._check_resource_limits():
                raise MCPBrowserException(
                    ErrorCode.RESOURCE_LIMIT_EXCEEDED,
                    "System resource limits exceeded. Cannot create new browser"
                )
            # Check if we've reached the maximum number of browsers
            if len(self.browsers) >= self.max_browsers:
                raise MCPBrowserException(
                    ErrorCode.MAX_BROWSERS_REACHED,
                    f"Maximum number of browsers ({self.max_browsers}) reached"
                )
            # Create a new browser instance
            instance_id = str(uuid.uuid4())
            browser_instance = BrowserInstance(
                instance_id,
                allowed_domains=self.allowed_domains,
                blocked_domains=self.blocked_domains,
                network_isolation=self.network_isolation
            )
            try:
                await browser_instance.initialize()
                self.browsers[instance_id] = browser_instance
                logger.info(f"Created new browser instance {instance_id}")
                return browser_instance
            except Exception as e:
                logger.error(f"Failed to initialize browser {instance_id}: {e}")
                await browser_instance.close()
                raise MCPBrowserException(
                    ErrorCode.BROWSER_INITIALIZATION_FAILED,
                    f"Failed to initialize browser: {str(e)}",
                    original_exception=e
                )
    async def close_browser(self, browser_id: str):
        """Close a specific browser instance and remove it from the pool."""
        logger.info(f"[Pool] close_browser called for {browser_id}")
        try:
            async with self.lock:
                if browser_id in self.browsers:
                    browser = self.browsers[browser_id]
                    logger.info(f"[Pool] Found browser {browser_id}. Initiating close...")
                    # Add timeout to browser.close()
                    try:
                        await asyncio.wait_for(browser.close(), timeout=5.0)
                        logger.info(f"[Pool] Successfully awaited browser.close() for {browser_id}")
                    except asyncio.TimeoutError:
                        logger.error(f"[Pool] Timeout while closing browser {browser_id}")
                        raise
                    except Exception as e:
                        logger.error(f"[Pool] Error during browser.close() for {browser_id}: {e}", exc_info=True)
                        raise
                    del self.browsers[browser_id]
                    logger.info(f"[Pool] Removed browser {browser_id} from pool.")
                else:
                    logger.warning(f"[Pool] Attempted to close non-existent browser {browser_id}")
        except Exception as e:
            logger.error(f"[Pool] Error in close_browser for {browser_id}: {e}", exc_info=True)
            raise
    def start_monitoring(self):
        """Start the background monitoring task."""
        if self._monitor_task_handle is None or self._monitor_task_handle.done():
            self._shutting_down = False
            self._monitor_task_handle = asyncio.create_task(self._monitor_task())
            logger.info("Started browser pool monitoring")
    async def cleanup(self):
        """Clean up all resources used by the pool."""
        logger.info("[Pool] Starting cleanup")
        try:
            async with self.lock:
                self._shutting_down = True
                logger.info("[Pool] Shutting down flag set.")
                # Cancel monitor task with timeout
                if self._monitor_task_handle and not self._monitor_task_handle.done():
                    logger.info("[Pool] Cancelling monitor task...")
                    self._monitor_task_handle.cancel()
                    try:
                        await asyncio.wait_for(self._monitor_task_handle, timeout=5.0)
                        logger.info("[Pool] Monitor task cancelled successfully")
                    except asyncio.TimeoutError:
                        logger.error("[Pool] Monitor task cancellation timed out")
                    except asyncio.CancelledError:
                        logger.info("[Pool] Monitor task cancelled")
                    except Exception as e:
                        logger.error(f"[Pool] Error during monitor task cancellation: {e}", exc_info=True)
                else:
                    logger.info("[Pool] Monitor task not running or already done")
                # Close browsers with timeout
                browser_ids = list(self.browsers.keys())
                if browser_ids:
                    logger.info(f"[Pool] Closing {len(browser_ids)} remaining browsers: {browser_ids}")
                    for browser_id in browser_ids:
                        try:
                            logger.info(f"[Pool] Starting close_browser for {browser_id}")
                            # Add timeout to individual browser close operations
                            await asyncio.wait_for(self.close_browser(browser_id), timeout=10.0)
                            logger.info(f"[Pool] Successfully closed browser {browser_id}")
                        except asyncio.TimeoutError:
                            logger.error(f"[Pool] Timeout while closing browser {browser_id}")
                        except Exception as e:
                            logger.error(f"[Pool] Error closing browser {browser_id}: {e}", exc_info=True)
                else:
                    logger.info("[Pool] No remaining browsers to close")
            logger.info("[Pool] Browser pool cleanup completed successfully")
        except Exception as e:
            logger.error(f"[Pool] Unexpected error during cleanup: {e}", exc_info=True)
            raise
# Global instance
browser_pool = None
async def initialize_browser_pool(max_browsers: int = 10, idle_timeout: int = 300):
    """
    Initialize the global browser pool
    Args:
        max_browsers: Maximum number of concurrent browser instances
        idle_timeout: Time in seconds after which idle browsers are closed
    """
    global browser_pool
    if browser_pool is None:
        browser_pool = BrowserPool(max_browsers, idle_timeout)
        await browser_pool.start()
    return browser_pool
async def close_browser_pool():
    """Close the global browser pool"""
    global browser_pool
    if browser_pool is not None:
        await browser_pool.stop()
        browser_pool = None
</file>

<file path="src/error_handler.py">
#!/usr/bin/env python3
"""
Error Handler for MCP Browser
This module provides standardized error handling for the MCP Browser application.
"""
import enum
import logging
import traceback
import asyncio
import functools
from typing import Dict, List, Optional, Any, Callable, TypeVar, Union
from pydantic import BaseModel
from fastapi import HTTPException, status
# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("error-handler")
class ErrorCode(str, enum.Enum):
    """Error codes for MCP Browser exceptions"""
    # Resource Management Errors
    RESOURCE_POOL_EXHAUSTED = "RESOURCE_POOL_EXHAUSTED"
    RESOURCE_NOT_FOUND = "RESOURCE_NOT_FOUND"
    RESOURCE_LIMIT_EXCEEDED = "RESOURCE_LIMIT_EXCEEDED"
    RESOURCE_RECOVERY_FAILED = "RESOURCE_RECOVERY_FAILED"
    RESOURCE_CLEANUP_FAILED = "RESOURCE_CLEANUP_FAILED"
    RESOURCE_MONITOR_ERROR = "RESOURCE_MONITOR_ERROR"
    # Browser Management Errors
    BROWSER_INITIALIZATION_FAILED = "BROWSER_INITIALIZATION_FAILED"
    BROWSER_CLEANUP_FAILED = "BROWSER_CLEANUP_FAILED"
    BROWSER_RECOVERY_FAILED = "BROWSER_RECOVERY_FAILED"
    BROWSER_PROCESS_ERROR = "BROWSER_PROCESS_ERROR"
    CONTEXT_CREATION_FAILED = "CONTEXT_CREATION_FAILED"
    CONTEXT_CLEANUP_FAILED = "CONTEXT_CLEANUP_FAILED"
    CONTEXT_RECOVERY_FAILED = "CONTEXT_RECOVERY_FAILED"
    # Page Management Errors
    PAGE_CREATION_FAILED = "PAGE_CREATION_FAILED"
    PAGE_NAVIGATION_FAILED = "PAGE_NAVIGATION_FAILED"
    PAGE_TIMEOUT = "PAGE_TIMEOUT"
    PAGE_ERROR = "PAGE_ERROR"
    # Network Errors
    NETWORK_ERROR = "NETWORK_ERROR"
    CONNECTION_ERROR = "CONNECTION_ERROR"
    TIMEOUT_ERROR = "TIMEOUT_ERROR"
    # Authentication Errors
    AUTH_REQUIRED = "AUTH_REQUIRED"
    AUTH_FAILED = "AUTH_FAILED"
    AUTH_EXPIRED = "AUTH_EXPIRED"
    # Permission Errors
    PERMISSION_DENIED = "PERMISSION_DENIED"
    RATE_LIMIT_EXCEEDED = "RATE_LIMIT_EXCEEDED"
    # General Errors
    INVALID_REQUEST = "INVALID_REQUEST"
    INTERNAL_ERROR = "INTERNAL_ERROR"
    NOT_IMPLEMENTED = "NOT_IMPLEMENTED"
class ErrorDetail(BaseModel):
    """Detailed error information"""
    field: Optional[str] = None
    message: str
    code: Optional[str] = None
class ErrorResponse(BaseModel):
    """Standardized error response"""
    error_code: int
    message: str
    status_code: int
    details: Optional[List[ErrorDetail]] = None
# Map error codes to HTTP status codes
ERROR_STATUS_CODES = {
    # Authentication errors
    ErrorCode.AUTH_REQUIRED: status.HTTP_401_UNAUTHORIZED,
    ErrorCode.AUTH_FAILED: status.HTTP_401_UNAUTHORIZED,
    ErrorCode.AUTH_EXPIRED: status.HTTP_401_UNAUTHORIZED,
    # Browser operation errors
    ErrorCode.PAGE_NAVIGATION_FAILED: status.HTTP_400_BAD_REQUEST,
    ErrorCode.PAGE_TIMEOUT: status.HTTP_408_REQUEST_TIMEOUT,
    ErrorCode.PAGE_ERROR: status.HTTP_500_INTERNAL_SERVER_ERROR,
    # Resource management errors
    ErrorCode.RESOURCE_NOT_FOUND: status.HTTP_404_NOT_FOUND,
    ErrorCode.RESOURCE_POOL_EXHAUSTED: status.HTTP_503_SERVICE_UNAVAILABLE,
    ErrorCode.RESOURCE_LIMIT_EXCEEDED: status.HTTP_429_TOO_MANY_REQUESTS,
    ErrorCode.RESOURCE_RECOVERY_FAILED: status.HTTP_500_INTERNAL_SERVER_ERROR,
    ErrorCode.RESOURCE_CLEANUP_FAILED: status.HTTP_500_INTERNAL_SERVER_ERROR,
    ErrorCode.RESOURCE_MONITOR_ERROR: status.HTTP_500_INTERNAL_SERVER_ERROR,
    # Browser operation errors
    ErrorCode.BROWSER_INITIALIZATION_FAILED: status.HTTP_500_INTERNAL_SERVER_ERROR,
    ErrorCode.BROWSER_CLEANUP_FAILED: status.HTTP_500_INTERNAL_SERVER_ERROR,
    ErrorCode.BROWSER_RECOVERY_FAILED: status.HTTP_500_INTERNAL_SERVER_ERROR,
    ErrorCode.BROWSER_PROCESS_ERROR: status.HTTP_500_INTERNAL_SERVER_ERROR,
    ErrorCode.CONTEXT_CREATION_FAILED: status.HTTP_500_INTERNAL_SERVER_ERROR,
    ErrorCode.CONTEXT_CLEANUP_FAILED: status.HTTP_500_INTERNAL_SERVER_ERROR,
    ErrorCode.CONTEXT_RECOVERY_FAILED: status.HTTP_500_INTERNAL_SERVER_ERROR,
    # Input validation errors
    ErrorCode.INVALID_REQUEST: status.HTTP_400_BAD_REQUEST,
    # System errors
    ErrorCode.INTERNAL_ERROR: status.HTTP_500_INTERNAL_SERVER_ERROR,
    ErrorCode.NOT_IMPLEMENTED: status.HTTP_501_NOT_IMPLEMENTED,
    # Network errors
    ErrorCode.NETWORK_ERROR: status.HTTP_503_SERVICE_UNAVAILABLE,
    ErrorCode.CONNECTION_ERROR: status.HTTP_503_SERVICE_UNAVAILABLE,
    ErrorCode.TIMEOUT_ERROR: status.HTTP_408_REQUEST_TIMEOUT
}
class MCPBrowserException(Exception):
    """Custom exception for MCP Browser application"""
    def __init__(
        self,
        error_code: ErrorCode,
        message: str,
        original_exception: Optional[Exception] = None,
        details: Optional[Dict[str, Any]] = None
    ):
        """
        Initialize the exception
        Args:
            error_code: Error code from ErrorCode enum
            message: Error message
            original_exception: The original exception that caused this error
            details: Additional details about the error
        """
        self.error_code = error_code
        self.message = message or error_code.name
        self.original_exception = original_exception
        self.details = details or {}
        # Log the error with traceback if there was an original exception
        if original_exception:
            logger.error(
                f"Error {error_code.name}: {message}",
                exc_info=original_exception
            )
        else:
            logger.error(f"Error {error_code.name}: {message}")
        super().__init__(self.message)
    def to_response(self) -> ErrorResponse:
        """
        Convert the exception to a standardized error response
        Returns:
            ErrorResponse object
        """
        return ErrorResponse(
            error_code=ERROR_STATUS_CODES.get(self.error_code, status.HTTP_500_INTERNAL_SERVER_ERROR),
            message=self.message,
            status_code=ERROR_STATUS_CODES.get(self.error_code, status.HTTP_500_INTERNAL_SERVER_ERROR),
            details=[ErrorDetail(field="error_code", message=str(self.error_code))]
        )
    def to_http_exception(self) -> HTTPException:
        """
        Convert the exception to an HTTPException
        Returns:
            HTTPException object
        """
        response = self.to_response()
        return HTTPException(
            status_code=ERROR_STATUS_CODES.get(self.error_code, status.HTTP_500_INTERNAL_SERVER_ERROR),
            detail=response.dict()
        )
class RetryConfig:
    """Configuration for retry behavior"""
    def __init__(
        self,
        max_retries: int = 3,
        delay: float = 1.0,
        backoff: float = 2.0,
        exceptions: Optional[List[type]] = None
    ):
        """
        Initialize retry configuration
        Args:
            max_retries: Maximum number of retry attempts
            delay: Initial delay in seconds before the first retry
            backoff: Multiplier for the delay between retries
            exceptions: List of exception types that should be retried
        """
        self.max_retries = max_retries
        self.delay = delay
        self.backoff = backoff
        self.exceptions = exceptions or [Exception]
# Default retry configuration
DEFAULT_RETRY_CONFIG = RetryConfig()
# Type variable for return type
T = TypeVar('T')
def with_retry(config: Optional[RetryConfig] = None):
    """
    Decorator for retrying operations that may fail
    Args:
        config: Retry configuration. If None, uses DEFAULT_RETRY_CONFIG
    """
    if config is None:
        config = DEFAULT_RETRY_CONFIG
    def decorator(func: Callable):
        @functools.wraps(func)
        async def wrapper(*args, **kwargs):
            last_exception = None
            delay = config.delay
            for attempt in range(config.max_retries):
                try:
                    return await func(*args, **kwargs)
                except tuple(config.exceptions) as e:
                    last_exception = e
                    if attempt < config.max_retries - 1:
                        logger.warning(
                            f"Attempt {attempt + 1} failed, retrying in {delay:.1f}s: {str(e)}"
                        )
                        await asyncio.sleep(delay)
                        delay *= config.backoff
                    else:
                        logger.error(
                            f"All {config.max_retries} attempts failed: {str(e)}"
                        )
            raise last_exception
        return wrapper
    return decorator
def handle_exceptions(func: Callable):
    """
    Decorator for standardized exception handling
    Args:
        func: The function to wrap
    """
    @functools.wraps(func)
    async def wrapper(*args, **kwargs):
        try:
            return await func(*args, **kwargs)
        except MCPBrowserException as e:
            # Log the error with stack trace for debugging
            logger.error(
                f"MCPBrowserException: {e.error_code} - {e.message}",
                exc_info=True
            )
            # Convert to HTTP exception
            status_code = ERROR_STATUS_CODES.get(e.error_code, status.HTTP_500_INTERNAL_SERVER_ERROR)
            if e.error_code in [
                ErrorCode.AUTH_REQUIRED,
                ErrorCode.AUTH_FAILED,
                ErrorCode.AUTH_EXPIRED
            ]:
                status_code = status.HTTP_401_UNAUTHORIZED
            elif e.error_code in [
                ErrorCode.PERMISSION_DENIED,
                ErrorCode.RATE_LIMIT_EXCEEDED
            ]:
                status_code = status.HTTP_403_FORBIDDEN
            elif e.error_code in [
                ErrorCode.RESOURCE_NOT_FOUND,
                ErrorCode.PAGE_ERROR
            ]:
                status_code = status.HTTP_404_NOT_FOUND
            elif e.error_code in [
                ErrorCode.INVALID_REQUEST,
                ErrorCode.PAGE_NAVIGATION_FAILED
            ]:
                status_code = status.HTTP_400_BAD_REQUEST
            elif e.error_code in [
                ErrorCode.RESOURCE_POOL_EXHAUSTED,
                ErrorCode.RESOURCE_LIMIT_EXCEEDED
            ]:
                status_code = status.HTTP_503_SERVICE_UNAVAILABLE
            raise HTTPException(
                status_code=status_code,
                detail={
                    "error_code": e.error_code,
                    "message": e.message,
                    "details": e.details
                }
            )
        except Exception as e:
            # Log unexpected errors
            logger.error("Unexpected error:", exc_info=True)
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail={
                    "error_code": ErrorCode.INTERNAL_ERROR,
                    "message": "An unexpected error occurred",
                    "details": {"error": str(e)}
                }
            )
    return wrapper
</file>

<file path="src/integrate_components.py">
#!/usr/bin/env python3
"""
Integration script for MCP Browser components
This script updates the main.py file to use the BrowserPool, error handling,
and authentication components we've implemented.
"""
import os
import sys
import asyncio
import logging
from typing import Dict, List, Optional, Any
from contextlib import asynccontextmanager
from fastapi import FastAPI
# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("mcp-browser-integration")
async def main():
    """Main integration function"""
    logger.info("Starting MCP Browser component integration")
    # Get paths
    script_dir = os.path.dirname(os.path.realpath(__file__))
    main_file = os.path.join(script_dir, "main.py")
    integration_file = os.path.join(script_dir, "integration.py")
    browser_pool_file = os.path.join(script_dir, "browser_pool.py")
    error_handler_file = os.path.join(script_dir, "error_handler.py")
    # Verify all files exist
    for file in [main_file, integration_file, browser_pool_file, error_handler_file]:
        if not os.path.exists(file):
            logger.error(f"Required file not found: {file}")
            return 1
    # Install component imports in main.py
    logger.info("Installing component imports in main.py")
    await install_imports(main_file)
    # Replace existing browser initialization with BrowserPool
    logger.info("Replacing browser initialization with BrowserPool")
    await replace_browser_init(main_file)
    # Apply error handling to critical endpoints
    logger.info("Applying error handling to critical endpoints")
    await apply_error_handling(main_file)
    # Update auth system to use new components
    logger.info("Updating auth system")
    await update_auth_system(main_file)
    # Add token refresh endpoint
    logger.info("Adding token refresh endpoint")
    await add_token_refresh(main_file)
    # Add rate limiting
    logger.info("Adding rate limiting")
    await add_rate_limiting(main_file)
    logger.info("MCP Browser component integration completed successfully")
    return 0
async def install_imports(main_file: str):
    """
    Install required imports in the main application file
    Args:
        main_file: Path to main.py
    """
    with open(main_file, 'r') as f:
        content = f.read()
    # Prepare the new imports to add
    new_imports = """
# Component integration imports
from integration import browser_manager, auth_manager, configure_app, handle_exceptions, with_retry, DEFAULT_RETRY_CONFIG
from error_handler import MCPBrowserException, ErrorCode, RetryConfig
"""
    # Add imports after the last import statement
    import_section_end = content.rfind("import") + content[content.rfind("import"):].find('\n') + 1
    updated_content = content[:import_section_end] + new_imports + content[import_section_end:]
    with open(main_file, 'w') as f:
        f.write(updated_content)
    logger.info("Component imports added to main.py")
async def replace_browser_init(main_file: str):
    """
    Replace existing browser initialization with BrowserPool integration and lifespan events
    Args:
        main_file: Path to main.py
    """
    with open(main_file, 'r') as f:
        content = f.read()
    # Check if file already contains lifespan context manager
    if "asynccontextmanager" in content and "@asynccontextmanager" in content:
        logger.info("File already contains lifespan context manager")
        return
    # Add imports for asynccontextmanager if needed
    if "from contextlib import asynccontextmanager" not in content:
        if "from typing import" in content:
            content = content.replace(
                "from typing import", 
                "from typing import AsyncGenerator, "
            )
        else:
            # Add imports near the top after other imports
            import_end = content.find("# Configure logging")
            if import_end == -1:
                import_end = content.find("import ")
                import_end = content.find("\n", import_end) + 1
            content = (
                content[:import_end] + 
                "from contextlib import asynccontextmanager\n" + 
                "from typing import AsyncGenerator\n" + 
                content[import_end:]
            )
    # Look for app initialization
    app_init_start = content.find("app = FastAPI(")
    if app_init_start == -1:
        logger.error("Could not find FastAPI app initialization")
        return
    app_init_end = content.find(")", app_init_start)
    if app_init_end == -1:
        logger.error("Could not determine end of FastAPI app initialization")
        return
    # Create lifespan function
    lifespan_code = """
# Define lifespan context manager
@asynccontextmanager
async def lifespan(app: FastAPI) -> AsyncGenerator[None, None]:
    \"\"\"Lifespan context manager for startup and shutdown events\"\"\"
    global app_state
    app_state = {}
    # Configure the app with integration components
    configure_app(app)
    # Initialize MCP client for tool registration
    if os.environ.get("MCP_SERVER_URL") and os.environ.get("MCP_API_KEY"):
        app_state["mcp_client"] = MCPClient(
            model_name=os.environ.get("MCP_MODEL_NAME", "mcp-browser"),
            server_url=os.environ.get("MCP_SERVER_URL"),
            api_key=os.environ.get("MCP_API_KEY")
        )
        try:
            await app_state["mcp_client"].register_tools()
            logger.info("MCP tools registered successfully")
        except Exception as e:
            logger.error(f"Failed to register MCP tools: {str(e)}")
    else:
        logger.warning("MCP_SERVER_URL or MCP_API_KEY not set, skipping MCP tool registration")
    # Initialize event subscriptions
    app_state["subscriptions"] = {}
    logger.info("MCP Browser server started")
    yield  # Run the application
    # Cleanup on shutdown
    # Close MCP client
    if app_state.get("mcp_client"):
        await app_state["mcp_client"].close()
    # Clear subscriptions
    app_state["subscriptions"] = {}
    logger.info("MCP Browser server shut down")
"""
    # Find a good insertion point for the lifespan function
    # Look for # App state or some other clear marker before app initialization
    app_state_pos = content.find("# App state")
    if app_state_pos == -1:
        # Insert after imports but before app initialization
        app_state_pos = content.find("# Configure logging")
        if app_state_pos == -1:
            app_state_pos = app_init_start
        else:
            # Find the next section after logging config
            next_section = content.find("#", app_state_pos + 15)
            if next_section != -1 and next_section < app_init_start:
                app_state_pos = next_section
            else:
                app_state_pos = app_init_start
    # Insert lifespan code before app initialization
    content = content[:app_state_pos] + lifespan_code + content[app_state_pos:]
    # Update app initialization to use lifespan
    app_init_content = content[app_init_start:app_init_end+1]
    if "lifespan=lifespan" not in app_init_content:
        # Check if there's a comma at the end of the last parameter
        if app_init_content.rstrip().endswith(","):
            new_app_init = app_init_content.rstrip() + "\n    lifespan=lifespan\n)"
        else:
            new_app_init = app_init_content.rstrip()[:-1] + ",\n    lifespan=lifespan\n)"
        # Replace app initialization
        content = content[:app_init_start] + new_app_init + content[app_init_end+1:]
    # Remove old @app.on_event handlers that we've replaced with lifespan
    startup_event_pos = content.find('@app.on_event("startup")')
    if startup_event_pos != -1:
        # Find the end of the startup_event function
        function_start = content.find("async def startup_event", startup_event_pos)
        if function_start != -1:
            # Find the end of the function by looking for the next function or class
            next_func = content.find("@app", function_start + 30)
            if next_func == -1:
                next_func = content.find("def ", function_start + 30)
            if next_func == -1:
                next_func = content.find("class ", function_start + 30)
            if next_func != -1:
                # Remove the startup event handler
                content = content[:startup_event_pos] + content[next_func:]
    shutdown_event_pos = content.find('@app.on_event("shutdown")')
    if shutdown_event_pos != -1:
        # Find the end of the shutdown_event function
        function_start = content.find("async def shutdown_event", shutdown_event_pos)
        if function_start != -1:
            # Find the end of the function by looking for the next function or class
            next_func = content.find("@app", function_start + 30)
            if next_func == -1:
                next_func = content.find("def ", function_start + 30)
            if next_func == -1:
                next_func = content.find("class ", function_start + 30)
            if next_func != -1:
                # Remove the shutdown event handler
                content = content[:shutdown_event_pos] + content[next_func:]
    # Write updated content back to file
    with open(main_file, 'w') as f:
        f.write(content)
    logger.info("Updated main.py with lifespan event handlers and browser integration")
async def apply_error_handling(main_file: str):
    """
    Apply error handling to critical endpoints
    Args:
        main_file: Path to main.py
    """
    with open(main_file, 'r') as f:
        content = f.read()
    # Identify critical browser endpoints to apply error handling
    endpoints = [
        "@app.post(\"/api/browser/navigate\")",
        "@app.post(\"/api/browser/back\")",
        "@app.post(\"/api/browser/forward\")",
        "@app.post(\"/api/browser/refresh\")",
        "@app.post(\"/api/browser/click\")",
        "@app.post(\"/api/browser/type\")",
        "@app.post(\"/api/browser/select\")",
        "@app.post(\"/api/browser/fill_form\")",
        "@app.post(\"/api/browser/screenshot\")",
        "@app.post(\"/api/browser/extract_text\")",
        "@app.post(\"/api/browser/check_visibility\")",
        "@app.post(\"/api/browser/wait_for_selector\")",
        "@app.post(\"/api/browser/evaluate\")",
        "@app.post(\"/api/screenshots/capture\")",
        "@app.post(\"/api/dom/extract\")",
        "@app.post(\"/api/css/analyze\")",
        "@app.post(\"/api/accessibility/test\")",
        "@app.post(\"/api/responsive/test\")"
    ]
    updated_content = content
    # Add the handle_exceptions decorator to each endpoint
    for endpoint in endpoints:
        endpoint_pos = updated_content.find(endpoint)
        if endpoint_pos == -1:
            logger.warning(f"Could not find endpoint: {endpoint}")
            continue
        # Check if handle_exceptions is already applied
        prev_lines = updated_content[max(0, endpoint_pos - 100):endpoint_pos].splitlines()
        if any("@handle_exceptions" in line for line in prev_lines[-3:]):
            logger.info(f"handle_exceptions already applied to {endpoint}")
            continue
        # Add the decorator
        updated_content = updated_content[:endpoint_pos] + "@handle_exceptions\n" + updated_content[endpoint_pos:]
    with open(main_file, 'w') as f:
        f.write(updated_content)
    logger.info("Error handling applied to critical endpoints")
async def update_auth_system(main_file: str):
    """
    Update authentication system to use the integrated auth manager
    Args:
        main_file: Path to main.py
    """
    with open(main_file, 'r') as f:
        content = f.read()
    # Find existing auth function implementations that need to be updated
    functions_to_update = [
        "def create_access_token",
        "async def get_current_user",
        "async def get_current_active_user",
        "def has_permission",
        "async def get_token_from_query",
        "async def verify_websocket_token"
    ]
    updated_content = content
    # Comment out each function and replace with a reference to auth_manager
    for func in functions_to_update:
        func_pos = updated_content.find(func)
        if func_pos == -1:
            logger.warning(f"Could not find function: {func}")
            continue
        # Find function start
        function_start = updated_content.rfind("\n", 0, func_pos) + 1
        # Find function end (next function def or class def)
        next_func = updated_content.find("def ", func_pos + len(func))
        next_class = updated_content.find("class ", func_pos + len(func))
        if next_func == -1 and next_class == -1:
            function_end = len(updated_content)
        elif next_func == -1:
            function_end = next_class
        elif next_class == -1:
            function_end = next_func
        else:
            function_end = min(next_func, next_class)
        # Find the indentation before the function
        func_lines = updated_content[function_start:function_end].splitlines()
        # Comment out the entire function
        commented_function = "# Auth system now managed by auth_manager\n"
        commented_function += "# " + "\n# ".join(func_lines)
        # Replace the function with commented version
        updated_content = updated_content[:function_start] + commented_function + updated_content[function_end:]
    with open(main_file, 'w') as f:
        f.write(updated_content)
    logger.info("Auth system updated to use auth_manager")
async def add_token_refresh(main_file: str):
    """
    Add token refresh endpoint
    Args:
        main_file: Path to main.py
    """
    with open(main_file, 'r') as f:
        content = f.read()
    # Find a good place to add the token refresh endpoint (after the login endpoint)
    login_endpoint = content.find("@app.post(\"/token\"")
    if login_endpoint == -1:
        logger.warning("Could not find login endpoint to add token refresh")
        return
    # Find the end of the login endpoint function
    login_function_end = content.find("@app", login_endpoint + 1)
    if login_function_end == -1:
        logger.warning("Could not determine end of login function")
        return
    # New refresh token endpoint code
    refresh_endpoint = """
@app.post("/token/refresh", response_model=Token)
@handle_exceptions
async def refresh_access_token(refresh_token: str = Body(...)):
    """
    Refresh an access token using a refresh token
    Args:
        refresh_token: Valid refresh token
    Returns:
        New access token
    Raises:
        HTTPException: If refresh token is invalid
    """
    try:
        # Verify the refresh token
        payload = await auth_manager.decode_token(refresh_token)
        # Check if it's actually a refresh token
        if not payload.get("refresh"):
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Not a refresh token"
            )
        # Check username
        username = payload.get("sub")
        if not username:
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="Invalid refresh token"
            )
        # Get permissions from the refresh token
        permissions = payload.get("permissions", [])
        # Create a new access token
        access_token = await auth_manager.create_access_token(
            data={"sub": username, "permissions": permissions}
        )
        return {"access_token": access_token, "token_type": "bearer"}
    except (JWTError, MCPBrowserException) as e:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail=f"Invalid refresh token: {str(e)}",
            headers={"WWW-Authenticate": "Bearer"}
        )
"""
    # Add the refresh endpoint after the login endpoint
    updated_content = content[:login_function_end] + refresh_endpoint + content[login_function_end:]
    with open(main_file, 'w') as f:
        f.write(updated_content)
    logger.info("Token refresh endpoint added")
async def add_rate_limiting(main_file: str):
    """
    Add rate limiting to sensitive endpoints
    Args:
        main_file: Path to main.py
    """
    with open(main_file, 'r') as f:
        content = f.read()
    # Add rate limiting imports and middleware
    imports_end = content.find("# Component integration imports") + content[content.find("# Component integration imports"):].find('\n') + 1
    rate_limit_imports = """
# Rate limiting
from fastapi import Depends, Request
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded
"""
    updated_content = content[:imports_end] + rate_limit_imports + content[imports_end:]
    # Add limiter initialization before the app creation
    app_creation = updated_content.find("app = FastAPI(")
    if app_creation == -1:
        logger.warning("Could not find FastAPI app creation")
        return
    limiter_init = """
# Initialize rate limiter
limiter = Limiter(key_func=get_remote_address)
"""
    updated_content = updated_content[:app_creation] + limiter_init + updated_content[app_creation:]
    # Add middleware configuration after app creation
    app_created_end = updated_content.find("app = FastAPI(") + updated_content[updated_content.find("app = FastAPI("):].find(')') + 1
    middleware_config = """
# Add rate limiting middleware
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)
# Add trusted host middleware
app.add_middleware(
    TrustedHostMiddleware, 
    allowed_hosts=os.environ.get("ALLOWED_HOSTS", "*").split(",")
)
"""
    updated_content = updated_content[:app_created_end] + middleware_config + updated_content[app_created_end:]
    # Add rate limiting to sensitive endpoints
    sensitive_endpoints = [
        "@app.post(\"/token\"",
        "@app.post(\"/token/refresh\"",
    ]
    for endpoint in sensitive_endpoints:
        endpoint_pos = updated_content.find(endpoint)
        if endpoint_pos == -1:
            logger.warning(f"Could not find endpoint: {endpoint}")
            continue
        # Check if rate limiting is already applied
        prev_lines = updated_content[max(0, endpoint_pos - 100):endpoint_pos].splitlines()
        if any("@limiter.limit" in line for line in prev_lines[-3:]):
            logger.info(f"Rate limiting already applied to {endpoint}")
            continue
        # Add the rate limiter
        updated_content = updated_content[:endpoint_pos] + '@limiter.limit("5/minute")\n' + updated_content[endpoint_pos:]
    with open(main_file, 'w') as f:
        f.write(updated_content)
    logger.info("Rate limiting added to sensitive endpoints")
if __name__ == "__main__":
    try:
        exit_code = asyncio.run(main())
        sys.exit(exit_code)
    except KeyboardInterrupt:
        logger.info("Integration cancelled by user")
        sys.exit(1)
    except Exception as e:
        logger.error(f"Integration failed: {str(e)}", exc_info=True)
        sys.exit(1)
</file>

<file path="src/integration.py">
#!/usr/bin/env python3
"""
Integration Module for MCP Browser
This module integrates BrowserPool, error handling, and authentication components.
"""
import os
import logging
import asyncio
import time
import uuid
from typing import Dict, List, Optional, Any, Set, Callable, AsyncGenerator
from datetime import datetime, timedelta
import jwt
from fastapi import FastAPI, Depends, HTTPException, status, Request
from fastapi.security import OAuth2PasswordBearer
from pydantic import BaseModel
from contextlib import asynccontextmanager
# Import our components
from browser_pool import BrowserInstance, browser_pool, initialize_browser_pool, close_browser_pool
from error_handler import (
    MCPBrowserException, ErrorCode, RetryConfig, with_retry, handle_exceptions, DEFAULT_RETRY_CONFIG
)
# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("integration")
# OAuth2 password bearer for token authentication
oauth2_scheme = OAuth2PasswordBearer(tokenUrl="token")
# JWT configuration
JWT_SECRET_KEY = os.environ.get("JWT_SECRET_KEY", "mcp-browser-default-secret-key")
JWT_ALGORITHM = "HS256"
ACCESS_TOKEN_EXPIRE_MINUTES = int(os.environ.get("ACCESS_TOKEN_EXPIRE_MINUTES", 30))
REFRESH_TOKEN_EXPIRE_DAYS = int(os.environ.get("REFRESH_TOKEN_EXPIRE_DAYS", 7))
# User models
class User(BaseModel):
    username: str
    email: Optional[str] = None
    full_name: Optional[str] = None
    disabled: Optional[bool] = None
    permissions: List[str] = []
# Fake database for demo
fake_users_db = {
    "admin": {
        "username": "admin",
        "full_name": "Administrator",
        "email": "admin@example.com",
        "disabled": False,
        "permissions": ["browser:full", "admin"]
    },
    "user": {
        "username": "user",
        "full_name": "Regular User",
        "email": "user@example.com",
        "disabled": False,
        "permissions": ["browser:basic"]
    }
}
class BrowserManager:
    """Manager for browser resources"""
    def __init__(self):
        """Initialize the browser manager"""
        self.session_contexts = {}  # Maps session IDs to context IDs
    async def initialize(self, max_browsers: int = 10, idle_timeout: int = 300):
        """
        Initialize the browser manager
        Args:
            max_browsers: Maximum number of concurrent browser instances
            idle_timeout: Time in seconds after which idle browsers are closed
        """
        await initialize_browser_pool(max_browsers, idle_timeout)
        logger.info(f"Browser manager initialized with max_browsers={max_browsers}")
    async def shutdown(self):
        """Shutdown the browser manager"""
        await close_browser_pool()
        logger.info("Browser manager shut down")
    async def create_browser_context(
        self, 
        session_id: str, 
        user_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Create a browser context for a session
        Args:
            session_id: Session identifier
            user_id: User identifier
        Returns:
            Context information
        """
        try:
            # Get a browser from the pool
            browser_instance = await browser_pool.get_browser()
            # Create context ID
            context_id = str(uuid.uuid4())
            # Create the context
            context = await browser_instance.create_context(
                context_id,
                user_id=user_id
            )
            # Store the mapping
            self.session_contexts[session_id] = {
                "context_id": context_id,
                "browser_id": browser_instance.id,
                "created_at": time.time(),
                "user_id": user_id
            }
            logger.info(f"Created browser context {context_id} for session {session_id}")
            return context
        except Exception as e:
            logger.error(f"Error creating browser context: {str(e)}")
            raise MCPBrowserException(
                error_code=ErrorCode.RESOURCE_POOL_EXHAUSTED,
                message=f"Failed to create browser context: {str(e)}",
                original_exception=e
            )
    async def get_browser_context(self, session_id: str) -> Dict[str, Any]:
        """
        Get the browser context for a session
        Args:
            session_id: Session identifier
        Returns:
            Context information
        """
        session_info = self.session_contexts.get(session_id)
        if not session_info:
            raise MCPBrowserException(
                error_code=ErrorCode.RESOURCE_NOT_FOUND,
                message=f"No browser context found for session {session_id}"
            )
        return session_info
    async def close_browser_context(self, session_id: str):
        """
        Close the browser context for a session
        Args:
            session_id: Session identifier
        """
        session_info = self.session_contexts.get(session_id)
        if not session_info:
            logger.warning(f"No browser context found for session {session_id}")
            return
        context_id = session_info["context_id"]
        browser_id = session_info["browser_id"]
        try:
            # Get the browser instance
            browser = browser_pool.browsers.get(browser_id)
            if browser:
                # Close the context
                await browser.close_context(context_id)
            # Remove the session mapping
            del self.session_contexts[session_id]
            logger.info(f"Closed browser context for session {session_id}")
        except Exception as e:
            logger.error(f"Error closing browser context: {str(e)}")
            # Still remove the session mapping
            if session_id in self.session_contexts:
                del self.session_contexts[session_id]
class AuthManager:
    """Manager for authentication and authorization"""
    def __init__(self):
        """Initialize the auth manager"""
        pass
    async def get_user(self, username: str) -> Optional[User]:
        """
        Get a user by username
        Args:
            username: Username
        Returns:
            User object or None if not found
        """
        user_data = fake_users_db.get(username)
        if user_data:
            return User(**user_data)
        return None
    async def authenticate_user(self, username: str, password: str) -> Optional[User]:
        """
        Authenticate a user
        Args:
            username: Username
            password: Password
        Returns:
            User object if authentication succeeds, None otherwise
        """
        # For demo, any password works
        user = await self.get_user(username)
        if not user:
            return None
        return user
    async def create_access_token(
        self, 
        data: Dict[str, Any], 
        expires_delta: Optional[timedelta] = None
    ) -> str:
        """
        Create an access token
        Args:
            data: Claims to include in the token
            expires_delta: Token expiration time
        Returns:
            JWT token
        """
        to_encode = data.copy()
        # Set expiration
        if expires_delta:
            expire = datetime.utcnow() + expires_delta
        else:
            expire = datetime.utcnow() + timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)
        to_encode.update({"exp": expire})
        # Create the token
        encoded_jwt = jwt.encode(to_encode, JWT_SECRET_KEY, algorithm=JWT_ALGORITHM)
        return encoded_jwt
    async def create_refresh_token(self, data: Dict[str, Any]) -> str:
        """
        Create a refresh token
        Args:
            data: Claims to include in the token
        Returns:
            JWT token
        """
        to_encode = data.copy()
        # Set expiration
        expire = datetime.utcnow() + timedelta(days=REFRESH_TOKEN_EXPIRE_DAYS)
        to_encode.update({"exp": expire, "refresh": True})
        # Create the token
        encoded_jwt = jwt.encode(to_encode, JWT_SECRET_KEY, algorithm=JWT_ALGORITHM)
        return encoded_jwt
    async def decode_token(self, token: str) -> Dict[str, Any]:
        """
        Decode a JWT token
        Args:
            token: JWT token
        Returns:
            Token claims
        Raises:
            MCPBrowserException: If token is invalid
        """
        try:
            payload = jwt.decode(token, JWT_SECRET_KEY, algorithms=[JWT_ALGORITHM])
            return payload
        except jwt.ExpiredSignatureError:
            raise MCPBrowserException(
                error_code=ErrorCode.AUTH_TOKEN_EXPIRED,
                message="Token has expired"
            )
        except jwt.InvalidTokenError:
            raise MCPBrowserException(
                error_code=ErrorCode.AUTH_INVALID_TOKEN,
                message="Invalid token"
            )
    async def get_current_user(self, token: str = Depends(oauth2_scheme)) -> User:
        """
        Get the current user from a token
        Args:
            token: JWT token
        Returns:
            User object
        Raises:
            HTTPException: If token is invalid or user not found
        """
        try:
            payload = await self.decode_token(token)
            username = payload.get("sub")
            if username is None:
                raise MCPBrowserException(
                    error_code=ErrorCode.AUTH_INVALID_TOKEN,
                    message="Token missing username"
                )
            user = await self.get_user(username)
            if user is None:
                raise MCPBrowserException(
                    error_code=ErrorCode.AUTH_INVALID_TOKEN,
                    message="User not found"
                )
            return user
        except MCPBrowserException as e:
            raise e.to_http_exception()
    async def get_current_active_user(self, current_user: User = Depends(get_current_user)) -> User:
        """
        Check if the current user is active
        Args:
            current_user: User object
        Returns:
            User object if active
        Raises:
            HTTPException: If user is disabled
        """
        if current_user.disabled:
            raise MCPBrowserException(
                error_code=ErrorCode.AUTH_USER_DISABLED,
                message="Inactive user"
            ).to_http_exception()
        return current_user
    def has_permission(self, user: User, required_permission: str) -> bool:
        """
        Check if a user has a permission
        Args:
            user: User object
            required_permission: Required permission
        Returns:
            True if user has permission, False otherwise
        """
        return required_permission in user.permissions or "admin" in user.permissions
# Create global instances
browser_manager = BrowserManager()
auth_manager = AuthManager()
def configure_app(app: FastAPI) -> FastAPI:
    """
    Configure the FastAPI app with lifespan event handlers
    Args:
        app: FastAPI app
    Returns:
        FastAPI app with lifespan configured
    """
    # Define lifespan context manager for this app
    @asynccontextmanager
    async def lifespan(app: FastAPI) -> AsyncGenerator[None, None]:
        """Lifespan context manager for startup and shutdown events"""
        # Startup: Initialize services
        max_browsers = int(os.environ.get("MAX_BROWSERS", 10))
        idle_timeout = int(os.environ.get("IDLE_TIMEOUT", 300))
        await browser_manager.initialize(max_browsers, idle_timeout)
        logger.info("Integration services initialized")
        yield  # Run the application
        # Shutdown: Clean up resources
        await browser_manager.shutdown()
        logger.info("Integration services shut down")
    # Configure app with lifespan
    app.router.lifespan_context = lifespan
    return app
# Export components and functions
__all__ = [
    "browser_manager",
    "auth_manager",
    "configure_app",
    "with_retry",
    "handle_exceptions",
    "DEFAULT_RETRY_CONFIG"
]
</file>

<file path="src/main.py">
#!/usr/bin/env python3
"""
MCP Browser - A browser automation server
This module provides a FastAPI server with browser automation capabilities.
"""
import os
import logging
from typing import Dict, List, Optional, Any, AsyncGenerator
import json
import time
import uvicorn
from fastapi import FastAPI, HTTPException, Depends, WebSocket, status, Body, Request, Response
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, JSONResponse
from pydantic import BaseModel
from contextlib import asynccontextmanager
from fastapi.middleware.base import BaseHTTPMiddleware
from rate_limiter import RateLimiter
# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("mcp-browser")
# App state
app_state = {}
# Models
class Token(BaseModel):
    access_token: str
    token_type: str
class User(BaseModel):
    username: str
    email: Optional[str] = None
    full_name: Optional[str] = None
    disabled: Optional[bool] = None
    permissions: List[str] = []
class BrowserNavigation(BaseModel):
    url: str
    timeout: Optional[int] = 30
    wait_until: Optional[str] = "networkidle"
class BrowserSelector(BaseModel):
    selector: str
    timeout: Optional[int] = 30
class BrowserClick(BrowserSelector):
    force: Optional[bool] = False
class BrowserType(BrowserSelector):
    text: str
    delay: Optional[int] = 0
# Initialize rate limiter
rate_limiter = RateLimiter()
class RateLimitMiddleware(BaseHTTPMiddleware):
    """Middleware to add rate limit headers to responses"""
    async def dispatch(self, request: Request, call_next):
        response = await call_next(request)
        # Add rate limit headers if present
        if hasattr(request.state, "rate_limit_headers"):
            for name, value in request.state.rate_limit_headers.items():
                response.headers[name] = value
        return response
# Define lifespan context manager
@asynccontextmanager
async def lifespan(app: FastAPI) -> AsyncGenerator[None, None]:
    """Lifespan context manager for startup and shutdown events"""
    global app_state
    # Startup: Initialize services
    app_state = {}
    # Initialize app state here
    logger.info("MCP Browser server started")
    # Add rate limit middleware
    app.add_middleware(RateLimitMiddleware)
    yield  # Run the application
    # Shutdown: Cleanup resources
    # Cleanup resources here
    logger.info("MCP Browser server shut down")
# Create FastAPI app with lifespan
app = FastAPI(
    title="MCP Browser",
    description="Browser automation server for MCP",
    version="0.1.0",
    lifespan=lifespan
)
# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
# Define auth functions
def create_access_token(data: dict, expires_delta: Optional[int] = None):
    """Create a JWT access token"""
    # This is a placeholder for the real implementation
    return "placeholder_token"
async def get_current_user(token: str):
    """Get the current user from JWT token"""
    # This is a placeholder for the real implementation
    return User(username="test_user", permissions=["browser:full"])
async def get_current_active_user(current_user: User = Depends(get_current_user)):
    """Check if the user is active"""
    if current_user.disabled:
        raise HTTPException(status_code=400, detail="Inactive user")
    return current_user
# Endpoints
@app.get("/", response_class=HTMLResponse)
async def root():
    """Root endpoint with HTML response"""
    return """
    <html>
    <head>
        <title>MCP Browser</title>
    </head>
    <body>
            <h1>MCP Browser Server</h1>
            <p>Browser automation server for MCP</p>
    </body>
    </html>
    """
@app.get("/api/status")
async def status():
    """Get server status"""
    return {"status": "ok"}
@app.post("/token", response_model=Token)
async def login_for_access_token(username: str = Body(...), password: str = Body(...)):
    """Generate access token for API authentication"""
    # This is a placeholder for the real authentication
    access_token = create_access_token(
        data={"sub": username, "permissions": ["browser:full"]}
    )
    return {"access_token": access_token, "token_type": "bearer"}
@app.get("/users/me", response_model=User)
async def get_user_me(current_user: User = Depends(get_current_active_user)):
    """Get current user information"""
    return current_user
@app.post("/api/browser/navigate")
@rate_limiter.limit("50/minute", exempt_with_token=True)
async def navigate(params: BrowserNavigation, current_user: User = Depends(get_current_active_user)):
    """Navigate to URL"""
    logger.info(f"Navigating to {params.url}")
    return {"status": "success", "url": params.url}
@app.post("/api/browser/back")
async def back(current_user: User = Depends(get_current_active_user)):
    """Go back in browser history"""
    logger.info("Going back in history")
    return {"status": "success"}
@app.post("/api/browser/forward")
async def forward(current_user: User = Depends(get_current_active_user)):
    """Go forward in browser history"""
    logger.info("Going forward in history")
    return {"status": "success"}
@app.post("/api/browser/refresh")
async def refresh(current_user: User = Depends(get_current_active_user)):
    """Refresh current page"""
    logger.info("Refreshing page")
    return {"status": "success"}
@app.post("/api/browser/click")
async def click(params: BrowserClick, current_user: User = Depends(get_current_active_user)):
    """Click on element"""
    logger.info(f"Clicking element: {params.selector}")
    return {"status": "success", "selector": params.selector}
@app.post("/api/browser/type")
async def type_text(params: BrowserType, current_user: User = Depends(get_current_active_user)):
    """Type text into element"""
    logger.info(f"Typing '{params.text}' into element: {params.selector}")
    return {"status": "success", "selector": params.selector, "text": params.text}
# WebSocket endpoints
@app.websocket("/ws")
@rate_limiter.limit("100/minute", exempt_with_token=True)
async def websocket_endpoint(websocket: WebSocket):
    """WebSocket endpoint for real-time communication"""
    await websocket.accept()
    try:
        while True:
            data = await websocket.receive_text()
            await websocket.send_text(f"Echo: {data}")
    except Exception as e:
        logger.error(f"WebSocket error: {str(e)}")
    finally:
        await websocket.close()
@app.websocket("/ws/browser/events")
@rate_limiter.limit("100/minute", exempt_with_token=True)
async def websocket_browser_events(websocket: WebSocket):
    """WebSocket endpoint for browser event subscriptions"""
    await websocket.accept()
    # Generate a unique client ID
    client_id = f"client_{int(time.time())}"
    try:
        # Send welcome message
        await websocket.send_json({
            "type": "connection",
            "client_id": client_id,
            "message": "Connected to MCP Browser Event Subscription Service",
            "timestamp": time.time()
        })
        # Process messages
        while True:
            data = await websocket.receive_text()
            try:
                message = json.loads(data)
                action = message.get("action", "")
                if action == "subscribe":
                    # Handle subscription request
                    event_types = message.get("event_types", [])
                    subscription_id = f"sub_{int(time.time())}"
                    # Send subscription confirmation
                    await websocket.send_json({
                        "type": "subscription",
                        "subscription_id": subscription_id,
                        "event_types": event_types,
                        "timestamp": time.time()
                    })
                elif action == "execute":
                    # Handle execute command
                    command = message.get("command", "")
                    params = message.get("params", {})
                    # Send command acknowledgment
                    await websocket.send_json({
                        "type": "command_executed",
                        "command": command,
                        "success": True,
                        "timestamp": time.time()
                    })
                    # If navigation command, send simulated page load event
                    if command == "navigate" and "url" in params:
                        await websocket.send_json({
                            "type": "PAGE",
                            "event": "page.load",
                            "timestamp": time.time(),
                            "data": {
                                "url": params["url"],
                                "title": f"Page Title for {params['url']}",
                                "status": 200,
                                "timestamp": time.time()
                            }
                        })
                else:
                    # Echo unknown messages
                    await websocket.send_text(f"Echo: {data}")
            except json.JSONDecodeError:
                await websocket.send_text(f"Invalid JSON: {data}")
    except Exception as e:
        logger.error(f"WebSocket error: {str(e)}")
    finally:
        await websocket.close()
# Run server
if __name__ == "__main__":
    uvicorn.run(
        "main:app",
        host=os.environ.get("HOST", "0.0.0.0"),
        port=int(os.environ.get("PORT", 8000)),
        reload=bool(os.environ.get("RELOAD", True))
    )
</file>

<file path="src/rate_limiter.py">
#!/usr/bin/env python3
"""
Rate Limiter for MCP Browser
This module provides rate limiting functionality using a sliding window algorithm.
"""
import time
import logging
import asyncio
from typing import Dict, Optional, Tuple, List
from dataclasses import dataclass
from collections import defaultdict
import re
from fastapi import Request, HTTPException
from error_handler import MCPBrowserException, ErrorCode
# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("rate-limiter")
@dataclass
class RateLimitConfig:
    """Configuration for rate limiting"""
    requests: int
    window: int  # Window size in seconds
    exempt_with_token: bool = False
class RateLimitExceeded(MCPBrowserException):
    """Exception raised when rate limit is exceeded"""
    def __init__(self, limit: int, reset_time: int):
        super().__init__(
            error_code=ErrorCode.RATE_LIMIT_EXCEEDED,
            message=f"Rate limit exceeded. Limit is {limit} requests. Reset in {reset_time} seconds."
        )
        self.limit = limit
        self.reset_time = reset_time
class SlidingWindowCounter:
    """Implements sliding window rate limiting algorithm"""
    def __init__(self, window_size: int):
        """
        Initialize sliding window counter
        Args:
            window_size: Window size in seconds
        """
        self.window_size = window_size
        self.requests: List[float] = []
        self._cleanup_lock = asyncio.Lock()
    async def add_request(self) -> bool:
        """
        Add a request to the counter
        Returns:
            True if request was added, False if window is full
        """
        now = time.time()
        async with self._cleanup_lock:
            # Clean up old requests
            cutoff = now - self.window_size
            self.requests = [ts for ts in self.requests if ts > cutoff]
            # Add new request
            self.requests.append(now)
        return True
    def get_count(self) -> int:
        """Get current request count in window"""
        now = time.time()
        cutoff = now - self.window_size
        return sum(1 for ts in self.requests if ts > cutoff)
    def time_to_reset(self) -> int:
        """Get seconds until window resets"""
        if not self.requests:
            return 0
        now = time.time()
        oldest = min(self.requests)
        return max(0, int(oldest + self.window_size - now))
class RateLimiter:
    """Rate limiter for FastAPI endpoints"""
    def __init__(self):
        """Initialize rate limiter"""
        self.limiters: Dict[str, Dict[str, SlidingWindowCounter]] = defaultdict(dict)
        self.configs: Dict[str, RateLimitConfig] = {}
        self._cleanup_task = None
        self._cleanup_lock = asyncio.Lock()
    def parse_limit(self, limit: str) -> Tuple[int, int]:
        """
        Parse rate limit string (e.g., "100/minute", "10/second")
        Args:
            limit: Rate limit string
        Returns:
            Tuple of (requests, window_size_in_seconds)
        """
        match = re.match(r"(\d+)/(\w+)", limit)
        if not match:
            raise ValueError(f"Invalid rate limit format: {limit}")
        requests = int(match.group(1))
        unit = match.group(2).lower()
        if unit == "second":
            window = 1
        elif unit == "minute":
            window = 60
        elif unit == "hour":
            window = 3600
        elif unit == "day":
            window = 86400
        else:
            raise ValueError(f"Invalid time unit: {unit}")
        return requests, window
    def get_client_id(self, request: Request) -> str:
        """
        Get client identifier from request
        Args:
            request: FastAPI request object
        Returns:
            Client identifier string
        """
        # Try X-Forwarded-For first
        forwarded_for = request.headers.get("X-Forwarded-For")
        if forwarded_for:
            return forwarded_for.split(",")[0].strip()
        # Fall back to client host
        return request.client.host if request.client else "unknown"
    def is_authenticated(self, request: Request) -> bool:
        """
        Check if request is authenticated
        Args:
            request: FastAPI request object
        Returns:
            True if request has valid auth token
        """
        auth = request.headers.get("Authorization")
        return bool(auth and auth.startswith("Bearer "))
    async def is_rate_limited(
        self,
        endpoint: str,
        client_id: str,
        config: RateLimitConfig
    ) -> Tuple[bool, int, int]:
        """
        Check if request should be rate limited
        Args:
            endpoint: Endpoint identifier
            client_id: Client identifier
            config: Rate limit configuration
        Returns:
            Tuple of (is_limited, remaining, reset_time)
        """
        # Get or create limiter for this client
        if client_id not in self.limiters[endpoint]:
            self.limiters[endpoint][client_id] = SlidingWindowCounter(config.window)
        limiter = self.limiters[endpoint][client_id]
        # Check current count
        count = limiter.get_count()
        if count >= config.requests:
            return True, 0, limiter.time_to_reset()
        # Add request
        await limiter.add_request()
        return False, config.requests - count - 1, limiter.time_to_reset()
    async def cleanup_old_entries(self):
        """Clean up expired entries periodically"""
        try:
            while True:
                await asyncio.sleep(60)  # Run every minute
                async with self._cleanup_lock:
                    now = time.time()
                    for endpoint in list(self.limiters.keys()):
                        config = self.configs.get(endpoint)
                        if not config:
                            continue
                        for client_id in list(self.limiters[endpoint].keys()):
                            limiter = self.limiters[endpoint][client_id]
                            if not limiter.requests or max(limiter.requests) < now - config.window:
                                del self.limiters[endpoint][client_id]
                        if not self.limiters[endpoint]:
                            del self.limiters[endpoint]
        except asyncio.CancelledError:
            logger.info("Cleanup task cancelled")
        except Exception as e:
            logger.error(f"Error in cleanup task: {str(e)}", exc_info=True)
    def limit(self, limit: str, exempt_with_token: bool = False):
        """
        Rate limiting decorator
        Args:
            limit: Rate limit string (e.g., "100/minute")
            exempt_with_token: Whether to exempt authenticated requests
        Returns:
            Decorator function
        """
        requests, window = self.parse_limit(limit)
        def decorator(func):
            # Store config for this endpoint
            endpoint = func.__name__
            self.configs[endpoint] = RateLimitConfig(
                requests=requests,
                window=window,
                exempt_with_token=exempt_with_token
            )
            # Start cleanup task if not running
            if not self._cleanup_task:
                self._cleanup_task = asyncio.create_task(self.cleanup_old_entries())
            async def wrapper(request: Request, *args, **kwargs):
                config = self.configs[endpoint]
                # Check for auth exemption
                if config.exempt_with_token and self.is_authenticated(request):
                    return await func(request, *args, **kwargs)
                # Get client ID and check rate limit
                client_id = self.get_client_id(request)
                is_limited, remaining, reset_time = await self.is_rate_limited(
                    endpoint, client_id, config
                )
                # Set rate limit headers
                request.state.rate_limit_headers = {
                    "X-RateLimit-Limit": str(config.requests),
                    "X-RateLimit-Remaining": str(remaining),
                    "X-RateLimit-Reset": str(reset_time)
                }
                if is_limited:
                    raise RateLimitExceeded(config.requests, reset_time)
                return await func(request, *args, **kwargs)
            return wrapper
        return decorator
</file>

<file path="src/simple_test.py">
#!/usr/bin/env python3
"""
Simple test script for MCP Browser API endpoints
"""
import os
import sys
import requests
import json
from datetime import datetime
# API Base URL
API_BASE_URL = "http://localhost:7665"
def log_message(msg):
    """Log a message with timestamp"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{timestamp}] {msg}")
def check_api_status():
    """Check if the API is running"""
    try:
        response = requests.get(f"{API_BASE_URL}/api/status")
        if response.status_code == 200:
            log_message(f"API Status: {response.json()}")
            return True
        else:
            log_message(f"API Status check failed: {response.status_code} - {response.text}")
            return False
    except Exception as e:
        log_message(f"Error checking API status: {e}")
        return False
def test_api():
    """Run basic API test"""
    log_message("Starting API test...")
    # Check if API is running
    if not check_api_status():
        log_message("API is not running or not responding. Aborting test.")
        return False
    log_message("API is running. Basic test passed!")
    return True
if __name__ == "__main__":
    success = test_api()
    sys.exit(0 if success else 1)
</file>

<file path="src/test_api.py">
#!/usr/bin/env python3
"""
Test script for MCP Browser API endpoints
"""
import os
import sys
import requests
import json
import base64
import time
from datetime import datetime
# API Base URL - can be overridden by environment variable
API_BASE_URL = os.environ.get("API_BASE_URL", "http://localhost:7665")
# Output directories
OUTPUT_DIR = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "output")
SCREENSHOTS_DIR = os.path.join(OUTPUT_DIR, "screenshots")
DOM_DIR = os.path.join(OUTPUT_DIR, "dom")
CSS_DIR = os.path.join(OUTPUT_DIR, "css")
# Create output directories if they don't exist
os.makedirs(SCREENSHOTS_DIR, exist_ok=True)
os.makedirs(DOM_DIR, exist_ok=True)
os.makedirs(CSS_DIR, exist_ok=True)
def log_message(msg):
    """Log a message with timestamp"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{timestamp}] {msg}")
def check_api_status():
    """Check if the API is running"""
    try:
        response = requests.get(f"{API_BASE_URL}/api/status")
        if response.status_code == 200:
            status_data = response.json()
            log_message(f"API Status: {status_data}")
            return True
        else:
            log_message(f"API Status check failed: {response.status_code} - {response.text}")
            return False
    except Exception as e:
        log_message(f"Error checking API status: {e}")
        return False
def test_screenshot_capture():
    """Test the screenshot capture API"""
    log_message("Testing screenshot capture API...")
    # Test parameters
    test_url = "https://example.com"
    viewport = {"width": 1280, "height": 800}
    try:
        response = requests.post(
            f"{API_BASE_URL}/api/screenshots/capture",
            params={
                "url": test_url,
                "full_page": True,
                "format": "png"
            },
            json={
                "viewport": viewport
            }
        )
        if response.status_code == 200:
            result = response.json()
            if result.get("success"):
                # Save the screenshot to a file for verification
                if "screenshot" in result:
                    img_data = base64.b64decode(result["screenshot"])
                    timestamp = int(time.time())
                    filename = f"screenshot_{timestamp}.png"
                    filepath = os.path.join(SCREENSHOTS_DIR, filename)
                    with open(filepath, "wb") as f:
                        f.write(img_data)
                    log_message(f"Screenshot saved to {filepath}")
                    return True
                else:
                    log_message("Screenshot data missing from response")
                    return False
            else:
                log_message(f"Screenshot capture failed: {result.get('error', 'Unknown error')}")
                return False
        else:
            log_message(f"API request failed: {response.status_code} - {response.text}")
            return False
    except Exception as e:
        log_message(f"Error testing screenshot capture: {e}")
        return False
def test_dom_extraction():
    """Test the DOM extraction API"""
    log_message("Testing DOM extraction API...")
    # Test parameters
    test_url = "https://example.com"
    selector = "h1"  # Example.com has an h1 element
    try:
        response = requests.post(
            f"{API_BASE_URL}/api/dom/extract",
            params={
                "url": test_url,
                "selector": selector,
                "include_styles": True,
                "include_attributes": True
            }
        )
        if response.status_code == 200:
            result = response.json()
            if result.get("success"):
                # Save the DOM info to a file for verification
                if "dom" in result:
                    timestamp = int(time.time())
                    filename = f"dom_extraction_{timestamp}.json"
                    filepath = os.path.join(DOM_DIR, filename)
                    with open(filepath, "w") as f:
                        json.dump(result["dom"], f, indent=2)
                    log_message(f"DOM extraction saved to {filepath}")
                    return True
                else:
                    log_message("DOM data missing from response")
                    return False
            else:
                log_message(f"DOM extraction failed: {result.get('error', 'Unknown error')}")
                return False
        else:
            log_message(f"API request failed: {response.status_code} - {response.text}")
            return False
    except Exception as e:
        log_message(f"Error testing DOM extraction: {e}")
        return False
def test_css_analysis():
    """Test the CSS analysis API"""
    log_message("Testing CSS analysis API...")
    # Test parameters
    url = "https://example.com"
    selector = "p"
    check_accessibility = True
    try:
        # Make the API call
        response = requests.post(
            f"{API_BASE_URL}/api/css/analyze",
            params={"url": url, "selector": selector, "check_accessibility": check_accessibility}
        )
        # Check response
        if response.status_code == 200:
            css_data = response.json()
            log_message(f"CSS analysis successful")
            # Save the response to file
            timestamp = int(time.time())
            output_file = os.path.join(CSS_DIR, f"css_analysis_{timestamp}.json")
            with open(output_file, "w") as f:
                json.dump(css_data, f, indent=2)
            log_message(f"CSS analysis data saved to {output_file}")
            return True
        else:
            log_message(f"CSS analysis failed: {response.status_code} - {response.text}")
            return False
    except Exception as e:
        log_message(f"Error testing CSS analysis API: {e}")
        return False
def test_accessibility():
    """Test the accessibility testing API"""
    log_message("Testing accessibility testing API...")
    # Test parameters
    url = "https://example.com"
    standard = "wcag2aa"
    include_html = True
    include_warnings = True
    try:
        # Make the API call
        response = requests.post(
            f"{API_BASE_URL}/api/accessibility/test",
            params={
                "url": url, 
                "standard": standard, 
                "include_html": include_html,
                "include_warnings": include_warnings
            }
        )
        # Check response
        if response.status_code == 200:
            accessibility_data = response.json()
            log_message(f"Accessibility testing successful")
            # Save the response to file
            timestamp = int(time.time())
            output_dir = os.path.join(OUTPUT_DIR, "accessibility")
            os.makedirs(output_dir, exist_ok=True)
            output_file = os.path.join(output_dir, f"accessibility_test_{timestamp}.json")
            with open(output_file, "w") as f:
                json.dump(accessibility_data, f, indent=2)
            log_message(f"Accessibility test data saved to {output_file}")
            return True
        else:
            log_message(f"Accessibility testing failed: {response.status_code} - {response.text}")
            return False
    except Exception as e:
        log_message(f"Error testing accessibility API: {e}")
        return False
def test_responsive():
    """Test the responsive design testing API"""
    log_message("Testing responsive design testing API...")
    # Test parameters
    url = "https://example.com"
    viewports = [
        {"width": 375, "height": 667},  # Mobile
        {"width": 1366, "height": 768}  # Laptop
    ]
    selectors = ["h1", "p"]
    try:
        # Make the API call
        response = requests.post(
            f"{API_BASE_URL}/api/responsive/test",
            params={
                "url": url,
                "include_screenshots": True,
                "compare_elements": True
            },
            json={
                "viewports": viewports,
                "selectors": selectors
            }
        )
        # Check response
        if response.status_code == 200:
            responsive_data = response.json()
            log_message(f"Responsive design testing successful")
            # Save the response to file
            timestamp = int(time.time())
            output_dir = os.path.join(OUTPUT_DIR, "responsive")
            os.makedirs(output_dir, exist_ok=True)
            output_file = os.path.join(output_dir, f"responsive_test_summary_{timestamp}.json")
            with open(output_file, "w") as f:
                json.dump(responsive_data, f, indent=2)
            log_message(f"Responsive test data saved to {output_file}")
            return True
        else:
            log_message(f"Responsive design testing failed: {response.status_code} - {response.text}")
            return False
    except Exception as e:
        log_message(f"Error testing responsive design API: {e}")
        return False
def run_tests():
    """Run all the API tests"""
    # Check if the API is running
    if not check_api_status():
        log_message("API is not running. Exiting.")
        sys.exit(1)
    # Keep track of test results
    test_results = {
        "screenshot_capture": None,
        "dom_extraction": None,
        "css_analysis": None,
        "accessibility_testing": None,
        "responsive_testing": None
    }
    # Run tests
    test_results["screenshot_capture"] = test_screenshot_capture()
    test_results["dom_extraction"] = test_dom_extraction()
    test_results["css_analysis"] = test_css_analysis()
    test_results["accessibility_testing"] = test_accessibility()
    test_results["responsive_testing"] = test_responsive()
    # Report results
    log_message("\n--- Test Results ---")
    all_passed = True
    for test_name, result in test_results.items():
        status = "PASSED" if result else "FAILED"
        log_message(f"{test_name}: {status}")
        if not result:
            all_passed = False
    # Exit with appropriate status code
    if all_passed:
        log_message("All tests passed!")
        sys.exit(0)
    else:
        log_message("Some tests failed. Check the logs for details.")
        sys.exit(1)
if __name__ == "__main__":
    success = run_tests()
    sys.exit(0 if success else 1)
</file>

<file path="src/test_event_subscription.py">
#!/usr/bin/env python3
"""
Test script for MCP Browser WebSocket event subscriptions
This script connects to the MCP Browser server's WebSocket event endpoint,
subscribes to browser events, and displays them in real-time.
"""
import asyncio
import json
import sys
import argparse
import logging
import websockets
from datetime import datetime
# Try to import colorama for colored output
try:
    from colorama import Fore, Style, init
    # Initialize colorama
    init()
    HAS_COLORAMA = True
except ImportError:
    # Fallback if colorama is not available
    print("Warning: colorama not found. Using plain text output.")
    HAS_COLORAMA = False
    # Create dummy color objects
    class DummyColors:
        def __getattr__(self, name):
            return ""
    Fore = DummyColors()
    Style = DummyColors()
# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
logger = logging.getLogger(__name__)
# Event type colors
EVENT_COLORS = {
    "PAGE": Fore.BLUE,
    "NETWORK": Fore.CYAN,
    "CONSOLE": Fore.GREEN,
    "DOM": Fore.MAGENTA,
    "ERROR": Fore.RED,
    "DEFAULT": Fore.WHITE,
}
# Parse command line arguments
parser = argparse.ArgumentParser(description="MCP Browser Event Subscription Test")
parser.add_argument(
    "--url", "-s", 
    default="ws://localhost:7665/ws/browser/events", 
    help="WebSocket URL for the browser events endpoint"
)
parser.add_argument(
    "--types", "-t", 
    default="PAGE,NETWORK,CONSOLE,DOM", 
    help="Comma-separated list of event types to subscribe to"
)
parser.add_argument(
    "--filter-url", "-f", 
    default="", 
    help="Filter events by URL pattern"
)
parser.add_argument(
    "--target-url", 
    default="", 
    help="URL to navigate to after connecting"
)
parser.add_argument(
    "--timeout", 
    type=int, 
    default=0, 
    help="Exit after this many seconds (0 means run indefinitely)"
)
args = parser.parse_args()
async def subscribe_to_events(ws, event_types, url_pattern=None):
    """Subscribe to browser events"""
    subscription_data = {
        "action": "subscribe",
        "event_types": event_types.split(","),
    }
    if url_pattern:
        subscription_data["filters"] = {"url_pattern": url_pattern}
    await ws.send(json.dumps(subscription_data))
    response = await ws.recv()
    logger.info(f"Subscription response: {response}")
    return json.loads(response)
async def print_event(event_data):
    """Format and print an event"""
    try:
        event_json = json.loads(event_data)
        timestamp = datetime.fromtimestamp(event_json.get("timestamp", 0)).strftime("%H:%M:%S")
        event_type = event_json.get("type", "DEFAULT")
        event_name = event_json.get("event", "unknown")
        page_id = event_json.get("page_id", "unknown")
        data = event_json.get("data", {})
        # Get the appropriate color
        color = EVENT_COLORS.get(event_type, EVENT_COLORS["DEFAULT"])
        # Print the event
        print(f"{color}[{timestamp}] {event_type}.{event_name} {Style.RESET_ALL}")
        # Format the data nicely
        if isinstance(data, dict):
            for key, value in data.items():
                # Handle nested data for better display
                if isinstance(value, dict) and len(value) > 0:
                    print(f"  {key}:")
                    for subkey, subvalue in value.items():
                        if isinstance(subvalue, str) and len(subvalue) > 100:
                            subvalue = subvalue[:100] + "..."
                        print(f"    {subkey}: {subvalue}")
                else:
                    if isinstance(value, str) and len(value) > 100:
                        value = value[:100] + "..."
                    print(f"  {key}: {value}")
        else:
            print(f"  {data}")
        print("-" * 80)
    except Exception as e:
        logger.error(f"Error processing event: {e}")
        logger.error(f"Raw event data: {event_data}")
async def timeout_handler():
    """Handle timeout and exit gracefully"""
    if args.timeout > 0:
        logger.info(f"Will exit after {args.timeout} seconds")
        await asyncio.sleep(args.timeout)
        logger.info("Timeout reached, exiting")
        print(f"\n{Fore.YELLOW}Test completed after {args.timeout} seconds{Style.RESET_ALL}")
        sys.exit(0)
async def main():
    """Main function"""
    try:
        logger.info(f"Connecting to WebSocket at {args.url}")
        # Start timeout handler if specified
        if args.timeout > 0:
            asyncio.create_task(timeout_handler())
        async with websockets.connect(args.url) as ws:
            logger.info("Connected to WebSocket server")
            # Subscribe to events
            subscription = await subscribe_to_events(ws, args.types, args.filter_url)
            subscription_id = subscription.get("subscription_id", "unknown")
            logger.info(f"Subscribed to events with ID: {subscription_id}")
            # Navigate to target URL if provided
            if args.target_url:
                navigate_msg = {
                    "action": "execute",
                    "command": "navigate",
                    "params": {"url": args.target_url}
                }
                await ws.send(json.dumps(navigate_msg))
                logger.info(f"Navigating to {args.target_url}")
            # Print initial message
            print("\n" + "=" * 80)
            print(f"{Fore.YELLOW}MCP Browser Event Subscription Test{Style.RESET_ALL}")
            print(f"Listening for events of types: {args.types}")
            if args.filter_url:
                print(f"Filtering by URL pattern: {args.filter_url}")
            if args.timeout > 0:
                print(f"Will exit after {args.timeout} seconds")
            print("=" * 80 + "\n")
            # Receive events
            while True:
                message = await ws.recv()
                await print_event(message)
    except websockets.exceptions.ConnectionClosed:
        logger.error("WebSocket connection closed")
    except Exception as e:
        logger.error(f"Error: {e}")
if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nScript terminated by user")
        sys.exit(0)
</file>

<file path="src/test_events.html">
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>MCP Browser Events Test</title>
    <style>
      body {
        font-family: Arial, sans-serif;
        max-width: 800px;
        margin: 0 auto;
        padding: 20px;
      }
      h1 {
        color: #333;
      }
      .control-panel {
        margin: 20px 0;
        padding: 15px;
        border: 1px solid #ddd;
        border-radius: 5px;
        background-color: #f8f8f8;
      }
      button {
        padding: 8px 15px;
        margin-right: 10px;
        background-color: #4caf50;
        color: white;
        border: none;
        border-radius: 4px;
        cursor: pointer;
      }
      button:hover {
        background-color: #45a049;
      }
      #eventLog {
        margin-top: 20px;
        height: 300px;
        overflow-y: auto;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 5px;
        background-color: #f5f5f5;
      }
      .event {
        margin-bottom: 5px;
        padding: 5px;
        border-bottom: 1px solid #eee;
      }
      .error {
        color: red;
      }
      .warning {
        color: orange;
      }
      .info {
        color: blue;
      }
    </style>
  </head>
  <body>
    <h1>MCP Browser Events Test</h1>
    <div class="control-panel">
      <h2>Event Generators</h2>
      <button id="btnConsoleLog">Console Log</button>
      <button id="btnConsoleError">Console Error</button>
      <button id="btnConsoleWarn">Console Warning</button>
      <button id="btnAjaxRequest">AJAX Request</button>
      <button id="btnDOMChange">Change DOM</button>
      <button id="btnNavigate">Simulate Navigation</button>
    </div>
    <div class="control-panel">
      <h2>Dynamic Content</h2>
      <div id="dynamicContent">
        <p>This content will change when you click the "Change DOM" button.</p>
      </div>
    </div>
    <div>
      <h2>Event Log</h2>
      <div id="eventLog"></div>
    </div>
    <script>
      // Helper function to log events
      function logEvent(message, type = "info") {
        const eventLog = document.getElementById("eventLog");
        const eventElement = document.createElement("div");
        eventElement.className = `event ${type}`;
        eventElement.textContent = `[${new Date().toLocaleTimeString()}] ${message}`;
        eventLog.prepend(eventElement);
      }
      // Console events
      document.getElementById("btnConsoleLog").addEventListener("click", () => {
        console.log("This is a console log message");
        logEvent("Console log message sent");
      });
      document
        .getElementById("btnConsoleError")
        .addEventListener("click", () => {
          console.error("This is a console error message");
          logEvent("Console error message sent", "error");
        });
      document
        .getElementById("btnConsoleWarn")
        .addEventListener("click", () => {
          console.warn("This is a console warning message");
          logEvent("Console warning message sent", "warning");
        });
      // AJAX request
      document
        .getElementById("btnAjaxRequest")
        .addEventListener("click", () => {
          logEvent("Making AJAX request to example.com");
          fetch("https://example.com")
            .then((response) => {
              logEvent(
                `Received response: ${response.status} ${response.statusText}`
              );
              return response.text();
            })
            .catch((error) => {
              logEvent(`Request failed: ${error}`, "error");
            });
        });
      // DOM changes
      document.getElementById("btnDOMChange").addEventListener("click", () => {
        const dynamicContent = document.getElementById("dynamicContent");
        // Create new elements
        const newParagraph = document.createElement("p");
        newParagraph.textContent = `New paragraph added at ${new Date().toLocaleTimeString()}`;
        // Change attribute
        newParagraph.setAttribute("data-timestamp", Date.now());
        // Add to DOM
        dynamicContent.appendChild(newParagraph);
        // Change existing content
        const existingParagraphs = dynamicContent.querySelectorAll("p");
        if (existingParagraphs.length > 1) {
          existingParagraphs[0].style.color = getRandomColor();
        }
        logEvent("DOM changed");
      });
      // Simulate navigation
      document.getElementById("btnNavigate").addEventListener("click", () => {
        logEvent("Simulating navigation with window.history");
        // Push a new state to the history
        const state = { page: Math.floor(Math.random() * 100) };
        const title = "Page " + state.page;
        const url = `?page=${state.page}`;
        window.history.pushState(state, title, url);
        document.title = "MCP Browser Events Test - " + title;
        logEvent(`Navigation simulated to: ${url}`);
      });
      // Helper function to generate random colors
      function getRandomColor() {
        const letters = "0123456789ABCDEF";
        let color = "#";
        for (let i = 0; i < 6; i++) {
          color += letters[Math.floor(Math.random() * 16)];
        }
        return color;
      }
      // Log page load
      window.addEventListener("load", () => {
        logEvent("Page loaded");
      });
      // Log history changes
      window.addEventListener("popstate", (event) => {
        logEvent(`Navigation state changed: ${JSON.stringify(event.state)}`);
      });
    </script>
  </body>
</html>
</file>

<file path="src/test_integration.py">
#!/usr/bin/env python3
"""
Integration Test for MCP Browser Components
This script tests that all components work together properly.
"""
import asyncio
import json
import logging
import os
import sys
import psutil
from typing import Dict, Any, List, Optional
# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("integration-test")
# Import our components
from browser_pool import browser_pool, initialize_browser_pool, close_browser_pool
from error_handler import (
    MCPBrowserException, ErrorCode, RetryConfig, with_retry, handle_exceptions, DEFAULT_RETRY_CONFIG
)
from integration import browser_manager, auth_manager
async def test_browser_pool():
    """Test the browser pool component"""
    logger.info("Testing browser pool...")
    # Initialize browser pool with small limits for testing
    await initialize_browser_pool(max_browsers=2)
    try:
        # Get a browser instance
        browser = await browser_pool.get_browser()
        assert browser is not None, "Failed to get browser instance"
        assert browser.browser is not None, "Browser not initialized"
        assert browser.process is not None, "Browser process not tracked"
        logger.info(f"Got browser instance: {browser.id}")
        # Check resource monitoring
        metrics = browser_pool._get_browser_metrics(browser)
        assert "memory_percent" in metrics, "Memory metrics not available"
        assert "cpu_percent" in metrics, "CPU metrics not available"
        logger.info(f"Browser metrics: Memory={metrics['memory_percent']:.1f}%, CPU={metrics['cpu_percent']:.1f}%")
        # Create multiple contexts to test resource limits
        contexts = []
        for i in range(3):
            try:
                context = await browser.create_context(f"test-context-{i}")
                contexts.append(context)
                logger.info(f"Created context {i}")
            except MCPBrowserException as e:
                if e.error_code == ErrorCode.RESOURCE_LIMIT_EXCEEDED:
                    logger.info("Resource limit correctly enforced")
                    break
                raise
        # Clean up contexts
        for i, context in enumerate(contexts):
            await browser.close_context(f"test-context-{i}")
            logger.info(f"Closed context {i}")
        # Get another browser (should reuse the instance due to max_browsers=2)
        browser2 = await browser_pool.get_browser()
        assert browser2 is not None, "Failed to get second browser instance"
        assert len(browser_pool.browsers) <= 2, "Browser pool limit exceeded"
        logger.info(f"Got second browser instance: {browser2.id}")
        # Test cleanup of idle browsers
        await asyncio.sleep(2)
        await browser_pool._cleanup_idle_browsers()
        assert len(browser_pool.browsers) < 2, "Idle browsers not cleaned up"
        logger.info("Idle browser cleanup successful")
    finally:
        # Clean up
        await close_browser_pool()
        logger.info("Browser pool test passed")
async def test_resource_limits():
    """Test resource limit enforcement"""
    logger.info("Testing resource limits...")
    # Initialize browser pool with strict limits
    await initialize_browser_pool(max_browsers=1)
    browser_pool.max_memory_percent = 20.0  # Set low memory limit for testing
    try:
        # Get initial browser
        browser = await browser_pool.get_browser()
        assert browser is not None, "Failed to get browser instance"
        logger.info(f"Got initial browser: {browser.id}")
        # Try to exceed memory limit
        try:
            # Create contexts until we hit the limit
            contexts = []
            for i in range(10):  # Try to create more contexts than reasonable
                context = await browser.create_context(f"test-context-{i}")
                contexts.append((i, context))
                logger.info(f"Created context {i}")
                # Check memory usage
                metrics = browser_pool._get_browser_metrics(browser)
                logger.info(f"Memory usage: {metrics['memory_percent']:.1f}%")
                if metrics['memory_percent'] > browser_pool.max_memory_percent:
                    logger.info("Memory limit reached")
                    break
        except MCPBrowserException as e:
            assert e.error_code in [
                ErrorCode.RESOURCE_LIMIT_EXCEEDED,
                ErrorCode.BROWSER_INITIALIZATION_FAILED
            ], f"Unexpected error: {e.error_code}"
            logger.info("Resource limit correctly enforced")
        finally:
            # Clean up contexts
            if 'contexts' in locals():
                for i, context in contexts:
                    try:
                        await browser.close_context(f"test-context-{i}")
                    except Exception as e:
                        logger.warning(f"Error closing context {i}: {e}")
    finally:
        # Clean up
        await close_browser_pool()
        logger.info("Resource limits test passed")
async def test_error_handling():
    """Test error handling in browser operations"""
    logger.info("Testing error handling...")
    # Initialize browser pool
    await initialize_browser_pool(max_browsers=1)
    try:
        # Test invalid context operations
        try:
            browser = await browser_pool.get_browser()
            await browser.close_context("nonexistent-context")
        except MCPBrowserException as e:
            assert e.error_code == ErrorCode.RESOURCE_NOT_FOUND, "Wrong error code"
            logger.info("Invalid context handling passed")
        # Test resource cleanup on failure
        browser_count = len(browser_pool.browsers)
        try:
            # Force an error by closing browser then trying to use it
            await browser_pool.close_browser(browser.id)
            await browser.create_context("test-context")
        except MCPBrowserException as e:
            assert e.error_code in [
                ErrorCode.BROWSER_INITIALIZATION_FAILED,
                ErrorCode.CONTEXT_CREATION_FAILED
            ], "Wrong error code"
            assert len(browser_pool.browsers) == browser_count - 1, "Resource not cleaned up"
            logger.info("Resource cleanup on failure passed")
        # Test retry mechanism
        @with_retry(RetryConfig(max_retries=2, delay=0.1))
        async def failing_operation():
            raise MCPBrowserException(
                error_code=ErrorCode.NETWORK_ERROR,
                message="Simulated network error"
            )
        try:
            await failing_operation()
        except MCPBrowserException as e:
            assert e.error_code == ErrorCode.NETWORK_ERROR, "Wrong error code"
            logger.info("Retry mechanism passed")
    finally:
        # Clean up
        await close_browser_pool()
        logger.info("Error handling test passed")
async def test_memory_monitoring():
    """Test browser memory monitoring and limits"""
    logger.info("Testing memory monitoring...")
    await initialize_browser_pool(max_browsers=1)
    browser_pool.max_memory_percent = 50.0  # Set memory limit to 50%
    try:
        browser = await browser_pool.get_browser()
        assert browser is not None, "Failed to get browser instance"
        # Create a context and navigate to a memory-intensive page
        context = await browser.create_context("test-memory")
        page = await context.new_page()
        # Monitor memory usage
        initial_metrics = browser_pool._get_browser_metrics(browser)
        logger.info(f"Initial memory usage: {initial_metrics['memory_percent']:.1f}%")
        # Load a page that will use memory
        await page.goto("https://example.com")
        # Check memory metrics after load
        load_metrics = browser_pool._get_browser_metrics(browser)
        logger.info(f"Memory usage after load: {load_metrics['memory_percent']:.1f}%")
        assert load_metrics["memory_percent"] > 0, "Memory metrics not working"
        # Cleanup should reduce memory usage
        await browser.close_context("test-memory")
        await asyncio.sleep(1)  # Give time for cleanup
        final_metrics = browser_pool._get_browser_metrics(browser)
        logger.info(f"Final memory usage: {final_metrics['memory_percent']:.1f}%")
        assert final_metrics["memory_percent"] < load_metrics["memory_percent"], \
            "Memory not cleaned up properly"
    finally:
        await close_browser_pool()
        logger.info("Memory monitoring test passed")
async def test_process_monitoring():
    """Test browser process monitoring and cleanup"""
    logger.info("Testing process monitoring...")
    await initialize_browser_pool(max_browsers=2)
    try:
        # Get initial system process count
        initial_process_count = len(psutil.Process().children(recursive=True))
        # Create multiple browser instances
        browser1 = await browser_pool.get_browser()
        browser2 = await browser_pool.get_browser()
        # Verify processes are tracked
        assert browser1.process is not None, "Browser 1 process not tracked"
        assert browser2.process is not None, "Browser 2 process not tracked"
        # Verify process count increased
        current_process_count = len(psutil.Process().children(recursive=True))
        assert current_process_count > initial_process_count, "Browser processes not created"
        # Close one browser
        await browser_pool.close_browser(browser1.id)
        # Verify process was cleaned up
        after_close_count = len(psutil.Process().children(recursive=True))
        assert after_close_count < current_process_count, "Browser process not cleaned up"
        # Verify remaining browser still works
        context = await browser2.create_context("test-process")
        await browser2.close_context("test-process")
    finally:
        await close_browser_pool()
        logger.info("Process monitoring test passed")
async def test_cleanup_on_error():
    """Test resource cleanup when errors occur"""
    logger.info("Testing cleanup on error...")
    await initialize_browser_pool(max_browsers=1)
    try:
        browser = await browser_pool.get_browser()
        # Create a context
        context = await browser.create_context("test-error")
        try:
            # Simulate an error during page operation
            page = await context.new_page()
            await page.goto("https://nonexistent.example.com")
        except Exception as e:
            logger.info(f"Expected error occurred: {str(e)}")
            # Verify context is still tracked
            assert "test-error" in browser.contexts, "Context lost after error"
            # Cleanup should still work
            await browser.close_context("test-error")
            assert "test-error" not in browser.contexts, "Context not cleaned up after error"
    finally:
        await close_browser_pool()
        logger.info("Cleanup on error test passed")
async def test_integration():
    """Test the integration component"""
    logger.info("Testing integration...")
    # Test browser manager with resource monitoring
    await browser_manager.initialize(max_browsers=2)
    try:
        # Create multiple sessions to test resource management
        sessions = []
        for i in range(3):
            try:
                session_id = f"test-session-{i}"
                context = await browser_manager.create_browser_context(session_id, f"test-user-{i}")
                sessions.append(session_id)
                logger.info(f"Created browser context for session: {session_id}")
                # Verify context tracking
                session_info = await browser_manager.get_browser_context(session_id)
                assert session_info is not None, "Failed to get browser context"
                assert session_info["user_id"] == f"test-user-{i}", "Wrong user ID"
            except MCPBrowserException as e:
                if e.error_code == ErrorCode.RESOURCE_LIMIT_EXCEEDED:
                    logger.info("Resource limit correctly enforced")
                    break
                raise
        # Clean up sessions
        for session_id in sessions:
            await browser_manager.close_browser_context(session_id)
            logger.info(f"Closed browser context for session: {session_id}")
        # Test auth manager
        username = "admin"
        user = await auth_manager.get_user(username)
        assert user is not None, "Failed to get user"
        assert user.username == username, "Wrong username"
        logger.info(f"Got user: {user.username}")
        # Test token creation and decoding
        token_data = {"sub": username, "permissions": user.permissions}
        access_token = await auth_manager.create_access_token(token_data)
        assert access_token is not None, "Failed to create access token"
        logger.info(f"Created access token")
        # Decode token
        payload = await auth_manager.decode_token(access_token)
        assert payload["sub"] == username, "Wrong username in token"
        logger.info(f"Decoded token: {payload['sub']}")
        # Test permission check
        has_permission = auth_manager.has_permission(user, "browser:full")
        assert has_permission, "User should have permission"
        logger.info(f"User has permission: browser:full")
    finally:
        # Clean up
        await browser_manager.shutdown()
        logger.info("Integration test passed")
async def main():
    """Run all tests"""
    try:
        await test_browser_pool()
        await test_resource_limits()
        await test_error_handling()
        await test_memory_monitoring()
        await test_process_monitoring()
        await test_cleanup_on_error()
        await test_integration()
        logger.info("All tests passed successfully!")
    except Exception as e:
        logger.error("Test failed:", exc_info=True)
        sys.exit(1)
if __name__ == "__main__":
    asyncio.run(main())
</file>

<file path="src/test_lifespan.py">
#!/usr/bin/env python3
"""
Test file to verify lifespan events are working correctly.
This is a simplified version of the main application with lifespan events.
"""
import asyncio
import logging
from typing import AsyncGenerator
from contextlib import asynccontextmanager
import uvicorn
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("test-lifespan")
# App state
app_state = {}
# Define lifespan context manager
@asynccontextmanager
async def lifespan(app: FastAPI) -> AsyncGenerator[None, None]:
    """Lifespan context manager for startup and shutdown events"""
    global app_state
    # Startup: Initialize services
    app_state["initialized"] = True
    app_state["start_time"] = asyncio.get_event_loop().time()
    logger.info("Test server started with lifespan event")
    yield  # Run the application
    # Shutdown: Cleanup resources
    app_state["shutdown_time"] = asyncio.get_event_loop().time()
    app_state["uptime"] = app_state["shutdown_time"] - app_state["start_time"]
    logger.info(f"Test server shut down. Uptime: {app_state['uptime']:.2f} seconds")
# Create FastAPI app with lifespan
app = FastAPI(
    title="Lifespan Test",
    description="Test server for lifespan events",
    version="0.1.0",
    lifespan=lifespan
)
# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
# Endpoints
@app.get("/")
async def root():
    """Root endpoint"""
    return {
        "message": "Lifespan Test Server",
        "initialized": app_state.get("initialized", False),
        "uptime": asyncio.get_event_loop().time() - app_state.get("start_time", 0)
    }
@app.get("/state")
async def state():
    """Get app state"""
    return app_state
# Main entry point
if __name__ == "__main__":
    uvicorn.run("test_lifespan:app", host="0.0.0.0", port=8766, reload=False)
</file>

<file path="src/test_rate_limiting.py">
#!/usr/bin/env python3
"""
Test Rate Limiting for MCP Browser
This module tests the rate limiting functionality for API endpoints.
"""
import asyncio
import logging
import pytest
from fastapi import FastAPI, Request
from fastapi.testclient import TestClient
from typing import Dict, List, Optional, Any
from rate_limiter import RateLimiter, RateLimitConfig, RateLimitExceeded
from error_handler import MCPBrowserException, ErrorCode
# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("test-rate-limiting")
# Test app
app = FastAPI()
rate_limiter = RateLimiter()
@app.get("/test")
@rate_limiter.limit("10/minute")
async def test_endpoint():
    return {"status": "ok"}
@app.get("/auth-test")
@rate_limiter.limit("5/minute", exempt_with_token=True)
async def auth_test_endpoint(request: Request):
    return {"status": "ok"}
def test_basic_rate_limiting():
    """Test basic rate limiting functionality"""
    logger.info("Testing basic rate limiting...")
    client = TestClient(app)
    # Make requests up to the limit
    for i in range(10):
        response = client.get("/test")
        assert response.status_code == 200, f"Request {i+1} failed"
        # Check rate limit headers
        assert "X-RateLimit-Limit" in response.headers
        assert "X-RateLimit-Remaining" in response.headers
        assert "X-RateLimit-Reset" in response.headers
        remaining = int(response.headers["X-RateLimit-Remaining"])
        assert remaining == 9 - i, f"Wrong remaining count: {remaining}"
    # Next request should fail
    response = client.get("/test")
    assert response.status_code == 429
    assert response.json()["error_code"] == ErrorCode.RATE_LIMIT_EXCEEDED.value
def test_authenticated_rate_limiting():
    """Test rate limiting with authentication exemption"""
    logger.info("Testing authenticated rate limiting...")
    client = TestClient(app)
    # Test without auth token (should be limited)
    for i in range(5):
        response = client.get("/auth-test")
        assert response.status_code == 200, f"Request {i+1} failed"
    response = client.get("/auth-test")
    assert response.status_code == 429
    # Test with auth token (should bypass limit)
    headers = {"Authorization": "Bearer test-token"}
    for _ in range(10):  # Try more requests than normal limit
        response = client.get("/auth-test", headers=headers)
        assert response.status_code == 200, "Authenticated request failed"
def test_burst_protection():
    """Test protection against burst requests"""
    logger.info("Testing burst protection...")
    client = TestClient(app)
    # Send burst of concurrent requests
    async def make_requests():
        tasks = []
        for _ in range(20):  # Try double the limit
            tasks.append(client.get("/test"))
        return await asyncio.gather(*tasks, return_exceptions=True)
    responses = asyncio.run(make_requests())
    # Count successful and failed requests
    success_count = sum(1 for r in responses if getattr(r, "status_code", 0) == 200)
    fail_count = sum(1 for r in responses if getattr(r, "status_code", 0) == 429)
    assert success_count == 10, f"Expected 10 successful requests, got {success_count}"
    assert fail_count == 10, f"Expected 10 failed requests, got {fail_count}"
def test_sliding_window():
    """Test sliding window rate limiting"""
    logger.info("Testing sliding window rate limiting...")
    client = TestClient(app)
    # Make requests up to limit
    for _ in range(10):
        response = client.get("/test")
        assert response.status_code == 200
    # Wait for half the window
    asyncio.run(asyncio.sleep(30))
    # Should allow half the requests
    for i in range(5):
        response = client.get("/test")
        assert response.status_code == 200, f"Request {i+1} should be allowed"
    # Next request should fail
    response = client.get("/test")
    assert response.status_code == 429
def test_custom_limits():
    """Test custom rate limit configurations"""
    logger.info("Testing custom rate limits...")
    # Create test endpoint with custom limits
    @app.get("/custom")
    @rate_limiter.limit("2/second")
    async def custom_endpoint():
        return {"status": "ok"}
    client = TestClient(app)
    # Test second-based limit
    response = client.get("/custom")
    assert response.status_code == 200
    response = client.get("/custom")
    assert response.status_code == 200
    response = client.get("/custom")
    assert response.status_code == 429
    # Wait a second
    asyncio.run(asyncio.sleep(1))
    # Should be allowed again
    response = client.get("/custom")
    assert response.status_code == 200
if __name__ == "__main__":
    pytest.main([__file__, "-v"])
</file>

<file path="src/test_websocket_client.py">
#!/usr/bin/env python3
"""
WebSocket client for testing the WebSocket event subscription feature.
This connects to the test WebSocket server, subscribes to events, and displays them.
"""
import asyncio
import json
import logging
import sys
import argparse
import websockets
from datetime import datetime
# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
logger = logging.getLogger(__name__)
# Parse command line arguments
parser = argparse.ArgumentParser(description="WebSocket Event Subscription Test Client")
parser.add_argument(
    "--url", 
    default="ws://localhost:8765/ws/events", 
    help="WebSocket URL for the event endpoint"
)
parser.add_argument(
    "--types", 
    default="PAGE,NETWORK,CONSOLE,DOM", 
    help="Comma-separated list of event types to subscribe to"
)
parser.add_argument(
    "--test-events", 
    action="store_true", 
    help="Generate test events periodically"
)
parser.add_argument(
    "--timeout", 
    type=int, 
    default=0, 
    help="Exit after this many seconds (0 means run indefinitely)"
)
args = parser.parse_args()
async def subscribe_to_events(ws, event_types):
    """Subscribe to events"""
    subscription_data = {
        "action": "subscribe",
        "event_types": event_types.split(","),
    }
    await ws.send(json.dumps(subscription_data))
    response = await ws.recv()
    logger.info(f"Subscription response: {response}")
    return json.loads(response)
async def generate_test_event(ws, event_type="PAGE", event_name="test.event"):
    """Generate a test event"""
    test_event_data = {
        "action": "test_event",
        "event_type": event_type,
        "event_name": event_name,
        "data": {
            "message": f"Test event: {event_type}.{event_name}",
            "timestamp": datetime.now().strftime("%H:%M:%S"),
            "details": {
                "test": True,
                "generated_at": str(datetime.now())
            }
        }
    }
    await ws.send(json.dumps(test_event_data))
    response = await ws.recv()
    logger.info(f"Test event response: {response}")
async def print_event(event_data):
    """Format and print an event"""
    try:
        event_json = json.loads(event_data)
        event_type = event_json.get("type", "DEFAULT")
        event_name = event_json.get("event", "unknown")
        timestamp = datetime.fromtimestamp(event_json.get("timestamp", 0)).strftime("%H:%M:%S")
        data = event_json.get("data", {})
        # Print the event
        print(f"[{timestamp}] {event_type}.{event_name}")
        # Format the data nicely
        if isinstance(data, dict):
            for key, value in data.items():
                # Handle nested data
                if isinstance(value, dict) and len(value) > 0:
                    print(f"  {key}:")
                    for subkey, subvalue in value.items():
                        print(f"    {subkey}: {subvalue}")
                else:
                    print(f"  {key}: {value}")
        else:
            print(f"  {data}")
        print("-" * 80)
    except Exception as e:
        logger.error(f"Error processing event: {e}")
        logger.error(f"Raw event data: {event_data}")
async def test_event_generator(ws):
    """Generate test events periodically"""
    if not args.test_events:
        return
    event_types = ["PAGE", "DOM", "CONSOLE", "NETWORK"]
    event_names = {
        "PAGE": ["page.load", "page.navigate", "page.error"],
        "DOM": ["dom.mutation", "dom.attribute", "dom.child"],
        "CONSOLE": ["console.log", "console.error", "console.warning"],
        "NETWORK": ["network.request", "network.response", "network.error"]
    }
    logger.info("Starting test event generator")
    while True:
        # Cycle through event types
        for event_type in event_types:
            # Cycle through event names for this type
            for event_name in event_names.get(event_type, ["test.event"]):
                try:
                    await generate_test_event(ws, event_type, event_name)
                    await asyncio.sleep(2)  # Wait between events
                except Exception as e:
                    logger.error(f"Error generating test event: {e}")
                    return
async def timeout_handler():
    """Handle timeout and exit gracefully"""
    if args.timeout > 0:
        logger.info(f"Will exit after {args.timeout} seconds")
        await asyncio.sleep(args.timeout)
        logger.info("Timeout reached, exiting")
        print(f"\nTest completed after {args.timeout} seconds")
        sys.exit(0)
async def main():
    """Main function"""
    try:
        logger.info(f"Connecting to WebSocket at {args.url}")
        # Start timeout handler if specified
        if args.timeout > 0:
            asyncio.create_task(timeout_handler())
        async with websockets.connect(args.url) as ws:
            logger.info("Connected to WebSocket server")
            # Receive welcome message
            welcome = await ws.recv()
            logger.info(f"Welcome message: {welcome}")
            # Subscribe to events
            subscription = await subscribe_to_events(ws, args.types)
            subscription_id = subscription.get("subscription_id", "unknown")
            logger.info(f"Subscribed to events with ID: {subscription_id}")
            # Start test event generator if requested
            if args.test_events:
                asyncio.create_task(test_event_generator(ws))
            # Print initial message
            print("\n" + "=" * 80)
            print("WebSocket Event Subscription Test Client")
            print(f"Connected to: {args.url}")
            print(f"Subscribed to event types: {args.types}")
            if args.test_events:
                print("Test event generation: Enabled")
            if args.timeout > 0:
                print(f"Will exit after {args.timeout} seconds")
            print("=" * 80 + "\n")
            # Receive events
            while True:
                message = await ws.recv()
                await print_event(message)
    except websockets.exceptions.ConnectionClosed:
        logger.error("WebSocket connection closed")
    except Exception as e:
        logger.error(f"Error: {e}")
if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nScript terminated by user")
        sys.exit(0)
</file>

<file path="src/test_websocket.py">
#!/usr/bin/env python3
"""
Simple WebSocket server for testing event subscriptions.
This demonstrates the WebSocket event subscriptions feature with a minimal implementation.
"""
import asyncio
import json
import logging
import uuid
import time
from datetime import datetime
from typing import Dict, List, Set, Any, Optional, AsyncGenerator
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
from enum import Enum
from contextlib import asynccontextmanager
# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
logger = logging.getLogger(__name__)
# Define event types and models
class EventType(str, Enum):
    """Types of browser events"""
    PAGE = "PAGE"
    DOM = "DOM"
    CONSOLE = "CONSOLE"
    NETWORK = "NETWORK"
# Global variables
active_connections: Set[WebSocket] = set()
event_connections: Dict[str, WebSocket] = {}
active_subscriptions: Dict[str, Dict[str, Any]] = {}
subscription_handlers: Dict[str, List[str]] = {
    "PAGE": [],
    "DOM": [],
    "CONSOLE": [],
    "NETWORK": [],
}
# Forward declare the event generator function signature
async def event_generator():
    """Generate simulated events for testing"""
    pass  # Actual implementation below
# Define lifespan context manager
@asynccontextmanager
async def lifespan(app: FastAPI) -> AsyncGenerator[None, None]:
    """Lifespan context manager for startup and shutdown events"""
    # Startup: Create task for event generator
    event_task = asyncio.create_task(event_generator())
    logger.info("WebSocket Event Test Server started")
    yield  # Run the application
    # Shutdown: Cancel the event generator task
    event_task.cancel()
    try:
        await event_task
    except asyncio.CancelledError:
        logger.info("Event generator task cancelled")
# Create FastAPI app with lifespan
app = FastAPI(
    title="WebSocket Event Test",
    lifespan=lifespan
)
# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
# Event handler functions
async def broadcast_event(event_type: str, event_name: str, data: Dict[str, Any]):
    """Broadcast an event to all subscribed clients"""
    event = {
        "type": event_type,
        "event": event_name,
        "timestamp": time.time(),
        "data": data
    }
    # Convert event to JSON string
    event_json = json.dumps(event)
    # Find subscriptions for this event type
    for subscription_id in subscription_handlers.get(event_type, []):
        if subscription_id in active_subscriptions:
            client_id = active_subscriptions[subscription_id]["client_id"]
            # Check if client is still connected
            if client_id in event_connections:
                try:
                    await event_connections[client_id].send_text(event_json)
                    logger.info(f"Event {event_name} sent to client {client_id}")
                except Exception as e:
                    logger.error(f"Error sending event to client {client_id}: {e}")
async def add_subscription(client_id: str, subscription_id: str, event_types: List[str], filters: Optional[Dict[str, Any]] = None):
    """Add a new subscription for a client"""
    # Store subscription details
    active_subscriptions[subscription_id] = {
        "client_id": client_id,
        "event_types": event_types,
        "filters": filters,
        "created_at": time.time()
    }
    # Register subscription for each event type
    for event_type in event_types:
        if event_type in subscription_handlers:
            subscription_handlers[event_type].append(subscription_id)
    logger.info(f"Added subscription {subscription_id} for client {client_id}, event types: {event_types}")
async def remove_subscription(subscription_id: str):
    """Remove a subscription"""
    if subscription_id in active_subscriptions:
        # Get event types for this subscription
        event_types = active_subscriptions[subscription_id].get("event_types", [])
        # Remove from subscription handlers
        for event_type in event_types:
            if event_type in subscription_handlers and subscription_id in subscription_handlers[event_type]:
                subscription_handlers[event_type].remove(subscription_id)
        # Remove from active subscriptions
        del active_subscriptions[subscription_id]
        logger.info(f"Removed subscription {subscription_id}")
        return True
    return False
# Actual implementation of event generator task
async def event_generator():
    """Generate simulated events for testing"""
    event_types = ["PAGE", "DOM", "CONSOLE", "NETWORK"]
    event_names = {
        "PAGE": ["page.load", "page.navigate", "page.error"],
        "DOM": ["dom.mutation", "dom.attribute", "dom.child"],
        "CONSOLE": ["console.log", "console.error", "console.warning"],
        "NETWORK": ["network.request", "network.response", "network.error"]
    }
    while True:
        # Only generate events if there are active subscriptions
        if active_subscriptions:
            # Select random event type
            event_type = event_types[int(time.time() * 10) % len(event_types)]
            # Check if there are any subscribers for this event type
            if subscription_handlers.get(event_type, []):
                # Select random event name
                names = event_names.get(event_type, ["test.event"])
                event_name = names[int(time.time() * 100) % len(names)]
                # Generate event data
                data = {
                    "timestamp": datetime.now().strftime("%H:%M:%S"),
                    "message": f"Simulated {event_type}.{event_name} event",
                    "value": round(time.time() % 100, 2),
                    "details": {
                        "random": uuid.uuid4().hex[:8],
                        "counter": int(time.time()) % 1000
                    }
                }
                # Broadcast event
                await broadcast_event(event_type, event_name, data)
                logger.debug(f"Generated event: {event_type}.{event_name}")
        # Wait before generating next event
        await asyncio.sleep(2)
# API endpoints
@app.get("/api/status")
async def get_status():
    """Get server status"""
    return {
        "status": "ok",
        "version": "0.1.0",
        "timestamp": time.time(),
        "connections": len(active_connections),
        "subscriptions": len(active_subscriptions)
    }
# WebSocket endpoint for browser events
@app.websocket("/ws/events")
async def websocket_browser_events(websocket: WebSocket):
    """WebSocket endpoint for browser events"""
    await websocket.accept()
    # Generate a unique client ID
    client_id = f"client_{str(uuid.uuid4())}"
    # Add to active connections
    active_connections.add(websocket)
    event_connections[client_id] = websocket
    # Send welcome message
    await websocket.send_text(json.dumps({
        "type": "connection",
        "client_id": client_id,
        "message": "Connected to WebSocket Event Test Server",
        "timestamp": time.time()
    }))
    logger.info(f"Client {client_id} connected")
    try:
        # Process incoming messages
        while True:
            # Receive message
            data = await websocket.receive_text()
            try:
                # Parse JSON message
                message = json.loads(data)
                action = message.get("action", "")
                # Process action
                if action == "subscribe":
                    # Subscribe to events
                    event_types = message.get("event_types", [])
                    filters = message.get("filters")
                    # Generate subscription ID
                    subscription_id = f"sub_{str(uuid.uuid4())}"
                    # Add subscription
                    await add_subscription(client_id, subscription_id, event_types, filters)
                    # Send confirmation
                    await websocket.send_text(json.dumps({
                        "type": "subscription",
                        "subscription_id": subscription_id,
                        "event_types": event_types,
                        "filters": filters,
                        "timestamp": time.time()
                    }))
                elif action == "unsubscribe":
                    # Unsubscribe from events
                    subscription_id = message.get("subscription_id", "")
                    # Remove subscription
                    success = await remove_subscription(subscription_id)
                    # Send confirmation
                    await websocket.send_text(json.dumps({
                        "type": "unsubscription",
                        "subscription_id": subscription_id,
                        "success": success,
                        "timestamp": time.time()
                    }))
                elif action == "list":
                    # List active subscriptions for this client
                    client_subscriptions = {
                        sub_id: sub_data
                        for sub_id, sub_data in active_subscriptions.items()
                        if sub_data.get("client_id") == client_id
                    }
                    # Send subscription list
                    await websocket.send_text(json.dumps({
                        "type": "subscription_list",
                        "subscriptions": client_subscriptions,
                        "timestamp": time.time()
                    }))
                elif action == "test_event":
                    # Generate a test event for debugging
                    event_type = message.get("event_type", "PAGE")
                    event_name = message.get("event_name", "test.event")
                    event_data = message.get("data", {"message": "Test event"})
                    # Broadcast event
                    await broadcast_event(event_type, event_name, event_data)
                    # Send confirmation
                    await websocket.send_text(json.dumps({
                        "type": "event_generated",
                        "event_type": event_type,
                        "event_name": event_name,
                        "timestamp": time.time()
                    }))
                else:
                    # Unknown action
                    await websocket.send_text(json.dumps({
                        "type": "error",
                        "error": f"Unknown action: {action}",
                        "timestamp": time.time()
                    }))
            except json.JSONDecodeError:
                # Invalid JSON
                await websocket.send_text(json.dumps({
                    "type": "error",
                    "error": "Invalid JSON message",
                    "timestamp": time.time()
                }))
    except WebSocketDisconnect:
        # Client disconnected
        logger.info(f"Client {client_id} disconnected")
        # Remove from active connections
        active_connections.discard(websocket)
        if client_id in event_connections:
            del event_connections[client_id]
        # Remove client subscriptions
        client_subscriptions = [
            sub_id for sub_id, sub_data in active_subscriptions.items()
            if sub_data.get("client_id") == client_id
        ]
        for subscription_id in client_subscriptions:
            await remove_subscription(subscription_id)
# New endpoint for browser events at the expected path
@app.websocket("/ws/browser/events")
async def websocket_browser_events_alias(websocket: WebSocket):
    """WebSocket endpoint for browser events (alias for compatibility)"""
    await websocket.accept()
    # Generate a unique client ID
    client_id = f"client_{str(uuid.uuid4())}"
    # Add to active connections
    active_connections.add(websocket)
    event_connections[client_id] = websocket
    # Send welcome message
    await websocket.send_text(json.dumps({
        "type": "connection",
        "client_id": client_id,
        "message": "Connected to MCP Browser Event Subscription Service",
        "timestamp": time.time()
    }))
    logger.info(f"Client {client_id} connected to browser events endpoint")
    try:
        # Process incoming messages
        while True:
            # Receive message
            data = await websocket.receive_text()
            try:
                # Parse JSON message
                message = json.loads(data)
                action = message.get("action", "")
                # Process action
                if action == "subscribe":
                    # Subscribe to events
                    event_types = message.get("event_types", [])
                    filters = message.get("filters")
                    # Generate subscription ID
                    subscription_id = f"sub_{str(uuid.uuid4())}"
                    # Add subscription
                    await add_subscription(client_id, subscription_id, event_types, filters)
                    # Send confirmation
                    await websocket.send_text(json.dumps({
                        "type": "subscription",
                        "subscription_id": subscription_id,
                        "event_types": event_types,
                        "filters": filters,
                        "timestamp": time.time()
                    }))
                elif action == "unsubscribe":
                    # Unsubscribe from events
                    subscription_id = message.get("subscription_id", "")
                    # Remove subscription
                    success = await remove_subscription(subscription_id)
                    # Send confirmation
                    await websocket.send_text(json.dumps({
                        "type": "unsubscription",
                        "subscription_id": subscription_id,
                        "success": success,
                        "timestamp": time.time()
                    }))
                elif action == "list":
                    # List active subscriptions for this client
                    client_subscriptions = {
                        sub_id: sub_data
                        for sub_id, sub_data in active_subscriptions.items()
                        if sub_data.get("client_id") == client_id
                    }
                    # Send subscription list
                    await websocket.send_text(json.dumps({
                        "type": "subscription_list",
                        "subscriptions": client_subscriptions,
                        "timestamp": time.time()
                    }))
                elif action == "execute":
                    # Handle execute command (for navigation, etc.)
                    command = message.get("command", "")
                    params = message.get("params", {})
                    # Log the command (in a real implementation, this would actually execute it)
                    logger.info(f"Received execute command: {command} with params: {params}")
                    # Send confirmation
                    await websocket.send_text(json.dumps({
                        "type": "command_executed",
                        "command": command,
                        "success": True,
                        "message": f"Command {command} acknowledged (simulation)",
                        "timestamp": time.time()
                    }))
                    # If this is a navigation command, generate a simulated PAGE event
                    if command == "navigate" and "url" in params:
                        # Simulate a page load event
                        await asyncio.sleep(0.5)  # Simulate loading time
                        page_event_data = {
                            "url": params["url"],
                            "title": f"Page Title for {params['url']}",
                            "status": 200,
                            "timestamp": time.time()
                        }
                        # Broadcast a PAGE event
                        await broadcast_event("PAGE", "page.load", page_event_data)
                elif action == "test_event":
                    # Generate a test event for debugging
                    event_type = message.get("event_type", "PAGE")
                    event_name = message.get("event_name", "test.event")
                    event_data = message.get("data", {"message": "Test event"})
                    # Broadcast event
                    await broadcast_event(event_type, event_name, event_data)
                    # Send confirmation
                    await websocket.send_text(json.dumps({
                        "type": "event_generated",
                        "event_type": event_type,
                        "event_name": event_name,
                        "timestamp": time.time()
                    }))
                else:
                    # Unknown action
                    await websocket.send_text(json.dumps({
                        "type": "error",
                        "error": f"Unknown action: {action}",
                        "timestamp": time.time()
                    }))
            except json.JSONDecodeError:
                # Invalid JSON
                await websocket.send_text(json.dumps({
                    "type": "error",
                    "error": "Invalid JSON message",
                    "timestamp": time.time()
                }))
    except WebSocketDisconnect:
        # Client disconnected
        logger.info(f"Client {client_id} disconnected")
        # Remove from active connections
        active_connections.discard(websocket)
        if client_id in event_connections:
            del event_connections[client_id]
        # Remove client subscriptions
        client_subscriptions = [
            sub_id for sub_id, sub_data in active_subscriptions.items()
            if sub_data.get("client_id") == client_id
        ]
        for subscription_id in client_subscriptions:
            await remove_subscription(subscription_id)
# Main entry point
if __name__ == "__main__":
    # Use reload=False to prevent frequent reloads during development
    uvicorn.run("test_websocket:app", host="0.0.0.0", port=8765, reload=False)
</file>

<file path="tests/conftest.py">
import pytest
import pytest_asyncio
import asyncio
import logging
from src.browser_pool import BrowserPool
# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
@pytest.fixture(scope="session")
def event_loop():
    """Create an instance of the default event loop for the test session."""
    policy = asyncio.get_event_loop_policy()
    loop = policy.new_event_loop()
    asyncio.set_event_loop(loop)
    yield loop
    loop.close()
@pytest_asyncio.fixture(scope="session")
async def browser_pool(event_loop):
    """Create a browser pool for testing."""
    pool = BrowserPool(
        max_browsers=2,
        idle_timeout=5,  # Short timeout for testing
        max_memory_percent=30.0,  # Strict memory limit
        max_cpu_percent=30.0,  # Strict CPU limit
        monitor_interval=1  # Frequent monitoring
    )
    try:
        await pool.start()
        logger.info("Browser pool started successfully")
        yield pool
    except Exception as e:
        logger.error(f"Error starting browser pool: {e}")
        raise
    finally:
        logger.info("Cleaning up browser pool")
        await pool.cleanup()
@pytest.fixture
async def browser_context(browser_pool):
    """Create a browser context for testing."""
    logger.info("browser_context fixture: Getting browser...")
    browser = await browser_pool.get_browser()
    logger.info(f"browser_context fixture: Got browser {browser.pid}, creating context...")
    context = await browser.create_context()
    logger.info(f"browser_context fixture: Created context, yielding.")
    yield context
    # --- Teardown starts here ---
    logger.info(f"browser_context fixture: Starting teardown for context...")
    try:
        logger.info(f"browser_context fixture: Closing context...")
        await context.close()
        logger.info(f"browser_context fixture: Context closed.")
    except Exception as e:
        logger.error(f"browser_context fixture: Error closing context: {e}", exc_info=True)
    try:
        logger.info(f"browser_context fixture: Closing browser {browser.pid} via pool...")
        await browser_pool.close_browser(browser)
        logger.info(f"browser_context fixture: Browser {browser.pid} closed via pool.")
    except Exception as e:
        logger.error(f"browser_context fixture: Error closing browser via pool: {e}", exc_info=True)
    logger.info(f"browser_context fixture: Teardown complete.")
</file>

<file path="tests/test_network_isolation.py">
import pytest
import docker
import subprocess
import socket
import time
from typing import Dict, List
import asyncio
import logging
from src.browser_pool import BrowserPool, BrowserInstance
from src.error_handler import MCPBrowserException, ErrorCode
# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("test-network-isolation")
@pytest.fixture(scope="module")
def docker_client():
    return docker.from_env()
@pytest.fixture(scope="module")
def mcp_browser_container(docker_client):
    """Get the MCP Browser container"""
    containers = docker_client.containers.list(filters={"name": "mcp-browser"})
    assert len(containers) == 1, "MCP Browser container not found"
    return containers[0]
def test_network_configuration(docker_client):
    """Test Docker network configuration"""
    networks = docker_client.networks.list()
    # Check required networks exist
    network_names = [n.name for n in networks]
    assert "mcp-browser-internal" in network_names
    assert "mcp-browser-external" in network_names
    assert "mcp-browser-monitoring" in network_names
    # Verify network configurations
    for network in networks:
        if network.name.startswith("mcp-browser-"):
            config = network.attrs["IPAM"]["Config"][0]
            assert "Subnet" in config
            assert "Gateway" in config
            assert network.attrs["Driver"] == "bridge"
def test_container_network_access(mcp_browser_container):
    """Test container network access restrictions"""
    # Test internal network access
    internal_ip = "172.20.0.1"
    result = mcp_browser_container.exec_run(f"ping -c 1 {internal_ip}")
    assert result.exit_code != 0, "Container should not be able to ping internal network"
    # Test external network access
    external_ip = "172.21.0.1"
    result = mcp_browser_container.exec_run(f"ping -c 1 {external_ip}")
    assert result.exit_code != 0, "Container should not be able to ping external network"
    # Test monitoring network access
    monitoring_ip = "172.22.0.1"
    result = mcp_browser_container.exec_run(f"ping -c 1 {monitoring_ip}")
    assert result.exit_code != 0, "Container should not be able to ping monitoring network"
def test_port_access(mcp_browser_container):
    """Test port access restrictions"""
    # Test allowed ports
    allowed_ports = [8000, 7665]
    for port in allowed_ports:
        result = mcp_browser_container.exec_run(f"nc -zv localhost {port}")
        assert result.exit_code == 0, f"Container should be able to access port {port}"
    # Test blocked ports
    blocked_ports = [22, 80, 443]
    for port in blocked_ports:
        result = mcp_browser_container.exec_run(f"nc -zv localhost {port}")
        assert result.exit_code != 0, f"Container should not be able to access port {port}"
def test_apparmor_profile(mcp_browser_container):
    """Test AppArmor profile enforcement"""
    # Check if AppArmor profile is loaded
    result = subprocess.run(["aa-status"], capture_output=True, text=True)
    assert "mcp-browser" in result.stdout, "AppArmor profile not loaded"
    # Test raw socket access (should be denied)
    result = mcp_browser_container.exec_run("python3 -c 'import socket; s = socket.socket(socket.AF_INET, socket.SOCK_RAW, socket.IPPROTO_ICMP)'")
    assert result.exit_code != 0, "Container should not be able to create raw sockets"
def test_tcp_hardening(mcp_browser_container):
    """Test TCP hardening settings"""
    # Get container's TCP settings
    result = mcp_browser_container.exec_run("cat /proc/sys/net/ipv4/tcp_syncookies")
    assert result.exit_code == 0
    assert result.output.decode().strip() == "1", "TCP syncookies should be enabled"
    result = mcp_browser_container.exec_run("cat /proc/sys/net/ipv4/tcp_max_syn_backlog")
    assert result.exit_code == 0
    assert result.output.decode().strip() == "1024", "TCP max syn backlog should be 1024"
    result = mcp_browser_container.exec_run("cat /proc/sys/net/ipv4/tcp_synack_retries")
    assert result.exit_code == 0
    assert result.output.decode().strip() == "2", "TCP synack retries should be 2"
def test_resource_limits(mcp_browser_container):
    """Test resource limits"""
    # Get container's resource limits
    result = mcp_browser_container.exec_run("ulimit -n")
    assert result.exit_code == 0
    assert int(result.output.decode().strip()) == 65536, "File descriptor limit should be 65536"
    result = mcp_browser_container.exec_run("ulimit -u")
    assert result.exit_code == 0
    assert int(result.output.decode().strip()) == 65536, "Process limit should be 65536"
@pytest.mark.asyncio
async def test_network_isolation():
    """Test that network isolation is properly enforced."""
    logger.info("Starting network isolation test")
    # Initialize browser pool with network isolation
    pool = BrowserPool(
        max_browsers=1,
        idle_timeout=60,
        max_memory_percent=80,
        max_cpu_percent=80,
        network_isolation=True,
        allowed_domains=["example.com"],
        blocked_domains=["blocked.com"]
    )
    try:
        # Get a browser instance
        browser = await pool.get_browser()
        assert browser is not None, "Failed to get browser instance"
        assert browser.network_isolation, "Network isolation should be enabled"
        # Create a context
        context = await browser.create_context()
        assert context is not None, "Failed to create browser context"
        # Test access to allowed domain
        logger.info("Testing access to allowed domain (example.com)")
        page = await context.new_page()
        try:
            response = await page.goto("http://example.com")
            assert response is not None, "Failed to access allowed domain"
            assert response.status == 200, "Failed to get successful response from allowed domain"
            logger.info("Successfully accessed allowed domain")
        finally:
            await page.close()
        # Test access to blocked domain
        logger.info("Testing access to blocked domain (blocked.com)")
        page = await context.new_page()
        try:
            with pytest.raises(Exception) as exc_info:
                await page.goto("http://blocked.com")
            assert "blocked" in str(exc_info.value).lower(), "Expected blocked domain to be blocked"
            logger.info("Successfully blocked access to blocked domain")
        finally:
            await page.close()
        # Test access to unlisted domain
        logger.info("Testing access to unlisted domain (unlisted.com)")
        page = await context.new_page()
        try:
            with pytest.raises(Exception) as exc_info:
                await page.goto("http://unlisted.com")
            assert "not allowed" in str(exc_info.value).lower(), "Expected unlisted domain to be blocked"
            logger.info("Successfully blocked access to unlisted domain")
        finally:
            await page.close()
        # Clean up
        await context.close()
        await pool.close_browser(browser)
    finally:
        await pool.cleanup()
        logger.info("Network isolation test completed")
if __name__ == "__main__":
    asyncio.run(test_network_isolation())
</file>

<file path="tests/test_resource_management.py">
import pytest
import pytest_asyncio
import asyncio
import logging
from src.browser_pool import BrowserPool, BrowserInstance
from src.error_handler import MCPBrowserException, ErrorCode
# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("test-resource-management")
# Removed the local browser_pool fixture definition
# It will now use the session-scoped fixture from conftest.py
@pytest.mark.asyncio
async def test_resource_limits_enforcement(browser_pool):
    """Test that resource limits are strictly enforced"""
    # Get initial browser
    browser = await browser_pool.get_browser()
    assert browser is not None, "Failed to get browser instance"
    # Create contexts until we hit resource limits
    contexts = []
    try:
        for i in range(5):  # Try to create multiple contexts
            context = await browser.create_context(f"test-context-{i}")
            contexts.append(context)
            # Check if we've hit resource limits
            metrics = browser_pool._get_system_metrics()
            if metrics["memory_percent"] > browser_pool.max_memory_percent:
                logger.info("Memory limit reached")
                break
            if metrics["cpu_percent"] > browser_pool.max_cpu_percent:
                logger.info("CPU limit reached")
                break
    except MCPBrowserException as e:
        assert e.error_code == ErrorCode.RESOURCE_LIMIT_EXCEEDED, \
            f"Expected RESOURCE_LIMIT_EXCEEDED, got {e.error_code}"
    finally:
        # Clean up contexts
        for i, context in enumerate(contexts):
            # Check if context still exists before attempting to close
            if f"test-context-{i}" in browser.contexts:
                await browser.close_context(f"test-context-{i}")
@pytest.mark.asyncio
async def test_idle_context_cleanup(browser_pool):
    """Test that idle contexts are properly cleaned up"""
    browser = await browser_pool.get_browser()
    assert browser is not None, "Failed to get browser instance"
    # Create a context
    context_id = "idle-test-context"
    context = await browser.create_context(context_id)
    assert context is not None, "Failed to create context"
    assert context_id in browser.contexts
    # Wait for idle timeout
    logger.info(f"Waiting for idle timeout ({browser_pool.idle_timeout + 1}s)")
    await asyncio.sleep(browser_pool.idle_timeout + 1)
    # Force cleanup check (ensure monitoring task runs)
    logger.info("Forcing idle browser check")
    await browser_pool._close_idle_browsers(force_check=True)
    # Verify context was cleaned up
    # Need to check if the browser itself was closed too
    if browser.id in browser_pool.browsers:
        assert context_id not in browser.contexts, f"Idle context {context_id} was not cleaned up"
    else:
        logger.info(f"Browser {browser.id} was closed due to idle timeout, context cleanup is implicit.")
        # If browser is gone, the context is implicitly cleaned up.
        pass # Assertion passes implicitly
@pytest.mark.asyncio
async def test_browser_pool_limits():
    """Test browser pool resource limits"""
    logger.info("Starting test_browser_pool_limits")
    # Initialize pool with strict limits
    pool = BrowserPool(
        max_browsers=2,
        idle_timeout=60,
        max_memory_percent=80,
        max_cpu_percent=80,
        network_isolation=True
    )
    try:
        logger.info("Initializing browser pool")
        await pool.start()
        # Create first browser
        logger.info("Creating first browser")
        browser1 = await pool.get_browser()
        logger.info(f"First browser created with ID: {browser1.id}")
        # Create second browser
        logger.info("Creating second browser")
        browser2 = await pool.get_browser()
        logger.info(f"Second browser created with ID: {browser2.id}")
        # Try to create third browser (should fail)
        logger.info("Attempting to create third browser (should fail)")
        with pytest.raises(MCPBrowserException) as exc_info:
            await pool.get_browser()
        assert exc_info.value.error_code == ErrorCode.MAX_BROWSERS_REACHED
        logger.info("Third browser creation failed as expected")
        # Clean up
        logger.info("Starting cleanup")
        await browser1.close()
        logger.info("First browser closed")
        await browser2.close()
        logger.info("Second browser closed")
    except Exception as e:
        logger.error(f"Error in test_browser_pool_limits: {e}", exc_info=True)
        raise
    finally:
        logger.info("Starting pool cleanup")
        await pool.cleanup()
        logger.info("Pool cleanup completed")
@pytest.mark.asyncio
async def test_resource_monitoring(browser_pool):
    """Test that resource monitoring is working correctly"""
    # Ensure monitoring is active
    assert browser_pool._monitor_task_handle is not None and not browser_pool._monitor_task_handle.done(), \
        "Monitor task is not running"
    # Get initial metrics
    initial_metrics = browser_pool._get_system_metrics()
    logger.info(f"Initial system metrics: {initial_metrics}")
    assert "memory_percent" in initial_metrics, "Memory metrics not available"
    assert "cpu_percent" in initial_metrics, "CPU metrics not available"
    # Create a browser and context to potentially increase resource usage
    logger.info("Acquiring browser and context for resource monitoring test")
    browser = await browser_pool.get_browser()
    context = await browser.create_context("monitor-test-context")
    logger.info(f"Acquired browser {browser.id} and context")
    # Allow some time for metrics to potentially update
    await asyncio.sleep(browser_pool.monitor_interval + 0.5)
    # Get updated metrics
    updated_metrics = browser_pool._get_system_metrics()
    logger.info(f"Updated system metrics: {updated_metrics}")
    # Note: Asserting increase is unreliable in short tests. 
    # We primarily check that metrics are being reported.
    assert "memory_percent" in updated_metrics, "Updated memory metrics not available"
    assert "cpu_percent" in updated_metrics, "Updated CPU metrics not available"
    # Clean up
    logger.info("Cleaning up monitoring test resources")
    await browser.close_context("monitor-test-context")
    await browser_pool.close_browser(browser.id)
</file>

<file path=".dockerignore">
# Version control
.git
.gitignore
.github

# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# Python Virtual Environments
.env
.venv
env/
venv/
ENV/

# Playwright
node_modules/
/test-results/
/playwright-report/
/blob-report/
/playwright/.cache/
ms-playwright/

# Development and testing
.coverage
htmlcov/
.pytest_cache/
.tox/
.nox/
.hypothesis/
.coverage.*
coverage.xml
*.cover

# IDE & editor files
.idea/
.vscode/
*.swp
*.swo
*~
.DS_Store
.project
.pydevproject
.settings
.ropeproject
.spyderproject
.spyproject

# Docker
.dockerignore
docker-compose.override.yml
docker-compose.*.yml
!docker-compose.yml
.docker/data/

# uv
.uv/

# Temp files
tmp/
temp/

# Documentation
docs/
README.md
LICENSE
CHANGELOG.md
CONTRIBUTING.md

# Local configuration files
*.local
local_config.yaml
local_settings.py

# Log files
*.log
logs/

# Large binary files
*.db
*.sqlite3
*.dump

# Other
.eslintrc
.jshintrc
.editorconfig
.env*
!.env.example
**/*.md
!README.md
</file>

<file path=".gitignore">
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
env/
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
*.egg-info/
.installed.cfg
*.egg

# Virtual environment
venv/
.venv/
ENV/

# IDE files
.idea/
.vscode/
*.swp
*.swo

# OS specific
.DS_Store
Thumbs.db

# Logs
*.log

# Environment variables
.env

# Output files from API endpoints
output/
*.png
*.jpg
*.jpeg
*.json

# Playwright
node_modules/
/test-results/
/playwright-report/
/blob-report/
/playwright/.cache/

# Logging & Debugging
*.log
logs/
.coverage
htmlcov/
.pytest_cache/
.tox/
.nox/
.hypothesis/
.coverage.*
nosetests.xml
coverage.xml
*.cover
.hypothesis/

# IDE & editor files
.idea/
.vscode/
*.swp
*.swo
*~
.DS_Store
.project
.pydevproject
.settings/
.ropeproject
.spyderproject
.spyproject

# Environment variables
.env
.env.*
!.env.example

# Docker
.docker/data/

# uv
.uv/

# Temp files
tmp/
temp/

# Local configurations
*.local
local_config.yaml
local_settings.py

# MCP Browser specific
ms-playwright/
*.db
*.sqlite3
</file>

<file path=".python-version">
3.13
</file>

<file path="CHANGELOG.md">
# Changelog

## [0.2.0] - 2025-03-23

### Added
- Implemented Accessibility Testing API
  - Added `/api/accessibility/test` endpoint that analyzes web pages for accessibility issues
  - Support for multiple standards (WCAG 2.0 A/AA/AAA, WCAG 2.1 AA, Section 508)
  - Integration with axe-core for comprehensive accessibility testing
  - Element-specific testing with selectors
  - Detailed violation, warning, and incomplete results
  - HTML context inclusion for better debugging

- Implemented Responsive Design Testing API
  - Added `/api/responsive/test` endpoint that tests web pages across different viewport sizes
  - Support for multiple viewport testing (mobile, tablet, laptop, desktop)
  - Element comparison across viewport sizes to detect responsive layout issues
  - Media query analysis to identify breakpoints
  - Touch target size validation for mobile-friendly testing
  - Screenshots captured at each viewport size for visual comparison
  - Detailed metrics and responsive issue reporting

- Added API documentation in `docs/api.md`
- Created example scripts in `docs/examples/`
- Added GitHub PR template

### Fixed
- JavaScript boolean values in Playwright page.evaluate() functions
- Fixed proper output directory structure for API test results
- Improved error handling in API endpoints

## [0.1.0] - 2025-03-22

### Added
- Implemented core browser automation infrastructure
- Created Screenshot Capture API
  - Added `/api/screenshots/capture` endpoint with configurable options
  - Support for different viewport sizes
  - Full page and viewport-only screenshots
  - Multiple image formats (PNG/JPEG) and quality options

- Implemented DOM Extraction API
  - Added `/api/dom/extract` endpoint for DOM structure analysis
  - Support for CSS selector targeting
  - Optional style computation and attribute extraction

- Implemented CSS Analysis API
  - Added `/api/css/analyze` endpoint for CSS property analysis
  - Detailed style property extraction
  - Optional accessibility checking
  - Element visibility and positioning information

- Created testing framework with automated test scripts
- Set up Docker containerization with Playwright and Xvfb
- Established WebSocket interface for real-time communication
- Created comprehensive documentation in Memory Bank
</file>

<file path="docker-compose.yml">
version: "3.8"
services:
  mcp-browser:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: mcp-browser
    environment:
      - PYTHONPATH=/app
      - DISPLAY=:99
      - NETWORK_ISOLATION=true
      - ALLOWED_DOMAINS=example.com
      - BLOCKED_DOMAINS=blocked.com
      - RUN_TESTS=${RUN_TESTS:-false}
    volumes:
      - ./src:/app/src
      - ./tests:/app/tests
    networks:
      - mcp-browser-internal
      - mcp-browser-external
      - mcp-browser-monitoring
    security_opt:
      - apparmor=mcp-browser
    cap_add:
      - NET_ADMIN
    sysctls:
      net.ipv4.tcp_syncookies: 1
      net.ipv4.tcp_max_syn_backlog: 1024
      net.ipv4.tcp_synack_retries: 2
    ulimits:
      nofile:
        soft: 65536
        hard: 65536
      nproc:
        soft: 65536
        hard: 65536
    ports:
      - "7665:7665"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7665/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
networks:
  mcp-browser-internal:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
          gateway: 172.20.0.1
  mcp-browser-external:
    driver: bridge
    ipam:
      config:
        - subnet: 172.21.0.0/16
          gateway: 172.21.0.1
  mcp-browser-monitoring:
    driver: bridge
    ipam:
      config:
        - subnet: 172.22.0.0/16
          gateway: 172.22.0.1
</file>

<file path="Dockerfile">
FROM mcr.microsoft.com/playwright:v1.51.1-noble

# Install system dependencies
RUN apt-get update && apt-get install -y \
    xvfb \
    curl \
    python3 \
    python3-pip \
    python3.12-venv \
    && rm -rf /var/lib/apt/lists/*

# Set up virtual environment
ENV VIRTUAL_ENV=/app/venv
ENV PATH="$VIRTUAL_ENV/bin:$PATH"
ENV PYTHONPATH=/app
RUN python3 -m venv $VIRTUAL_ENV

# Install Python dependencies
COPY pyproject.toml requirements-test.txt /app/
WORKDIR /app
RUN pip install --no-cache-dir -r requirements-test.txt

# Install Playwright browsers
RUN python3 -m playwright install chromium

# Copy application files
COPY src/ /app/src/
COPY tests/ /app/tests/

# Copy Xvfb init script
COPY docker/xvfb-init.sh /usr/local/bin/
RUN chmod +x /usr/local/bin/xvfb-init.sh

# Set environment variables
ENV DISPLAY=:99
ENV RUN_TESTS=false

# Start Xvfb and run application or tests
CMD ["/usr/local/bin/xvfb-init.sh"]
</file>

<file path="example_mac_mini_setup.md">
# Setting up an MCP Browser on Mac Mini

This guide demonstrates how to set up the MCP Browser on a Mac Mini with a single command, allowing Claude or other MCP clients to visualize and test web frontends.

## Quick Start (One-Line Installation)

Simply run this command in your terminal on the Mac Mini:

```bash
curl -sSL https://raw.githubusercontent.com/neoforge-dev/mcp-browser/main/install_one_line.sh | bash
```

## What Gets Installed

The one-line installer will:

1. Install required dependencies (Git, Docker, Python, XQuartz)
2. Clone the MCP Browser repository
3. Configure environment settings
4. Start the MCP Browser server in Docker
5. Create a browser test client for visualization

## Testing the Installation

After installation completes, you'll see connection details displayed:

```
========================================
      MCP Browser Installation Complete
========================================

Server URL: http://192.168.1.x:7665
API Status: http://192.168.1.x:7665/api/status
WebSocket:  ws://192.168.1.x:7665/ws
Event WS:   ws://192.168.1.x:7665/ws/browser/events

Test Client: file:///Users/username/.mcp-browser/client/index.html

Connection Details:
MCP Secret: abcd1234efgh5678...

Connect your MCP client to this Mac using:
IP: 192.168.1.x
Port: 7665
Secret: abcd1234efgh5678...
```

## Connecting Claude or Other MCP Clients

You can connect Claude or other MCP clients to the server using the displayed IP, port, and secret. The server provides:

1. RESTful API for browser control
2. WebSocket API for real-time events
3. Visual browser interface for testing

## For iOS Development

To develop an iOS app as an MCP client:

1. Connect to the WebSocket endpoint: `ws://mac-ip:7665/ws/browser/events`
2. Subscribe to browser events using the WebSocket protocol
3. Use the REST API endpoints to control the browser

## Troubleshooting

If you encounter issues:

1. Check the installation log: `~/mcp-browser-install.log`
2. Verify Docker is running: `docker ps`
3. Check server logs: `cd ~/mcp-browser && docker-compose logs`
4. Restart the server: `cd ~/mcp-browser && docker-compose restart`
</file>

<file path="install_one_line.sh">
#!/bin/bash
#
# MCP Browser One-Line Installer Launcher
# Usage: curl -sSL https://raw.githubusercontent.com/neoforge-dev/mcp-browser/main/install_one_line.sh | bash
set -e
# Configuration variables
REPO="neoforge-dev/mcp-browser"
BRANCH="main"
INSTALLER_FILE="install.sh"
GITHUB_RAW_URL="https://raw.githubusercontent.com/${REPO}/${BRANCH}/${INSTALLER_FILE}"
# Check if running on Mac
if [[ "$(uname)" != "Darwin" ]]; then
  echo "This installer is designed for macOS. Please run it on a Mac."
  exit 1
fi
# Show banner
echo "========================================"
echo "      MCP Browser One-Line Installer"
echo "========================================"
echo ""
echo "This will install MCP Browser on your Mac"
echo "with visualization support for AI agents."
echo ""
# Ask for confirmation
read -p "Continue with installation? (y/n) " -n 1 -r
echo ""
if [[ ! $REPLY =~ ^[Yy]$ ]]; then
  echo "Installation cancelled."
  exit 0
fi
# Install Homebrew if not present
if ! command -v brew &> /dev/null; then
  echo "Installing Homebrew..."
  /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
fi
# Download and run the installer with line ending fixes
echo "Downloading and running MCP Browser installer..."
curl -sSL "$GITHUB_RAW_URL" | tr -d '\r' > /tmp/install_mcp_browser.sh
chmod +x /tmp/install_mcp_browser.sh
# Run the installer
/tmp/install_mcp_browser.sh
# Clean up
rm /tmp/install_mcp_browser.sh
</file>

<file path="install.sh">
#!/bin/bash
#
# MCP Browser Installer
# This script installs and configures MCP Browser for visual testing on Mac
set -e
# Configuration variables
REPO_URL="https://github.com/neoforge-dev/mcp-browser.git"
INSTALL_DIR="$HOME/mcp-browser"
PORT=7665
SECRET=$(openssl rand -hex 16)
LOG_FILE="$HOME/mcp-browser-install.log"
# Show banner
echo "========================================"
echo "      MCP Browser Installer"
echo "========================================"
echo ""
echo "This will install MCP Browser on your Mac"
echo "with visualization support for AI agents."
echo ""
# Ask for confirmation
read -p "Continue with installation? (y/n) " -n 1 -r
echo ""
if [[ ! $REPLY =~ ^[Yy]$ ]]; then
  echo "Installation cancelled."
  exit 0
fi
# Function to check for prerequisites
check_prerequisites() {
  echo "Checking prerequisites..."
  # Check for Git
  if ! command -v git &> /dev/null; then
    echo "Git not found. Installing..."
    brew install git
  fi
  # Check for Docker
  if ! command -v docker &> /dev/null; then
    echo "Docker not found. Installing..."
    brew install docker
    brew install docker-compose
  fi
  # Check for Python
  if ! command -v python3 &> /dev/null; then
    echo "Python not found. Installing..."
    brew install python
  fi
  # Check for XQuartz (X11 for Mac)
  if ! command -v xquartz &> /dev/null; then
    echo "XQuartz not found. Installing..."
    brew install --cask xquartz
  fi
}
# Function to clone or update repository
setup_repository() {
  echo "Setting up repository..."
  if [ -d "$INSTALL_DIR" ]; then
    echo "Repository exists. Updating..."
    cd "$INSTALL_DIR"
    git pull
  else
    echo "Cloning repository..."
    git clone "$REPO_URL" "$INSTALL_DIR"
    cd "$INSTALL_DIR"
  fi
}
# Function to configure environment
configure_environment() {
  echo "Configuring environment..."
  # Create .env file
  cat > "$INSTALL_DIR/.env" << EOF
MCP_SECRET=$SECRET
SERVER_PORT=8000
EOF
  # Create browser display configuration
  echo "Configuring browser display..."
  mkdir -p "$HOME/.mcp-browser"
  cat > "$HOME/.mcp-browser/config.json" << EOF
{
  "display": {
    "width": 1280,
    "height": 800,
    "deviceScaleFactor": 2,
    "mobile": false
  },
  "server": {
    "port": $PORT,
    "secret": "$SECRET"
  },
  "browser": {
    "headless": false,
    "defaultViewport": null
  }
}
EOF
}
# Function to start services
start_services() {
  echo "Starting services..."
  # Start XQuartz if not running
  if ! pgrep -x "Xquartz" > /dev/null && ! pgrep -x "X11" > /dev/null; then
    echo "Starting XQuartz X11 server..."
    # Try running the binary directly
    if [ -f "/Applications/Utilities/XQuartz.app/Contents/MacOS/X11" ]; then
      echo "Using XQuartz binary directly..."
      /Applications/Utilities/XQuartz.app/Contents/MacOS/X11 &
      sleep 5
    elif [ -f "/opt/X11/bin/Xquartz" ]; then
      echo "Using Xquartz binary from /opt/X11/bin..."
      /opt/X11/bin/Xquartz &
      sleep 5
    else
      echo "Trying to open XQuartz application..."
      open "/Applications/Utilities/XQuartz.app"
      sleep 5
      # Check if XQuartz started successfully
      if ! pgrep -x "Xquartz" > /dev/null && ! pgrep -x "X11" > /dev/null; then
        echo "WARNING: Could not start XQuartz automatically."
        echo "You may need to start it manually before proceeding."
        echo "Try running: /Applications/Utilities/XQuartz.app/Contents/MacOS/X11"
        echo "Or open XQuartz from your Applications folder."
        read -p "Press Enter to continue once XQuartz is running, or Ctrl+C to abort..."
      fi
    fi
  else
    echo "XQuartz is already running."
  fi
  # Start MCP Browser
  cd "$INSTALL_DIR"
  docker-compose down || true
  docker-compose up -d
  # Wait for service to be ready
  echo "Waiting for MCP Browser to be ready..."
  for i in {1..15}; do
    if curl -s "http://localhost:$PORT/api/status" | grep -q "ok"; then
      echo "MCP Browser is ready!"
      break
    fi
    if [ $i -eq 15 ]; then
      echo "MCP Browser failed to start. Check logs at: docker-compose logs"
      exit 1
    fi
    echo "Waiting... ($i/15)"
    sleep 5
  done
}
# Function to set up browser client
setup_browser_client() {
  echo "Setting up browser client..."
  # Create browser client HTML for testing
  mkdir -p "$HOME/.mcp-browser/client"
  cat > "$HOME/.mcp-browser/client/index.html" << 'EOF'
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>MCP Browser Client</title>
  <style>
    body { font-family: Arial, sans-serif; margin: 0; padding: 20px; }
    .container { max-width: 800px; margin: 0 auto; }
    .status { margin-bottom: 20px; padding: 10px; border-radius: 4px; }
    .connected { background-color: #d4edda; color: #155724; }
    .disconnected { background-color: #f8d7da; color: #721c24; }
    .event-log { height: 300px; overflow-y: auto; background-color: #f8f9fa; 
                 border: 1px solid #ddd; padding: 10px; border-radius: 4px; }
    button { background-color: #007bff; color: white; border: none; 
             padding: 8px 16px; border-radius: 4px; cursor: pointer; margin-right: 10px; }
    button:hover { background-color: #0069d9; }
    input { padding: 8px; margin-right: 10px; border: 1px solid #ddd; border-radius: 4px; }
  </style>
</head>
<body>
  <div class="container">
    <h1>MCP Browser Client</h1>
    <div id="status" class="status disconnected">Disconnected</div>
    <div class="actions">
      <button id="connect">Connect</button>
      <button id="disconnect" disabled>Disconnect</button>
      <button id="subscribe" disabled>Subscribe to Events</button>
    </div>
    <h2>Browser Control</h2>
    <div class="browser-control">
      <input type="text" id="url" placeholder="https://example.com" value="https://example.com">
      <button id="navigate" disabled>Navigate</button>
      <button id="screenshot" disabled>Take Screenshot</button>
      <button id="back" disabled>Back</button>
      <button id="forward" disabled>Forward</button>
    </div>
    <h2>Event Log</h2>
    <div id="event-log" class="event-log"></div>
  </div>
  <script>
    // Get port from URL or use default
    const PORT = 7665;
    // DOM Elements
    const statusEl = document.getElementById('status');
    const eventLogEl = document.getElementById('event-log');
    const connectBtn = document.getElementById('connect');
    const disconnectBtn = document.getElementById('disconnect');
    const subscribeBtn = document.getElementById('subscribe');
    const navigateBtn = document.getElementById('navigate');
    const screenshotBtn = document.getElementById('screenshot');
    const backBtn = document.getElementById('back');
    const forwardBtn = document.getElementById('forward');
    const urlInput = document.getElementById('url');
    // WebSocket connection
    let socket = null;
    let eventSocket = null;
    // Log an event
    function logEvent(message, isError = false) {
      const item = document.createElement('div');
      item.textContent = `[${new Date().toLocaleTimeString()}] ${message}`;
      if (isError) {
        item.style.color = '#dc3545';
      }
      eventLogEl.appendChild(item);
      eventLogEl.scrollTop = eventLogEl.scrollHeight;
    }
    // Connect to WebSocket
    connectBtn.addEventListener('click', () => {
      // Connect to main WebSocket
      socket = new WebSocket(`ws://localhost:${PORT}/ws`);
      socket.onopen = () => {
        statusEl.textContent = 'Connected';
        statusEl.classList.remove('disconnected');
        statusEl.classList.add('connected');
        connectBtn.disabled = true;
        disconnectBtn.disabled = false;
        subscribeBtn.disabled = false;
        navigateBtn.disabled = false;
        screenshotBtn.disabled = false;
        backBtn.disabled = false;
        forwardBtn.disabled = false;
        logEvent('Connected to WebSocket');
      };
      socket.onmessage = (event) => {
        const data = JSON.parse(event.data);
        logEvent(`Received: ${JSON.stringify(data)}`);
      };
      socket.onclose = () => {
        statusEl.textContent = 'Disconnected';
        statusEl.classList.remove('connected');
        statusEl.classList.add('disconnected');
        connectBtn.disabled = false;
        disconnectBtn.disabled = true;
        subscribeBtn.disabled = true;
        navigateBtn.disabled = true;
        screenshotBtn.disabled = true;
        backBtn.disabled = true;
        forwardBtn.disabled = true;
        logEvent('Disconnected from WebSocket');
      };
      socket.onerror = (error) => {
        logEvent(`WebSocket Error: ${error}`, true);
      };
    });
    // Disconnect from WebSocket
    disconnectBtn.addEventListener('click', () => {
      if (socket) {
        socket.close();
      }
      if (eventSocket) {
        eventSocket.close();
      }
    });
    // Subscribe to events
    subscribeBtn.addEventListener('click', () => {
      // Connect to event WebSocket
      eventSocket = new WebSocket(`ws://localhost:${PORT}/ws/browser/events`);
      eventSocket.onopen = () => {
        logEvent('Connected to Event WebSocket');
        // Subscribe to all event types
        const subscribeMsg = {
          action: 'subscribe',
          event_types: ['PAGE', 'DOM', 'CONSOLE', 'NETWORK'],
          filters: { url_pattern: '*' }
        };
        eventSocket.send(JSON.stringify(subscribeMsg));
      };
      eventSocket.onmessage = (event) => {
        const data = JSON.parse(event.data);
        logEvent(`Event: ${JSON.stringify(data)}`);
      };
      eventSocket.onclose = () => {
        logEvent('Disconnected from Event WebSocket');
      };
      eventSocket.onerror = (error) => {
        logEvent(`Event WebSocket Error: ${error}`, true);
      };
    });
    // Navigate to URL
    navigateBtn.addEventListener('click', () => {
      if (socket && socket.readyState === WebSocket.OPEN) {
        const url = urlInput.value;
        fetch(`http://localhost:${PORT}/api/browser/navigate`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({ url, timeout: 30, wait_until: 'networkidle' }),
        })
        .then(response => response.json())
        .then(data => {
          logEvent(`Navigated to: ${url}`);
        })
        .catch((error) => {
          logEvent(`Navigation Error: ${error}`, true);
        });
      }
    });
    // Take screenshot
    screenshotBtn.addEventListener('click', () => {
      if (socket && socket.readyState === WebSocket.OPEN) {
        fetch(`http://localhost:${PORT}/api/browser/screenshot`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({ full_page: true }),
        })
        .then(response => response.json())
        .then(data => {
          if (data.image_data) {
            const img = document.createElement('img');
            img.src = `data:image/png;base64,${data.image_data}`;
            img.style.maxWidth = '100%';
            img.style.marginTop = '10px';
            const wrapper = document.createElement('div');
            wrapper.appendChild(img);
            eventLogEl.appendChild(wrapper);
            eventLogEl.scrollTop = eventLogEl.scrollHeight;
            logEvent('Screenshot taken');
          }
        })
        .catch((error) => {
          logEvent(`Screenshot Error: ${error}`, true);
        });
      }
    });
    // Go back
    backBtn.addEventListener('click', () => {
      if (socket && socket.readyState === WebSocket.OPEN) {
        fetch(`http://localhost:${PORT}/api/browser/back`, {
          method: 'POST',
        })
        .then(response => response.json())
        .then(data => {
          logEvent('Navigated back');
        })
        .catch((error) => {
          logEvent(`Back Error: ${error}`, true);
        });
      }
    });
    // Go forward
    forwardBtn.addEventListener('click', () => {
      if (socket && socket.readyState === WebSocket.OPEN) {
        fetch(`http://localhost:${PORT}/api/browser/forward`, {
          method: 'POST',
        })
        .then(response => response.json())
        .then(data => {
          logEvent('Navigated forward');
        })
        .catch((error) => {
          logEvent(`Forward Error: ${error}`, true);
        });
      }
    });
  </script>
</body>
</html>
EOF
  echo "Browser client is available at: file://$HOME/.mcp-browser/client/index.html"
}
# Function to display installation summary
show_summary() {
  IP_ADDRESS=$(ipconfig getifaddr en0 || echo "localhost")
  echo ""
  echo "========================================"
  echo "      MCP Browser Installation Complete"
  echo "========================================"
  echo ""
  echo "Server URL: http://$IP_ADDRESS:$PORT"
  echo "API Status: http://$IP_ADDRESS:$PORT/api/status"
  echo "WebSocket:  ws://$IP_ADDRESS:$PORT/ws"
  echo "Event WS:   ws://$IP_ADDRESS:$PORT/ws/browser/events"
  echo ""
  echo "Test Client: file://$HOME/.mcp-browser/client/index.html"
  echo ""
  echo "Connection Details:"
  echo "MCP Secret: $SECRET"
  echo ""
  echo "Installation Log: $LOG_FILE"
  echo ""
  echo "Connect your MCP client to this Mac using:"
  echo "IP: $IP_ADDRESS"
  echo "Port: $PORT"
  echo "Secret: $SECRET"
  echo ""
  echo "To stop the server: cd $INSTALL_DIR && docker-compose down"
  echo "To start the server: cd $INSTALL_DIR && docker-compose up -d"
  echo ""
  echo "========================================"
}
# Main installation function
main() {
  check_prerequisites
  setup_repository
  configure_environment
  start_services
  setup_browser_client
  show_summary
  echo "MCP Browser installation completed successfully!"
}
# Execute main function and log output
{
  main
} 2>&1 | tee -a "$LOG_FILE"
</file>

<file path="Makefile">
.PHONY: build test test-network clean run

build:
	docker-compose build

run: build
	RUN_TESTS=false docker-compose up -d

test: build
	RUN_TESTS=true docker-compose up -d
	docker-compose logs -f

test-network: build
	RUN_TESTS=true docker-compose up -d
	docker-compose exec mcp-browser pytest /app/tests/test_network_isolation.py -v

clean:
	docker-compose down
	docker-compose rm -f

publish:
	docker login -u ${DOCKER_USER} -p ${DOCKER_PASS}
	docker tag mcp-browser neoforge-dev/mcp-browser:$(shell git rev-parse --short HEAD)
	docker push neoforge-dev/mcp-browser

generate-secret:
	@echo "MCP_SECRET=$(shell openssl rand -hex 32)" > .env

security-check:
	docker run --rm -it \
	  --security-opt apparmor=mcp-browser \
	  --entrypoint=lynis \
	  neoforge-dev/mcp-browser:latest audit system
</file>

<file path="ONE_LINE_INSTALL.md">
# MCP Browser One-Line Installation

## Mac Setup

To set up MCP Browser on your Mac with browser visualization for AI agents, run this command:

```bash
curl -sSL https://raw.githubusercontent.com/neoforge-dev/mcp-browser/main/install_one_line.sh | bash
```

## What This Does

This command:

1. Installs all required dependencies (including Homebrew if needed)
2. Sets up Docker and other prerequisites 
3. Configures MCP Browser with visualization support
4. Creates a browser test client for viewing and controlling the browser
5. Sets up WebSocket communication for real-time browser events
6. Provides configuration details for connecting your MCP client

## Requirements

- Mac running macOS
- Internet connection
- Administrator access

## Troubleshooting XQuartz Issues

If you encounter issues with XQuartz not starting properly during installation:

1. The installer will attempt to start XQuartz in several ways:
   - First by checking if it's already running
   - Then by trying to start it directly using the binary
   - Finally by opening the application

2. If automatic startup fails, you'll be prompted to start XQuartz manually:
   - Try running: `/Applications/Utilities/XQuartz.app/Contents/MacOS/X11`
   - Or open XQuartz from your Applications folder

3. Once XQuartz is running, press Enter to continue with the installation

## For iOS Development

For iOS app development as an MCP client:

1. Use the provided server URL, WebSocket endpoints, and secret generated during installation.
2. Implement WebSocket communication in your iOS app to connect to the MCP Browser server.
3. Utilize the API endpoints for browser control and event subscription.

## Manual Setup

If you prefer manual setup, you can:

1. Clone the repository: `git clone https://github.com/neoforge-dev/mcp-browser.git`
2. Navigate to the directory: `cd mcp-browser`
3. Run the installer: `./install.sh`

## Viewing and Testing

After installation, you can access:

- Test Client: `file:///Users/[username]/.mcp-browser/client/index.html`
- Server Status: `http://[mac-ip]:7665/api/status`

## Troubleshooting

If you encounter issues:

1. Check the installation log at `~/mcp-browser-install.log`
2. Ensure Docker is running properly
3. Check the Docker container logs: `cd ~/mcp-browser && docker-compose logs`
</file>

<file path="pyproject.toml">
[project]
name = "mcp-browser"
version = "0.1.0"
description = "Enterprise-grade secure browser automation for L3 AI coding agents"
readme = "README.md"
requires-python = ">=3.13"
dependencies = [
    "fastapi>=0.108.0",
    "uvicorn[standard]>=0.24.0",
    "playwright>=1.51.0",
    "python-jose>=3.4.0",
    "passlib>=1.7.4",
    "bcrypt>=4.3.0",
    "python-multipart>=0.0.20",
    "aiohttp>=3.11.14",
    "aiofiles>=24.1.0",
    "httpx>=0.28.1",
    "websockets>=15.0.1",
    "requests>=2.32.3",
    "pyyaml>=6.0",
    "mcp[cli]>=1.5.0",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src"]

[tool.pytest.ini_options]
pythonpath = ["src"]
testpaths = ["tests"]
python_files = ["test_*.py"]
addopts = "-v --strict-markers"
asyncio_mode = "strict"
asyncio_default_fixture_loop_scope = "function"
timeout = 10
</file>

<file path="README.md">
# MCP Browser

A headless browser interface for the Model Control Protocol (MCP).

## Features

- Headless browser automation using Playwright
- Web UI for browser interaction
- WebSocket communication for real-time updates
- Real-time browser event subscription system
- Integration with MCP for AI agents

## Prerequisites

- Python 3.13+
- [uv](https://github.com/astral-sh/uv) for dependency management
- Docker (for containerized usage)

## Installation

### One-Line Installation

To install MCP Browser on your Mac with one command:

```bash
curl -sSL https://raw.githubusercontent.com/neoforge-dev/mcp-browser/main/install_one_line.sh | bash
```

This command will download and run the installer with proper line ending handling to avoid common issues.

### Manual Installation

For manual installation:

1. Clone this repository
2. Run the installer script:

```bash
git clone https://github.com/neoforge-dev/mcp-browser.git
cd mcp-browser
./install.sh
```

### XQuartz Requirements

MCP Browser requires XQuartz (X11) for proper visualization. The installer will:

1. Check if XQuartz is already installed and install it if needed
2. Attempt to start the X11 server in various ways
3. Prompt you to start it manually if automatic methods fail

If you encounter issues, see the [Troubleshooting XQuartz Issues](ONE_LINE_INSTALL.md#troubleshooting-xquartz-issues) section.

## Local Development

### Setup with uv

```bash
# Clone the repository
git clone https://github.com/yourusername/mcp-browser.git
cd mcp-browser

# Install dependencies
uv venv .venv
source .venv/bin/activate
uv pip install -e .

# Install Playwright browsers
python -m playwright install
```

### Running Locally

For a simple test without Xvfb:

```bash
./simple_test.sh
```

For a full test with Xvfb (requires X11):

```bash
./test_local.sh
```

## Docker Deployment

Build and run using Docker Compose:

```bash
# Set your MCP secret
export MCP_SECRET=your_secret_key

# Build and run
docker-compose up --build
```

Or use the provided script:

```bash
./run.sh
```

## Configuration

The following environment variables can be set:

- `MCP_SECRET`: Secret key for MCP authentication
- `SERVER_PORT`: Port to run the server on (default: 7665)
- `PLAYWRIGHT_SKIP_BROWSER_DOWNLOAD`: Set to 1 to skip browser download and run in headless-only mode

## API Endpoints

- `GET /`: Web UI
- `GET /api/status`: Get browser and MCP client status
- `WebSocket /ws`: WebSocket endpoint for real-time communication
- `WebSocket /ws/browser/events`: WebSocket endpoint for browser event subscriptions
- `GET /api/browser/subscribe`: Subscribe to browser events
- `GET /api/browser/unsubscribe`: Unsubscribe from browser events
- `GET /api/browser/subscriptions`: List active event subscriptions

## Event Subscriptions

The MCP Browser supports real-time event subscriptions via WebSockets. This allows clients to receive browser events as they happen, including:

- Page events (navigation, load, error)
- DOM events (mutations, changes)
- Console events (logs, warnings, errors)
- Network events (requests, responses, errors)

For detailed documentation and examples of the event subscription system, see:
- [WebSocket Events Documentation](./WEBSOCKET_EVENTS.md)
- [Event Subscription Example](./examples/event_subscription_example.py)

## License

MIT
</file>

<file path="requirements-test.txt">
pytest>=8.2.0
pytest-asyncio==0.25.3
pytest-cov==4.1.0
playwright>=1.44.0
aiohttp==3.9.3
python-dotenv==1.0.1
docker
psutil
pydantic
fastapi
pytest-timeout
</file>

<file path="run_analysis.sh">
#!/bin/bash
# Run the MCP Browser with all frontend analysis APIs enabled
# Default port
PORT=7665
# Banner function
function print_banner() {
    echo "==============================================="
    echo "  MCP Browser - Frontend Analysis Platform"
    echo "  Version 0.2.0"
    echo "==============================================="
    echo ""
}
# Help function
function print_help() {
    echo "Usage: $0 [OPTIONS]"
    echo ""
    echo "Options:"
    echo "  -p, --port PORT    Specify the port to run on (default: 7665)"
    echo "  -h, --help         Show this help message"
    echo ""
    echo "Available API Endpoints:"
    echo "  - /api/screenshots/capture   Capture screenshots with various options"
    echo "  - /api/dom/extract           Extract and analyze DOM structure"
    echo "  - /api/css/analyze           Analyze CSS properties of elements"
    echo "  - /api/accessibility/test    Test for accessibility issues"
    echo "  - /api/responsive/test       Test responsive behavior across viewports"
    echo ""
    echo "Example: $0 --port 8080"
}
# Parse command line arguments
while [[ $# -gt 0 ]]; do
    case $1 in
        -p|--port)
            PORT="$2"
            shift
            shift
            ;;
        -h|--help)
            print_banner
            print_help
            exit 0
            ;;
        *)
            echo "Unknown option: $1"
            print_help
            exit 1
            ;;
    esac
done
# Create required directories
mkdir -p output/screenshots
mkdir -p output/dom
mkdir -p output/css
mkdir -p output/accessibility
mkdir -p output/responsive
# Print banner
print_banner
# Check for Python and uv
if ! command -v python3 &> /dev/null; then
    echo "Error: Python 3 is required but not found"
    exit 1
fi
if ! command -v uv &> /dev/null; then
    echo "Error: The uv package manager is required but not found"
    echo "Install with: pip install uv"
    exit 1
fi
# Activate virtual environment if it exists
if [ -d ".venv" ]; then
    echo "Activating virtual environment..."
    source .venv/bin/activate
fi
# Set environment variables
export SERVER_PORT=$PORT
# Run the server
echo "Starting MCP Browser on port $PORT..."
echo "Press Ctrl+C to stop the server"
echo ""
uv run src/main.py
# Capture Ctrl+C and clean up
trap 'echo "Shutting down MCP Browser..."; exit 0' INT
</file>

<file path="run.sh">
#!/bin/bash
set -e
# Check if .env file exists and source it
if [ -f .env ]; then
    echo "Loading environment variables from .env file..."
    export $(grep -v '^#' .env | xargs)
elif [ -f .env.example ]; then
    echo "No .env file found. Using .env.example as a template..."
    cp .env.example .env
    echo "Please update the .env file with your actual secrets and configuration."
    echo "Press Enter to continue with example values or Ctrl+C to abort."
    read -r
    export $(grep -v '^#' .env | xargs)
fi
# Check if MCP_SECRET is set
if [ -z "$MCP_SECRET" ]; then
    echo "WARNING: MCP_SECRET environment variable is not set."
    echo "Some functionality may be limited."
    echo "You can set it in your .env file or using: export MCP_SECRET=your_secret_key"
    # Generate a random secret if needed
    MCP_SECRET=$(openssl rand -hex 16)
    echo "Generated a random MCP_SECRET for this session: $MCP_SECRET"
    export MCP_SECRET
fi
# Check if docker-compose is installed
if ! command -v docker-compose &> /dev/null; then
    echo "docker-compose is not installed. Please install it first."
    exit 1
fi
# Build and start the MCP browser container
echo "Building and starting MCP browser..."
echo "The server will be available at http://localhost:7665"
# Use cat to prevent interactive output issues
docker-compose up --build "$@" | cat
# Handle exit
echo "MCP browser stopped."
</file>

<file path="simple_test.sh">
#!/bin/bash
set -e
# Check for virtual environment and create if needed
if [ ! -d ".venv" ]; then
    echo "Creating virtual environment..."
    uv venv .venv
fi
# Activate virtual environment
echo "Activating virtual environment..."
source .venv/bin/activate
# Install dependencies
echo "Installing dependencies..."
uv pip install -e .
# Set MCP_SECRET if not already set
if [ -z "$MCP_SECRET" ]; then
    export MCP_SECRET="test_secret_key"
    echo "Set MCP_SECRET to a test value. In production, use a proper secret."
fi
# Set headless mode for Playwright (no display needed)
export PLAYWRIGHT_BROWSERS_PATH=0
export PLAYWRIGHT_DRIVER_URL=""
export PLAYWRIGHT_SKIP_BROWSER_DOWNLOAD=1
# Start the MCP browser in headless-only mode
echo "Starting MCP Browser on http://localhost:7665 in headless mode"
cd src
python main.py
</file>

<file path="test_api.sh">
#!/bin/bash
# Test the MCP Browser API endpoints
set -e
# Determine the directory where the script is located
SCRIPT_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
# Create output directories if they don't exist
mkdir -p "$SCRIPT_DIR/output/screenshots"
mkdir -p "$SCRIPT_DIR/output/dom"
mkdir -p "$SCRIPT_DIR/output/css"
mkdir -p "$SCRIPT_DIR/output/accessibility"
mkdir -p "$SCRIPT_DIR/output/responsive"
# Check if the server is running
if ! curl -s "http://localhost:7665/api/status" > /dev/null; then
    echo "Error: MCP Browser server is not running on port 7665."
    echo "Please start the server first with ./run.sh"
    exit 1
fi
# Navigate to the script directory
cd "$SCRIPT_DIR"
# Activate virtual environment if it exists
if [ -d ".venv" ]; then
    echo "Activating virtual environment..."
    source .venv/bin/activate
fi
# Install test dependencies if not already installed
if ! python -c "import requests" 2>/dev/null; then
    echo "Installing test dependencies..."
    python -m pip install requests
fi
# Run the API tests
echo "Running API tests..."
python src/test_api.py
# Get the exit code
EXIT_CODE=$?
# Output based on success or failure
if [ $EXIT_CODE -eq 0 ]; then
    echo "✅ All tests passed successfully!"
else
    echo "❌ Some tests failed. Check the output above for details."
fi
exit $EXIT_CODE
</file>

<file path="test_local.sh">
#!/bin/bash
set -e
# Check for Xvfb
if ! command -v Xvfb &> /dev/null; then
    echo "Xvfb not found. You may need to install it."
    echo "On macOS: brew install xquartz"
    echo "On Linux: sudo apt-get install xvfb"
    read -p "Continue without Xvfb? (y/n) " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        exit 1
    fi
    echo "Continuing without Xvfb. Some features may not work properly."
    export DISPLAY=:0
else
    # Start Xvfb if not already running
    if ! ps aux | grep -v grep | grep -q "Xvfb :99"; then
        echo "Starting Xvfb..."
        Xvfb :99 -screen 0 1280x1024x24 -ac +extension GLX +render -noreset &
        XVFB_PID=$!
        export DISPLAY=:99
        # Give Xvfb time to start
        sleep 2
        # Check if Xvfb is running
        if ! ps -p $XVFB_PID > /dev/null; then
            echo "Error: Xvfb failed to start"
            exit 1
        fi
        echo "Xvfb started with PID $XVFB_PID"
        # Set up a trap to ensure clean shutdown
        trap "echo 'Shutting down Xvfb'; kill $XVFB_PID; exit" SIGINT SIGTERM EXIT
    else
        echo "Xvfb is already running"
        export DISPLAY=:99
    fi
fi
# Check for virtual environment and create if needed
if [ ! -d ".venv" ]; then
    echo "Creating virtual environment..."
    uv venv .venv
fi
# Activate virtual environment
echo "Activating virtual environment..."
source .venv/bin/activate
# Install dependencies
echo "Installing dependencies..."
uv pip install -e .
# Install Playwright browsers if needed
if [ ! -d "$HOME/.cache/ms-playwright" ]; then
    echo "Installing Playwright browsers..."
    python -m playwright install
fi
# Set MCP_SECRET if not already set
if [ -z "$MCP_SECRET" ]; then
    export MCP_SECRET="test_secret_key"
    echo "Set MCP_SECRET to a test value. In production, use a proper secret."
fi
# Start the MCP browser
echo "Starting MCP Browser on http://localhost:7665"
cd src
python main.py
</file>

<file path="test_mcp_events.sh">
#!/bin/bash
# Test script for MCP WebSocket event subscription
set -e
# Configuration
HOST=${HOST:-"localhost"}
PORT=${PORT:-8765}
ENDPOINT="ws://$HOST:$PORT/ws/browser/events"
# Check if colorama is available for colored output
if python3 -c "import colorama" &>/dev/null; then
    HAS_COLORAMA=1
else
    HAS_COLORAMA=0
    echo "Notice: colorama not installed. Running without color."
fi
# Color output function
color_echo() {
    local COLOR=$1
    local TEXT=$2
    if [ "$HAS_COLORAMA" -eq 1 ]; then
        python3 -c "import colorama; colorama.init(); print($COLOR + '$TEXT' + colorama.Style.RESET_ALL)" | cat
    else
        echo "$TEXT"
    fi
}
# Start the WebSocket server if it's not already running
if ! nc -z localhost $PORT 2>/dev/null; then
    color_echo "colorama.Fore.YELLOW" "Starting WebSocket server..."
    python3 src/test_websocket.py & 
    WEBSOCKET_PID=$!
    # Wait for server to start
    sleep 2
    color_echo "colorama.Fore.GREEN" "WebSocket server started with PID $WEBSOCKET_PID"
    # Register cleanup handler
    cleanup() {
        color_echo "colorama.Fore.YELLOW" "Stopping WebSocket server..."
        kill $WEBSOCKET_PID 2>/dev/null || true
        color_echo "colorama.Fore.GREEN" "WebSocket server stopped"
        exit 0
    }
    trap cleanup INT TERM EXIT
fi
# Check if server is running
if ! nc -z localhost $PORT 2>/dev/null; then
    color_echo "colorama.Fore.RED" "WebSocket server is not running!"
    exit 1
fi
# Run client test with websocket-client and colorama
color_echo "colorama.Fore.BLUE" "Testing WebSocket event subscription..."
# Run the client and pipe to cat to prevent interactive issues
python3 src/test_event_subscription.py -s $ENDPOINT -t "PAGE,DOM" -f "*example.com*" | cat
# If we started the server, we'll clean it up on exit via the trap
if [ -n "$WEBSOCKET_PID" ]; then
    color_echo "colorama.Fore.GREEN" "Test completed successfully. Press Ctrl+C to exit."
    # Keep the script running so the server stays alive for manual testing
    while true; do
        sleep 1
    done
else
    color_echo "colorama.Fore.GREEN" "Test completed successfully."
fi
</file>

<file path="test_mcp_tools.sh">
#!/bin/bash
# Test script for MCP Browser Protocol Extensions
# This script tests the browser navigation, DOM manipulation, and visual analysis tools
set -e
# Set API base URL
API_URL=${API_URL:-"http://localhost:7665"}
TEST_URL="https://example.com"
# Colors for output
GREEN='\033[0;32m'
RED='\033[0;31m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color
# Function to make API calls with query parameters
call_api() {
    local endpoint=$1
    local query_params=$2
    echo -e "${YELLOW}Testing: ${endpoint}${NC}"
    # Prepare query string if params provided
    local query_string=""
    if [ -n "$query_params" ]; then
        query_string="?$query_params"
    fi
    response=$(curl -s -X POST "${API_URL}${endpoint}${query_string}")
    if echo "$response" | grep -q "success\":true"; then
        echo -e "${GREEN}✅ Success: $endpoint${NC}"
    else
        echo -e "${RED}❌ Failed: $endpoint${NC}"
        echo "$response"
    fi
    # Create a safe filename by replacing slashes and other special chars
    safe_filename=$(echo "${endpoint}${query_string}" | sed 's/[\/\?=&]/_/g')
    echo "$response" > "output/mcp_test${safe_filename}.json"
    echo ""
    # Return the response for further processing
    echo "$response"
}
# Create output directory if it doesn't exist
mkdir -p output
echo -e "${YELLOW}Starting MCP Browser Protocol Extensions Test...${NC}"
echo -e "${YELLOW}API URL: ${API_URL}${NC}"
echo -e "${YELLOW}Test URL: ${TEST_URL}${NC}"
echo ""
# Check API status
echo -e "${YELLOW}Checking API status...${NC}"
status=$(curl -s "${API_URL}/api/status")
echo "$status"
echo ""
# First create a new page by navigating to a URL
echo -e "${YELLOW}Creating initial browser page...${NC}"
call_api "/api/browser/navigate" "url=${TEST_URL}&wait_until=networkidle"
# Test Browser Navigation Tools
echo -e "${YELLOW}Testing Browser Navigation Tools...${NC}"
# Get current URL
call_api "/api/browser/get_url" ""
# Get page title
call_api "/api/browser/get_title" ""
# Navigate to another page
call_api "/api/browser/navigate" "url=https://example.org&wait_until=networkidle"
# Go back
call_api "/api/browser/back" "wait_until=networkidle"
# Go forward
call_api "/api/browser/forward" "wait_until=networkidle"
# Refresh page
call_api "/api/browser/refresh" "wait_until=networkidle"
# Test DOM Manipulation Tools
echo -e "${YELLOW}Testing DOM Manipulation Tools...${NC}"
# Navigate to test URL again
call_api "/api/browser/navigate" "url=${TEST_URL}&wait_until=networkidle"
# Click on a link
call_api "/api/browser/click" "selector=a&wait_for_navigation=true"
# Go back
call_api "/api/browser/back" "wait_until=networkidle"
# Check visibility
call_api "/api/browser/check_visibility" "selector=h1"
# Wait for selector
call_api "/api/browser/wait_for_selector" "selector=h1&state=visible"
# Extract text
call_api "/api/browser/extract_text" "selector=h1"
# Test Visual Analysis Tools
echo -e "${YELLOW}Testing Visual Analysis Tools...${NC}"
# Take a screenshot of full page
call_api "/api/browser/screenshot" "full_page=true&format=png"
# Take a screenshot of specific element
call_api "/api/browser/screenshot" "selector=h1&format=png"
# Evaluate JavaScript
call_api "/api/browser/evaluate" "expression=document.title"
echo -e "${GREEN}MCP Browser Protocol Extensions Test Complete!${NC}"
echo -e "${GREEN}Test results saved to the output directory.${NC}"
</file>

<file path="test_simple.sh">
#!/bin/bash
# Simple test for the MCP Browser API endpoints
set -e
# Determine the directory where the script is located
SCRIPT_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
# Check if the server is running
if ! curl -s "http://localhost:7665/api/status" > /dev/null; then
    echo "Error: MCP Browser server is not running on port 7665."
    echo "Please start the server first with ./run.sh or 'uv run src/main.py'"
    exit 1
fi
# Navigate to the script directory
cd "$SCRIPT_DIR"
# Activate virtual environment if it exists
if [ -d ".venv" ]; then
    echo "Activating virtual environment..."
    source .venv/bin/activate
fi
# Run the simple test with pipe to cat to avoid interactive issues
echo "Running simple API test..."
python src/simple_test.py | cat
# Get the exit code (use PIPESTATUS to get the exit code of the python command, not cat)
EXIT_CODE=${PIPESTATUS[0]}
# Output based on success or failure
if [ $EXIT_CODE -eq 0 ]; then
    echo "✅ Basic test passed successfully!"
else
    echo "❌ Basic test failed. Check the output above for details."
fi
exit $EXIT_CODE
</file>

<file path="WEBSOCKET_EVENTS.md">
# MCP Browser WebSocket Event Subscriptions

This document describes the WebSocket event subscription feature in MCP Browser, which allows real-time monitoring of browser events.

## Overview

The WebSocket event subscription system enables clients to:

1. Connect to the MCP Browser server via WebSockets
2. Subscribe to specific types of browser events
3. Receive real-time notifications when these events occur
4. Filter events based on various criteria

This creates a powerful foundation for building real-time monitoring, debugging, and automation tools that can react to browser activity.

## Event Types

The system supports the following event types:

| Event Type | Description                             | Examples                                      |
|------------|-----------------------------------------|-----------------------------------------------|
| PAGE       | Page lifecycle events                   | Navigation, loads, errors                     |
| DOM        | DOM mutations and changes               | Element additions/removals, attribute changes |
| CONSOLE    | Browser console messages                | Logs, warnings, errors                        |
| NETWORK    | Network requests, responses, and errors | XHR, fetch, resource loading                  |

## WebSocket Endpoints

### Browser Events Endpoint

- URL: `/ws/browser/events`
- Description: Main WebSocket endpoint for subscribing to browser events

## Subscribing to Events

To subscribe to events, send a JSON message to the WebSocket with:

```json
{
  "action": "subscribe",
  "event_types": ["PAGE", "NETWORK", "CONSOLE", "DOM"],
  "filters": {
    "url_pattern": "example\\.com"  // Optional URL pattern filter
  }
}
```

You'll receive a confirmation with a subscription ID:

```json
{
  "type": "subscription",
  "subscription_id": "sub_ce12596c-d74e-4cf6-a911-2534dfbcb773",
  "event_types": ["PAGE", "NETWORK", "CONSOLE", "DOM"],
  "filters": { "url_pattern": "example\\.com" },
  "timestamp": 1742765514.711262
}
```

## Receiving Events

Events are pushed to the client as JSON messages with this structure:

```json
{
  "type": "PAGE",
  "event": "page.load",
  "timestamp": 1742765514.711472,
  "page_id": "page_123456",
  "data": {
    "url": "https://example.com",
    "lifecycle": "load",
    "timestamp": 1742765514.711472
  }
}
```

## Event Filtering

Events can be filtered using:

- `url_pattern`: Regular expression to match the page URL
- `page_id`: Specific page ID to monitor

## Unsubscribing

To unsubscribe, send:

```json
{
  "action": "unsubscribe",
  "subscription_id": "sub_ce12596c-d74e-4cf6-a911-2534dfbcb773"
}
```

## Listing Active Subscriptions

To list your active subscriptions, send:

```json
{
  "action": "list"
}
```

## Example Usage Scenarios

1. **Real-time debugging**: Monitor console errors, network failures, and DOM changes
2. **Performance monitoring**: Track page load times, resource loading, and rendering performance
3. **Automation**: Trigger actions based on specific page events
4. **Testing**: Verify expected events occur in the correct sequence
5. **Analytics**: Collect detailed browsing behavior and performance data

## Testing

The repository includes test scripts to demonstrate this functionality:

1. `src/test_websocket.py`: A minimal WebSocket server that simulates browser events
2. `src/test_websocket_client.py`: A client that connects to the WebSocket server and displays events

To run the tests:

```bash
# Terminal 1: Start the WebSocket server
python src/test_websocket.py

# Terminal 2: Run the WebSocket client
python src/test_websocket_client.py --test-events
```

## Integration with MCP Browser

The WebSocket event subscription system is integrated with the MCP Browser's core functionality:

1. Real browser events are captured and transmitted through the WebSocket
2. Event handlers are automatically set up when pages are created
3. The system handles disconnections and subscription management gracefully
4. Events can be used by agent tools to enhance browser automation
</file>

</files>
